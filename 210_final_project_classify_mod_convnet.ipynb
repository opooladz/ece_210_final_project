{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210_final_project_classify_mod_convnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ece_210_final_project/blob/master/210_final_project_classify_mod_convnet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WUtfV1f7oe2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Libs \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special\n",
        "import scipy.io as sio\n",
        "import math\n",
        "#from  scipy.ndimage import convolve1d\n",
        "\n",
        "# Reloading any code written in external .py files.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oNvGRs4ogii",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keras try model \n",
        "def try_model(model, data, name, epochs=200, verbose=1):  \n",
        "  model.compile(optimizer='nadam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=[ 'accuracy'])\n",
        "\n",
        "  model.summary()  \n",
        "  history = model.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=64, verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']))  \n",
        "  score = model.evaluate(data['x_test'], data['y_test'])\n",
        "  print('Test accuracy: {}'.format(score))\n",
        "  \n",
        "#   out_path = 'serialized_models/{}.h5'.format(name)  \n",
        "#   model.save(out_path)\n",
        "  \n",
        "#   with open('serialized_models/{}_history.pickle'.format(name), 'wb') as handle:\n",
        "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "  return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUKnMAX7oh4c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Comms Stuff Will add more later\n",
        "def qammod(m,y):\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  x = a + 1.*1j*b\n",
        "  # lets hold x in a np array([real,imag])\n",
        "  # x = np.array([a,1.*b]).T\n",
        "  return [x , y] \n",
        "\n",
        "def qammod2(m,size,trials):\n",
        "  \"\"\"\n",
        "  m - highest integer for the randint\n",
        "  \"\"\"\n",
        "  y = np.random.randint(m,size=(trials,size))\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  #x = a + 1.*1j*b\n",
        "  # lets hold x in a dp array([real,imag])\n",
        "  #x = np.array([a,1.*b])\n",
        "  x = np.dstack((a,b))\n",
        "  return [x , y]                        \n",
        "\n",
        "def channel2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  \n",
        "  [x,y] = qammod2(m,sequenceLen,trials)\n",
        "  \n",
        "  h = [1., 0.5, 0.3, -0.13, 0.2, 0, 0.4]\n",
        "  #h = np.random.randn(1,chanelLen)\n",
        "  #h = [1]\n",
        "  #print(x.shape)\n",
        "#   xh = np.empty((sequenceLen+len(h)-1,2))\n",
        "#   xh[:,0] = np.convolve(x[:,0],h)   \n",
        "#   xh[:,1] = np.convolve(x[:,1],h)   \n",
        "  #xh = convolve1d(x,h,axis = 1)\n",
        "  xh = np.apply_along_axis(lambda m: np.convolve(m,h[0:chanelLen],mode=\"full\"),axis = 1,arr=x)\n",
        "  #print(xh.shape)\n",
        "  SNR = 10**(SNRdB/10)\n",
        "  sym_noise_pow = np.var(xh)/SNR\n",
        "  sym_noise_scale_fact = np.sqrt(sym_noise_pow/2)\n",
        "  if(Noise):\n",
        "    AWGN = sym_noise_scale_fact*np.random.normal(1, size=xh.shape) \n",
        "    xh = xh + AWGN\n",
        "  #return [xhN.T , np.repeat(y,2) ]\n",
        "  return [xh , y ]\n",
        "  \n",
        "                        \n",
        "data={}\n",
        "def generateData(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  [data['x_train'],data['y_train']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_val'],data['y_val']] = channel2(m=m,sequenceLen=sequenceLen,trials=int(trials*0.5),Noise= Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_test'],data['y_test']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen) \n",
        "                        \n",
        "data2={}\n",
        "def generateData2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  [data2['x_train'],data2['y_train']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data2['x_val'],data2['y_val']] = channel2(m=m,sequenceLen=sequenceLen,trials=int(trials*0.5),Noise= Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data2['x_test'],data2['y_test']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jcXW5-Kht_oK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unison_shuffled_copies(a, b, c):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p], c[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iEmM1vT0okMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a9c18760-3245-4734-f9f6-78d05b31c7a5"
      },
      "cell_type": "code",
      "source": [
        "# Visulizing the data\n",
        "\n",
        "m = 4         # order of modulation\n",
        "#seqLen = 64    # length of one trial must be square powers of 2 to make sense see below \n",
        "trials = 5000   # number of trials\n",
        "validation_trials = int(trials*0.5)\n",
        "Noise = 1\n",
        "SNRdB = 0\n",
        "chanelLen = 3\n",
        "\n",
        "\n",
        "x = 4\n",
        "square_power_of_two = 2**(2*x)\n",
        "seqLen = square_power_of_two\n",
        "print(seqLen)\n",
        "\n",
        "generateData(4,seqLen,trials,Noise,SNRdB,chanelLen)\n",
        "print(data['x_train'].shape) # data  # axis 1 should be 2x seqLen because of conv with a 2tap filter\n",
        "print(data['y_train'].shape) # labels\n",
        "data['y_train_QAM'] = np.zeros((trials,1))\n",
        "data['y_val_QAM'] = np.zeros((validation_trials,1))\n",
        "data['y_test_QAM'] = np.zeros((trials,1))\n",
        "\n",
        "generateData2(16,seqLen,trials,Noise,SNRdB,chanelLen)\n",
        "print(data2['x_train'].shape) # data  # axis 1 should be 2x seqLen because of conv with a 2tap filter\n",
        "print(data2['y_train'].shape) # labels\n",
        "data2['y_train_QAM'] = np.ones((trials,1))\n",
        "data2['y_val_QAM'] = np.ones((validation_trials,1))\n",
        "data2['y_test_QAM'] = np.ones((trials,1))\n",
        "\n",
        "bigData = {}\n",
        "bigData['x_train'] = np.reshape(np.stack((data['x_train'],data2['x_train']), axis=0), (trials*2, seqLen+chanelLen-1, 2))\n",
        "bigData['x_val'] = np.reshape(np.stack((data['x_val'],data2['x_val']), axis=0), (validation_trials * 2, seqLen+chanelLen-1, 2))\n",
        "bigData['x_test'] = np.reshape(np.stack((data['x_test'],data2['x_test']), axis=0), (trials*2, seqLen+chanelLen-1, 2))\n",
        "\n",
        "bigData['y_train'] = np.reshape(np.stack((data['y_train'],data2['y_train']), axis=0), (trials*2, seqLen))\n",
        "bigData['y_val'] = np.reshape(np.stack((data['y_val'],data2['y_val']), axis=0), (validation_trials * 2, seqLen))\n",
        "bigData['y_test'] = np.reshape(np.stack((data['y_test'],data2['y_test']), axis=0), (trials*2, seqLen))\n",
        "\n",
        "bigData['y_train_QAM'] = np.reshape(np.stack((data['y_train_QAM'],data2['y_train_QAM']), axis=0), (trials*2,1))\n",
        "bigData['y_val_QAM'] = np.reshape(np.stack((data['y_val_QAM'],data2['y_val_QAM']), axis=0), (validation_trials*2,1))\n",
        "bigData['y_test_QAM'] = np.reshape(np.stack((data['y_test_QAM'],data2['y_test_QAM']), axis=0), (trials*2,1))\n",
        "\n",
        "[bigData['x_train'], bigData['y_train_QAM'], bigData['y_train']] = unison_shuffled_copies(bigData['x_train'], bigData['y_train_QAM'], bigData['y_train'])\n",
        "[bigData['x_val'], bigData['y_val_QAM'], bigData['y_val']] = unison_shuffled_copies(bigData['x_val'], bigData['y_val_QAM'], bigData['y_val'])\n",
        "[bigData['x_test'], bigData['y_test_QAM'], bigData['y_test']] = unison_shuffled_copies(bigData['x_test'], bigData['y_test_QAM'], bigData['y_test'])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "(5000, 258, 2)\n",
            "(5000, 256)\n",
            "(5000, 258, 2)\n",
            "(5000, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vl13A8xWok_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b2b8831d-9bad-4c4a-c871-4c0a5dfc5e3c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Some keras stuffs\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, Flatten, AveragePooling2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.layers import Reshape, Permute\n",
        "from keras import regularizers\n",
        "import keras\n",
        "ykeys = {'y_train','y_val','y_test'}\n",
        "xkeys = {'x_train','x_val','x_test'}\n",
        "\n",
        "  \n",
        "y_train = keras.utils.to_categorical(bigData['y_train_QAM'] )\n",
        "y_val = keras.utils.to_categorical(bigData['y_val_QAM'] )\n",
        "y_test = keras.utils.to_categorical(bigData['y_test_QAM'] )\n",
        "\n",
        "#y_train = bigData['y_train_QAM']\n",
        "#y_val = bigData['y_val_QAM']\n",
        "#y_test = bigData['y_test_QAM']\n",
        "#print(bigData['x_train'].shape)\n",
        "#print(bigData['x_val'].shape)\n",
        "#print(bigData['x_test'].shape)\n",
        "#print(y_train.shape)\n",
        "#print(y_val.shape)\n",
        "#print(y_test.shape)\n",
        "\n",
        "\n",
        "default_data = {\n",
        "  'x_train': bigData['x_train'][:,0:bigData['y_train'].shape[1]-chanelLen+1,:],\n",
        "  'x_val': bigData['x_val'][:,0:bigData['y_val'].shape[1]-chanelLen+1,:],\n",
        "  'x_test': bigData['x_test'][:,0:bigData['y_test'].shape[1]-chanelLen+1,:],\n",
        "  'y_train': y_train,\n",
        "  'y_val': y_val,\n",
        "  'y_test': y_test,\n",
        "}\n",
        "# print(default_data['x_train'].shape)\n",
        "# print(default_data['x_val'].shape)\n",
        "# print(default_data['x_test'].shape)\n",
        "# print(default_data['y_train'].shape)\n",
        "# print(default_data['y_val'].shape)\n",
        "# print(default_data['y_test'].shape)\n",
        "\n",
        "\n",
        "xkeys = {'x_train','x_val','x_test'}\n",
        "bigDataX = {x:bigData[x].reshape(bigData[x].shape[0],-1,1) for x in xkeys}\n",
        "default_data.update(bigDataX)\n",
        "#bigDataY={y:np.expand_dims(default_data[y],axis=2) for y in ykeys}\n",
        "#default_data.update(bigDataY)\n",
        "print(default_data['x_train'].shape)\n",
        "print(default_data['x_test'].shape)\n",
        "print(default_data['y_train'].shape)\n",
        "print(default_data['y_test'].shape)\n",
        "print(default_data['x_val'].shape)\n",
        "print(default_data['y_val'].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 516, 1)\n",
            "(10000, 516, 1)\n",
            "(10000, 2)\n",
            "(10000, 2)\n",
            "(5000, 516, 1)\n",
            "(5000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "taFHyRfnomfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "14b4a0e1-034b-4885-8280-f15580a72329"
      },
      "cell_type": "code",
      "source": [
        "# QAM-4\n",
        "from keras.layers import Reshape,MaxPooling1D,Dense,Embedding,Conv1D, LSTM,CuDNNLSTM, TimeDistributed, GaussianNoise, Softmax,Flatten\n",
        "from keras import regularizers\n",
        "#np.expand_dims()\n",
        "modCNN = Sequential()\n",
        "#modCNN.add(Reshape(target_shape = (200,20,1),input_shape=(None,20)))\n",
        "modCNN.add(Conv1D(40,kernel_size=(10),input_shape=((seqLen+chanelLen-1)*2,1)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(40,kernel_size=(10)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(MaxPooling1D(pool_size=2, strides=None, padding='valid'))\n",
        "modCNN.add(Conv1D(40,kernel_size=(10)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(40,kernel_size=(10)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Flatten())\n",
        "# modCNN.add(Dense(2,bias_regularizer=regularizers.l2(0.005)))\n",
        "# modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "# modCNN.add(BatchNormalization())\n",
        "modCNN.add(Dropout(0.7))\n",
        "#modCNN.add(BatchNormalization())\n",
        "modCNN.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n",
        "try_model(modCNN, default_data, 'conv_lstmx', epochs=1)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 507, 40)           440       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 507, 40)           160       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 498, 40)           16040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 498, 40)           160       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 249, 40)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 240, 40)           16040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 240, 40)           160       \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 231, 40)           16040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 231, 40)           160       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9240)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9240)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 18482     \n",
            "=================================================================\n",
            "Total params: 67,682\n",
            "Trainable params: 67,362\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            " 5696/10000 [================>.............] - ETA: 4s - loss: 0.0595 - acc: 0.9935"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 9s 920us/step - loss: 0.0456 - acc: 0.9963 - val_loss: 0.0224 - val_acc: 1.0000\n",
            "10000/10000 [==============================] - 2s 232us/step\n",
            "Test accuracy: [0.022353109589219093, 1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03430a6fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "mG7-Wl7VU_fJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}