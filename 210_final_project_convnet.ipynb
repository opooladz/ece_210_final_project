{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210_final_project_convnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ece_210_final_project/blob/master/210_final_project_convnet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DeLbOeSmqguA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Libs \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special\n",
        "import scipy.io as sio\n",
        "import math\n",
        "#from  scipy.ndimage import convolve1d\n",
        "\n",
        "# Reloading any code written in external .py files.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ogt-kQ8x61dI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keras try model \n",
        "def try_model(model, data, name, epochs=200, verbose=1):  \n",
        "  model.compile(optimizer='nadam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=[ 'accuracy'])\n",
        "\n",
        "  model.summary()  \n",
        "  history = model.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=64, verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']))  \n",
        "  score = model.evaluate(data['x_test'], data['y_test'])\n",
        "  print('Test accuracy: {}'.format(score))\n",
        "  \n",
        "#   out_path = 'serialized_models/{}.h5'.format(name)  \n",
        "#   model.save(out_path)\n",
        "  \n",
        "#   with open('serialized_models/{}_history.pickle'.format(name), 'wb') as handle:\n",
        "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "  return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a24-OWBXsGkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Comms Stuff Will add more later\n",
        "def qammod(m,y):\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  x = a + 1.*1j*b\n",
        "  # lets hold x in a np array([real,imag])\n",
        "  # x = np.array([a,1.*b]).T\n",
        "  return [x , y] \n",
        "\n",
        "def qammod2(m,size,trials):\n",
        "  \"\"\"\n",
        "  m - highest integer for the randint\n",
        "  \"\"\"\n",
        "  y = np.random.randint(m,size=(trials,size))\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  #x = a + 1.*1j*b\n",
        "  # lets hold x in a dp array([real,imag])\n",
        "  #x = np.array([a,1.*b])\n",
        "  x = np.dstack((a,b))\n",
        "  return [x , y]                        \n",
        "\n",
        "def channel2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  \n",
        "  [x,y] = qammod2(m,sequenceLen,trials)\n",
        "  \n",
        "  h = [1., 0.5, 0.3, -0.13, 0.2, 0, 0.4]\n",
        "  #h = np.random.randn(1,chanelLen)\n",
        "  #h = [1]\n",
        "  #print(x.shape)\n",
        "#   xh = np.empty((sequenceLen+len(h)-1,2))\n",
        "#   xh[:,0] = np.convolve(x[:,0],h)   \n",
        "#   xh[:,1] = np.convolve(x[:,1],h)   \n",
        "  #xh = convolve1d(x,h,axis = 1)\n",
        "  xh = np.apply_along_axis(lambda m: np.convolve(m,h[0:chanelLen],mode=\"full\"),axis = 1,arr=x)\n",
        "  #print(xh.shape)\n",
        "  SNR = 10**(SNRdB/10)\n",
        "  sym_noise_pow = np.var(xh)/SNR\n",
        "  sym_noise_scale_fact = np.sqrt(sym_noise_pow/2)\n",
        "  if(Noise):\n",
        "    AWGN = sym_noise_scale_fact*np.random.normal(1, size=xh.shape) \n",
        "    xh = xh + AWGN\n",
        "  #return [xhN.T , np.repeat(y,2) ]\n",
        "  return [xh ,y ]\n",
        "  \n",
        "                        \n",
        "data={}\n",
        "def generateData2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  [data['x_train'],data['y_train']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_val'],data['y_val']] = channel2(m=m,sequenceLen=sequenceLen,trials=int(trials*0.5),Noise= Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_test'],data['y_test']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sztUIJEosHZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3e77f219-421d-4a70-aacb-15e5a3e7a0ff"
      },
      "cell_type": "code",
      "source": [
        "# Visulizing the data\n",
        "\n",
        "m = 4         # order of modulation\n",
        "#seqLen = 64    # length of one trial must be square powers of 2 to make sense see below \n",
        "trials = 1500   # number of trials \n",
        "Noise = 1\n",
        "SNRdB = 20\n",
        "chanelLen = 4\n",
        "\n",
        "\n",
        "x = 4\n",
        "square_power_of_two = 2**(2*x)\n",
        "seqLen = square_power_of_two  \n",
        "print(seqLen)\n",
        "\n",
        "generateData2(m,seqLen,trials,Noise,SNRdB,chanelLen)\n",
        "print(data['x_train'].shape) # data  # axis 1 should be 2x seqLen because of conv with a 2tap filter\n",
        "print(data['y_train'].shape) # labels\n",
        "#print(data['x_train']) # so u can see the data \n",
        "\n",
        "# tmp = (data['x_train'][:,:-1].reshape(trials,seqLen))\n",
        "\n",
        "# #plot 1\n",
        "# plt.scatter(np.real(tmp[0][:]),np.imag(tmp[0][:]))   \n",
        "#                                          # I only plot the first 10 points from \n",
        "#                                          # the sequence because as time goes on \n",
        "#                                          # the data becomes less dependent on the\n",
        "#                                          # previous symbols. Even 10 is a lot. \n",
        "# plt.title('4-QAM Mod With Multi-Channel AWGN plot 1')\n",
        "# plt.show()\n",
        "\n",
        "#plot 2\n",
        "# Just a pure 16 qam with 1 point on each constalation point \n",
        "# clearly we have 16 classes\n",
        "# [xtmp,ytmp]=  qammod(16,data['y_train'])\n",
        "# plt.scatter(xtmp[:,0],xtmp[:,1])\n",
        "# plt.title('16-QAM Mod plot 2')\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "(1500, 259, 2)\n",
            "(1500, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6RLVcKzsKTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b5e2e4fe-4d2c-4a2d-ae31-57b3413e2575"
      },
      "cell_type": "code",
      "source": [
        "# Some keras stuffs\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, Flatten, AveragePooling2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.layers import Reshape, Permute\n",
        "from keras import regularizers\n",
        "import keras\n",
        "ykeys = {'y_train','y_val','y_test'}\n",
        "xkeys = {'x_train','x_val','x_test'}\n",
        "\n",
        "  \n",
        "y_train = keras.utils.to_categorical(data['y_train'] , num_classes=m)\n",
        "y_val = keras.utils.to_categorical(data['y_val'] , num_classes=m)\n",
        "y_test = keras.utils.to_categorical(data['y_test'] , num_classes=m)\n",
        "\n",
        "print(data['x_train'].shape)\n",
        "print(data['x_test'].shape)\n",
        "print(y_train.shape)\n",
        "print(data['x_val'].shape)\n",
        "\n",
        "\n",
        "default_data = {\n",
        "  'x_train': data['x_train'],\n",
        "  'x_val': data['x_val'],\n",
        "  'x_test': data['x_test'],\n",
        "  'y_train': y_train,\n",
        "  'y_val': y_val,\n",
        "  'y_test': y_test,\n",
        "}\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 259, 2)\n",
            "(1500, 259, 2)\n",
            "(1500, 256, 4)\n",
            "(750, 259, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Jz3iVxn48iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2277
        },
        "outputId": "faf03f68-7a0a-4264-ab52-afe72eb486d2"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Reshape,Dense,Embedding,Conv1D, LSTM,CuDNNLSTM, TimeDistributed, GaussianNoise, Softmax,Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "modCNN = Sequential()\n",
        "modCNN.add(Conv1D(20,kernel_size=(80), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(20,kernel_size=(80), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Flatten())\n",
        "modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "modCNN.add(BatchNormalization())\n",
        "#modCNN.add(Dropout(0.4))\n",
        "modCNN.add(Softmax(axis=2))\n",
        "try_model(modCNN, default_data, 'conv_lstmx', epochs=50)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_32 (Conv1D)           (None, 180, 20)           3220      \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 180, 20)           80        \n",
            "_________________________________________________________________\n",
            "conv1d_33 (Conv1D)           (None, 101, 20)           32020     \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 101, 20)           80        \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 2020)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1024)              2069504   \n",
            "_________________________________________________________________\n",
            "reshape_16 (Reshape)         (None, 256, 4)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 256, 4)            16        \n",
            "_________________________________________________________________\n",
            "softmax_15 (Softmax)         (None, 256, 4)            0         \n",
            "=================================================================\n",
            "Total params: 2,104,920\n",
            "Trainable params: 2,104,832\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n",
            "Train on 1500 samples, validate on 750 samples\n",
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.3502 - acc: 0.3961 - val_loss: 1.0772 - val_acc: 0.5370\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 1s 399us/step - loss: 0.8067 - acc: 0.7357 - val_loss: 0.8595 - val_acc: 0.6861\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 1s 397us/step - loss: 0.6219 - acc: 0.8601 - val_loss: 0.7336 - val_acc: 0.7663\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 1s 398us/step - loss: 0.5205 - acc: 0.9123 - val_loss: 0.6463 - val_acc: 0.8168\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 1s 397us/step - loss: 0.4528 - acc: 0.9402 - val_loss: 0.5811 - val_acc: 0.8488\n",
            "Epoch 6/50\n",
            " 448/1500 [=======>......................] - ETA: 0s - loss: 0.3863 - acc: 0.9664"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 1s 400us/step - loss: 0.4046 - acc: 0.9568 - val_loss: 0.5259 - val_acc: 0.8726\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 1s 406us/step - loss: 0.3670 - acc: 0.9677 - val_loss: 0.4810 - val_acc: 0.8894\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 1s 411us/step - loss: 0.3364 - acc: 0.9749 - val_loss: 0.4443 - val_acc: 0.9018\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 1s 404us/step - loss: 0.3108 - acc: 0.9801 - val_loss: 0.4141 - val_acc: 0.9112\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 1s 394us/step - loss: 0.2887 - acc: 0.9843 - val_loss: 0.3866 - val_acc: 0.9196\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 1s 396us/step - loss: 0.2696 - acc: 0.9874 - val_loss: 0.3644 - val_acc: 0.9265\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 1s 402us/step - loss: 0.2528 - acc: 0.9895 - val_loss: 0.3449 - val_acc: 0.9324\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 1s 401us/step - loss: 0.2373 - acc: 0.9913 - val_loss: 0.3288 - val_acc: 0.9365\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 1s 406us/step - loss: 0.2233 - acc: 0.9929 - val_loss: 0.3146 - val_acc: 0.9410\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 1s 405us/step - loss: 0.2109 - acc: 0.9941 - val_loss: 0.3011 - val_acc: 0.9444\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 1s 395us/step - loss: 0.1995 - acc: 0.9949 - val_loss: 0.2897 - val_acc: 0.9476\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 1s 393us/step - loss: 0.1889 - acc: 0.9959 - val_loss: 0.2792 - val_acc: 0.9502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 1s 391us/step - loss: 0.1793 - acc: 0.9964 - val_loss: 0.2697 - val_acc: 0.9535\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 1s 419us/step - loss: 0.1701 - acc: 0.9969 - val_loss: 0.2607 - val_acc: 0.9554\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 1s 405us/step - loss: 0.1621 - acc: 0.9973 - val_loss: 0.2529 - val_acc: 0.9577\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 1s 405us/step - loss: 0.1543 - acc: 0.9977 - val_loss: 0.2457 - val_acc: 0.9603\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 1s 399us/step - loss: 0.1473 - acc: 0.9980 - val_loss: 0.2389 - val_acc: 0.9616\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 1s 406us/step - loss: 0.1406 - acc: 0.9983 - val_loss: 0.2320 - val_acc: 0.9635\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 1s 413us/step - loss: 0.1344 - acc: 0.9984 - val_loss: 0.2261 - val_acc: 0.9653\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 1s 408us/step - loss: 0.1287 - acc: 0.9987 - val_loss: 0.2206 - val_acc: 0.9664\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 1s 409us/step - loss: 0.1232 - acc: 0.9988 - val_loss: 0.2153 - val_acc: 0.9677\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 1s 402us/step - loss: 0.1181 - acc: 0.9989 - val_loss: 0.2101 - val_acc: 0.9690\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 1s 399us/step - loss: 0.1133 - acc: 0.9991 - val_loss: 0.2055 - val_acc: 0.9705\n",
            "Epoch 29/50\n",
            "1216/1500 [=======================>......] - ETA: 0s - loss: 0.1070 - acc: 0.9992"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 1s 394us/step - loss: 0.1089 - acc: 0.9992 - val_loss: 0.2006 - val_acc: 0.9715\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 1s 397us/step - loss: 0.1044 - acc: 0.9993 - val_loss: 0.1966 - val_acc: 0.9719\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 1s 403us/step - loss: 0.1006 - acc: 0.9994 - val_loss: 0.1924 - val_acc: 0.9729\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 1s 400us/step - loss: 0.0968 - acc: 0.9994 - val_loss: 0.1884 - val_acc: 0.9741\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 1s 408us/step - loss: 0.0933 - acc: 0.9995 - val_loss: 0.1847 - val_acc: 0.9746\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 1s 394us/step - loss: 0.0899 - acc: 0.9995 - val_loss: 0.1807 - val_acc: 0.9756\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 1s 393us/step - loss: 0.0867 - acc: 0.9996 - val_loss: 0.1771 - val_acc: 0.9764\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 1s 399us/step - loss: 0.0836 - acc: 0.9996 - val_loss: 0.1738 - val_acc: 0.9769\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 1s 398us/step - loss: 0.0807 - acc: 0.9997 - val_loss: 0.1703 - val_acc: 0.9779\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 1s 397us/step - loss: 0.0780 - acc: 0.9997 - val_loss: 0.1674 - val_acc: 0.9786\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 1s 395us/step - loss: 0.0754 - acc: 0.9998 - val_loss: 0.1645 - val_acc: 0.9786\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 1s 402us/step - loss: 0.0730 - acc: 0.9998 - val_loss: 0.1616 - val_acc: 0.9793\n",
            "Epoch 41/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 1s 395us/step - loss: 0.0705 - acc: 0.9999 - val_loss: 0.1589 - val_acc: 0.9799\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 1s 393us/step - loss: 0.0683 - acc: 0.9999 - val_loss: 0.1561 - val_acc: 0.9804\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 1s 401us/step - loss: 0.0662 - acc: 0.9999 - val_loss: 0.1534 - val_acc: 0.9808\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 1s 410us/step - loss: 0.0642 - acc: 0.9999 - val_loss: 0.1510 - val_acc: 0.9811\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 1s 420us/step - loss: 0.0622 - acc: 0.9999 - val_loss: 0.1483 - val_acc: 0.9819\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 1s 402us/step - loss: 0.0604 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.9821\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 1s 403us/step - loss: 0.0585 - acc: 1.0000 - val_loss: 0.1434 - val_acc: 0.9827\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 1s 397us/step - loss: 0.0568 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 0.9828\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 1s 403us/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9833\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 1s 406us/step - loss: 0.0537 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9836\n",
            "1500/1500 [==============================] - 0s 153us/step\n",
            "Test accuracy: [0.1373520973920822, 0.9834427084922791]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3bdb729c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "JTXiqqQW1gxI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}