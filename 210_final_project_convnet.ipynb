{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210_final_project_convnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ece_210_final_project/blob/master/210_final_project_convnet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DeLbOeSmqguA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Libs \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special\n",
        "import scipy.io as sio\n",
        "import math\n",
        "#from  scipy.ndimage import convolve1d\n",
        "\n",
        "# Reloading any code written in external .py files.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ogt-kQ8x61dI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keras try model \n",
        "def try_model(model, data, name, epochs=200, verbose=1):  \n",
        "  model.compile(optimizer='nadam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=[ 'accuracy'])\n",
        "\n",
        "  model.summary()  \n",
        "  history = model.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=64, verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']))  \n",
        "  score = model.evaluate(data['x_test'], data['y_test'])\n",
        "  print('Test accuracy: {}'.format(score))\n",
        "  \n",
        "#   out_path = 'serialized_models/{}.h5'.format(name)  \n",
        "#   model.save(out_path)\n",
        "  \n",
        "#   with open('serialized_models/{}_history.pickle'.format(name), 'wb') as handle:\n",
        "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "  return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a24-OWBXsGkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Comms Stuff Will add more later\n",
        "def qammod(m,y):\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  x = a + 1.*1j*b\n",
        "  # lets hold x in a np array([real,imag])\n",
        "  # x = np.array([a,1.*b]).T\n",
        "  return [x , y] \n",
        "\n",
        "def qammod2(m,size,trials):\n",
        "  \"\"\"\n",
        "  m - highest integer for the randint\n",
        "  \"\"\"\n",
        "  y = np.random.randint(m,size=(trials,size))\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  #x = a + 1.*1j*b\n",
        "  # lets hold x in a dp array([real,imag])\n",
        "  #x = np.array([a,1.*b])\n",
        "  x = np.dstack((a,b))\n",
        "  return [x , y]                        \n",
        "\n",
        "def channel2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  \n",
        "  [x,y] = qammod2(m,sequenceLen,trials)\n",
        "  \n",
        "  h = [1., 0.5, 0.3, -0.13, 0.2, 0, 0.4]\n",
        "  #h = np.random.randn(1,chanelLen)\n",
        "  #h = [1]\n",
        "  #print(x.shape)\n",
        "#   xh = np.empty((sequenceLen+len(h)-1,2))\n",
        "#   xh[:,0] = np.convolve(x[:,0],h)   \n",
        "#   xh[:,1] = np.convolve(x[:,1],h)   \n",
        "  #xh = convolve1d(x,h,axis = 1)\n",
        "  xh = np.apply_along_axis(lambda m: np.convolve(m,h[0:chanelLen],mode=\"full\"),axis = 1,arr=x)\n",
        "  #print(xh.shape)\n",
        "  SNR = 10**(SNRdB/10)\n",
        "  sym_noise_pow = np.var(xh)/SNR\n",
        "  sym_noise_scale_fact = np.sqrt(sym_noise_pow/2)\n",
        "  if(Noise):\n",
        "    AWGN = sym_noise_scale_fact*np.random.normal(1, size=xh.shape) \n",
        "    xh = xh + AWGN\n",
        "  #return [xhN.T , np.repeat(y,2) ]\n",
        "  return [xh ,y ]\n",
        "  \n",
        "                        \n",
        "data={}\n",
        "def generateData2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  [data['x_train'],data['y_train']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_val'],data['y_val']] = channel2(m=m,sequenceLen=sequenceLen,trials=int(trials*0.5),Noise= Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_test'],data['y_test']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sztUIJEosHZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "79d89ccb-c423-4409-dab4-f6e8da9e2739"
      },
      "cell_type": "code",
      "source": [
        "# Visulizing the data\n",
        "\n",
        "m = 16         # order of modulation\n",
        "#seqLen = 64    # length of one trial must be square powers of 2 to make sense see below \n",
        "trials = 50000   # number of trials \n",
        "Noise = 1\n",
        "SNRdB = 20\n",
        "chanelLen = 2\n",
        "\n",
        "\n",
        "x = 4\n",
        "square_power_of_two = 2**(2*x)\n",
        "seqLen = square_power_of_two  \n",
        "print(seqLen)\n",
        "\n",
        "generateData2(m,seqLen,trials,Noise,SNRdB,chanelLen)\n",
        "print(data['x_train'].shape) # data  # axis 1 should be 2x seqLen because of conv with a 2tap filter\n",
        "print(data['y_train'].shape) # labels\n",
        "#print(data['x_train']) # so u can see the data \n",
        "\n",
        "# tmp = (data['x_train'][:,:-1].reshape(trials,seqLen))\n",
        "\n",
        "# #plot 1\n",
        "# plt.scatter(np.real(tmp[0][:]),np.imag(tmp[0][:]))   \n",
        "#                                          # I only plot the first 10 points from \n",
        "#                                          # the sequence because as time goes on \n",
        "#                                          # the data becomes less dependent on the\n",
        "#                                          # previous symbols. Even 10 is a lot. \n",
        "# plt.title('4-QAM Mod With Multi-Channel AWGN plot 1')\n",
        "# plt.show()\n",
        "\n",
        "#plot 2\n",
        "# Just a pure 16 qam with 1 point on each constalation point \n",
        "# clearly we have 16 classes\n",
        "# [xtmp,ytmp]=  qammod(16,data['y_train'])\n",
        "# plt.scatter(xtmp[:,0],xtmp[:,1])\n",
        "# plt.title('16-QAM Mod plot 2')\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "(50000, 257, 2)\n",
            "(50000, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6RLVcKzsKTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "dfdfe370-1de7-4561-9f65-777ec12f34d3"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Some keras stuffs\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, Flatten, AveragePooling2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.layers import Reshape, Permute\n",
        "from keras import regularizers\n",
        "import keras\n",
        "ykeys = {'y_train','y_val','y_test'}\n",
        "xkeys = {'x_train','x_val','x_test'}\n",
        "\n",
        "  \n",
        "y_train = keras.utils.to_categorical(data['y_train'] , num_classes=m)\n",
        "y_val = keras.utils.to_categorical(data['y_val'] , num_classes=m)\n",
        "y_test = keras.utils.to_categorical(data['y_test'] , num_classes=m)\n",
        "\n",
        "print(data['x_train'].shape)\n",
        "print(data['x_test'].shape)\n",
        "print(y_train.shape)\n",
        "print(data['x_val'].shape)\n",
        "\n",
        "\n",
        "default_data = {\n",
        "  'x_train': data['x_train'],\n",
        "  'x_val': data['x_val'],\n",
        "  'x_test': data['x_test'],\n",
        "  'y_train': y_train,\n",
        "  'y_val': y_val,\n",
        "  'y_test': y_test,\n",
        "}\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 257, 2)\n",
            "(50000, 257, 2)\n",
            "(50000, 256, 16)\n",
            "(25000, 257, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Jz3iVxn48iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2079
        },
        "outputId": "a1c05e4b-d516-4a10-80dc-0cc457a72954"
      },
      "cell_type": "code",
      "source": [
        "# QAM-4\n",
        "from keras.layers import Reshape,Dense,Embedding,Conv1D, LSTM,CuDNNLSTM, TimeDistributed, GaussianNoise, Softmax,Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "modCNN = Sequential()\n",
        "modCNN.add(Conv1D(2,kernel_size=(3), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(2,kernel_size=(3)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Flatten())\n",
        "modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "modCNN.add(BatchNormalization())\n",
        "#modCNN.add(Dropout(0.4))\n",
        "modCNN.add(Softmax(axis=2))\n",
        "try_model(modCNN, default_data, 'conv_lstmx', epochs=3)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_35 (Conv1D)           (None, 259, 2)            14        \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 259, 2)            8         \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 257, 2)            14        \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 257, 2)            8         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 514)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 4096)              2109440   \n",
            "_________________________________________________________________\n",
            "reshape_18 (Reshape)         (None, 256, 16)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 256, 16)           64        \n",
            "_________________________________________________________________\n",
            "softmax_18 (Softmax)         (None, 256, 16)           0         \n",
            "=================================================================\n",
            "Total params: 2,109,548\n",
            "Trainable params: 2,109,508\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 623us/step - loss: 2.7395 - acc: 0.1221 - val_loss: 2.4729 - val_acc: 0.1713\n",
            "Epoch 2/3\n",
            "  640/10000 [>.............................] - ETA: 3s - loss: 2.2020 - acc: 0.2984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3520/10000 [=========>....................] - ETA: 2s - loss: 2.2021 - acc: 0.2865"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6f413547e571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#modCNN.add(Dropout(0.4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtry_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv_lstmx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-34045dcff71f>\u001b[0m in \u001b[0;36mtry_model\u001b[0;34m(model, data, name, epochs, verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m   history = model.fit(data['x_train'], data['y_train'], \n\u001b[1;32m      8\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             validation_data=(data['x_val'], data['y_val']))  \n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4uiqlqiQ9y_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1357
        },
        "outputId": "9e1f8f7f-3444-42cb-c983-d36d46f3ab44"
      },
      "cell_type": "code",
      "source": [
        "# QAM-16\n",
        "from keras.layers import Reshape,Dense,Embedding,Conv1D, LSTM,CuDNNLSTM, TimeDistributed, GaussianNoise, Softmax,Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "modCNN = Sequential()\n",
        "modCNN.add(Conv1D(90,kernel_size=(10), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(90,kernel_size=(10)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Flatten())\n",
        "modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "modCNN.add(BatchNormalization())\n",
        "#modCNN.add(Dropout(0.4))\n",
        "modCNN.add(Softmax(axis=2))\n",
        "try_model(modCNN, default_data, 'conv_lstmx', epochs=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_43 (Conv1D)           (None, 248, 90)           1890      \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 248, 90)           360       \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 239, 90)           81090     \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 239, 90)           360       \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 21510)             0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 4096)              88109056  \n",
            "_________________________________________________________________\n",
            "reshape_22 (Reshape)         (None, 256, 16)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 256, 16)           64        \n",
            "_________________________________________________________________\n",
            "softmax_22 (Softmax)         (None, 256, 16)           0         \n",
            "=================================================================\n",
            "Total params: 88,192,820\n",
            "Trainable params: 88,192,428\n",
            "Non-trainable params: 392\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 25000 samples\n",
            "Epoch 1/50\n",
            " 3648/50000 [=>............................] - ETA: 2:45 - loss: 2.6164 - acc: 0.1648"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 137s 3ms/step - loss: 1.8606 - acc: 0.3693 - val_loss: 1.4891 - val_acc: 0.4446\n",
            "Epoch 2/50\n",
            "11072/50000 [=====>........................] - ETA: 1:39 - loss: 1.4602 - acc: 0.5140"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 1.3676 - acc: 0.5440 - val_loss: 1.2123 - val_acc: 0.5705\n",
            "Epoch 3/50\n",
            "13888/50000 [=======>......................] - ETA: 1:31 - loss: 1.1789 - acc: 0.6251"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 1.1242 - acc: 0.6458 - val_loss: 1.0167 - val_acc: 0.6673\n",
            "Epoch 4/50\n",
            "14976/50000 [=======>......................] - ETA: 1:29 - loss: 0.9861 - acc: 0.7047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.9451 - acc: 0.7221 - val_loss: 0.8613 - val_acc: 0.7414\n",
            "Epoch 5/50\n",
            "15360/50000 [========>.....................] - ETA: 1:28 - loss: 0.8337 - acc: 0.7677"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.7999 - acc: 0.7825 - val_loss: 0.7285 - val_acc: 0.8006\n",
            "Epoch 6/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.7067 - acc: 0.8181"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.6774 - acc: 0.8308 - val_loss: 0.6166 - val_acc: 0.8460\n",
            "Epoch 7/50\n",
            "15616/50000 [========>.....................] - ETA: 1:27 - loss: 0.5979 - acc: 0.8587"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.5728 - acc: 0.8691 - val_loss: 0.5212 - val_acc: 0.8805\n",
            "Epoch 8/50\n",
            "15616/50000 [========>.....................] - ETA: 1:27 - loss: 0.5064 - acc: 0.8903"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.4844 - acc: 0.8984 - val_loss: 0.4409 - val_acc: 0.9075\n",
            "Epoch 9/50\n",
            "15616/50000 [========>.....................] - ETA: 1:27 - loss: 0.4283 - acc: 0.9147"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.4100 - acc: 0.9209 - val_loss: 0.3743 - val_acc: 0.9275\n",
            "Epoch 10/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.3635 - acc: 0.9328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.3483 - acc: 0.9376 - val_loss: 0.3186 - val_acc: 0.9430\n",
            "Epoch 11/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.3097 - acc: 0.9465"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.2974 - acc: 0.9501 - val_loss: 0.2732 - val_acc: 0.9538\n",
            "Epoch 12/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.2654 - acc: 0.9570"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.2553 - acc: 0.9596 - val_loss: 0.2349 - val_acc: 0.9626\n",
            "Epoch 13/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.2291 - acc: 0.9646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.2208 - acc: 0.9666 - val_loss: 0.2051 - val_acc: 0.9683\n",
            "Epoch 14/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1991 - acc: 0.9703"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.1926 - acc: 0.9717 - val_loss: 0.1791 - val_acc: 0.9731\n",
            "Epoch 15/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1744 - acc: 0.9746"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.1691 - acc: 0.9757 - val_loss: 0.1591 - val_acc: 0.9762\n",
            "Epoch 16/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1542 - acc: 0.9777"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.1497 - acc: 0.9788 - val_loss: 0.1409 - val_acc: 0.9792\n",
            "Epoch 17/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1370 - acc: 0.9804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.1340 - acc: 0.9809 - val_loss: 0.1272 - val_acc: 0.9808\n",
            "Epoch 18/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1228 - acc: 0.9823"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.1198 - acc: 0.9829 - val_loss: 0.1157 - val_acc: 0.9822\n",
            "Epoch 19/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1127 - acc: 0.9829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.1096 - acc: 0.9837 - val_loss: 0.1047 - val_acc: 0.9837\n",
            "Epoch 20/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.1020 - acc: 0.9842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.0998 - acc: 0.9847 - val_loss: 0.0966 - val_acc: 0.9842\n",
            "Epoch 21/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.0939 - acc: 0.9847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.0933 - acc: 0.9845 - val_loss: 0.0908 - val_acc: 0.9841\n",
            "Epoch 22/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.0872 - acc: 0.9848"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.0875 - acc: 0.9843 - val_loss: 0.0863 - val_acc: 0.9835\n",
            "Epoch 23/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.0816 - acc: 0.9849"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.0806 - acc: 0.9851 - val_loss: 0.0790 - val_acc: 0.9847\n",
            "Epoch 24/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.0784 - acc: 0.9844"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 133s 3ms/step - loss: 0.0782 - acc: 0.9844 - val_loss: 0.0770 - val_acc: 0.9844\n",
            "Epoch 25/50\n",
            "15552/50000 [========>.....................] - ETA: 1:27 - loss: 0.0761 - acc: 0.9840"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "37184/50000 [=====================>........] - ETA: 32s - loss: 0.0755 - acc: 0.9843"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QTJRbvO9BkOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}