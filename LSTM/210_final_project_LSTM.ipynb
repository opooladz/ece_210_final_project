{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210_final_project_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ece_210_final_project/blob/master/LSTM/210_final_project_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DeLbOeSmqguA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c2c9863-b1d2-4130-d904-532144ab5096"
      },
      "cell_type": "code",
      "source": [
        "# Import Libs \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special\n",
        "import scipy.io as sio\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogt-kQ8x61dI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def categorical_crossentropy_with_masking(yTrue,yPred):\n",
        "  \"\"\"\n",
        "  Custom loss function to allow for masking \n",
        "  Assumption is that yTrue has a one-hot encoding and only has an all zero vector if that element should be masked\n",
        "  \"\"\"\n",
        "  #find which values in yTrue (target) are 0\n",
        "  #since y is shaped as (batch, length, features), the entire output vector must be true\n",
        "  mask = K.all(K.equal(yTrue, 0), axis=-1)\n",
        "  mask = 1 - K.cast(mask, K.floatx())\n",
        "  # multiply categorical_crossentropy with the mask\n",
        "  loss = K.categorical_crossentropy(yTrue, yPred) * mask\n",
        "\n",
        "  # take average w.r.t. the number of unmasked entries\n",
        "  return K.sum(loss) / K.sum(mask)\n",
        "\n",
        "def accuracy_with_masking(yTrue,yPred):\n",
        "  \"\"\"\n",
        "  Custom metric function to allow for masking\n",
        "  \"\"\"\n",
        "  mask = K.all(K.equal(yTrue, 0), axis=-1)\n",
        "  mask = 1 - K.cast(mask, K.floatx())\n",
        "  # Get categorical accuracy\n",
        "  loss = K.cast(K.equal(K.argmax(yTrue, axis=-1),\n",
        "                          K.argmax(yPred, axis=-1)),\n",
        "                  K.floatx()) \n",
        "  loss = loss*mask\n",
        "\n",
        "  # take average w.r.t. the number of unmasked entries\n",
        "  return K.sum(loss) / K.sum(mask)\n",
        "\n",
        "# Keras try model \n",
        "def try_model_lstm(model, data, epochs=200, verbose=1):\n",
        "  \"\"\"\n",
        "  model - Keras model\n",
        "  data - dictionary of training, testing, and validation data \n",
        "  name - str, name to save file under\n",
        "  epochs - number of epochs to run\n",
        "  verbose- boolean\n",
        "  mask - array to mask output\n",
        "  \"\"\"\n",
        "  reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy_with_masking', factor=0.2,\n",
        "                              patience=5,verbose = verbose)\n",
        "  model.compile(optimizer='nadam',\n",
        "            loss=categorical_crossentropy_with_masking,\n",
        "            metrics=[accuracy_with_masking])\n",
        "\n",
        "  model.summary()  \n",
        "  history = model.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=250, verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']),\n",
        "                     callbacks=[reduce_lr])  \n",
        "  score = model.evaluate(data['x_test'], data['y_test'])\n",
        "  print('Test accuracy: {}'.format(score))\n",
        "  \n",
        "  return history,score\n",
        "\n",
        "def try_model_conv(model, data, epochs=200, verbose=1):\n",
        "  \"\"\"\n",
        "  model - Keras model\n",
        "  data - dictionary of training, testing, and validation data \n",
        "  name - str, name to save file under\n",
        "  epochs - number of epochs to run\n",
        "  verbose- boolean\n",
        "  mask - array to mask output\n",
        "  \"\"\"\n",
        "  model.compile(optimizer='nadam',\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "  model.summary()  \n",
        "  history = model.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=250, verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']))  \n",
        "  score = model.evaluate(data['x_test'], data['y_test'])\n",
        "  print('Test accuracy: {}'.format(score))\n",
        "  \n",
        "  return history,score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4PD35IsamcBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Time-Invariant Channel"
      ]
    },
    {
      "metadata": {
        "id": "a24-OWBXsGkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Comms Stuff Will add more later\n",
        "def qammod(m,y):\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  x = a + 1.*1j*b\n",
        "  # lets hold x in a np array([real,imag])\n",
        "  # x = np.array([a,1.*b]).T\n",
        "  return [x , y] \n",
        "\n",
        "def qammod2(m,size,trials):\n",
        "  \"\"\"\n",
        "  m - highest integer for the randint\n",
        "  \"\"\"\n",
        "  y = np.random.randint(m,size=(trials,size))\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  #x = a + 1.*1j*b\n",
        "  # lets hold x in a dp array([real,imag])\n",
        "  #x = np.array([a,1.*b])\n",
        "  x = np.dstack((a,b))\n",
        "  return [x , y]                        \n",
        "\n",
        "def sim_channel(m,sequenceLen,trials,Noise,SNRdB,h):\n",
        "  \"\"\"\n",
        "  Simulates a channel\n",
        "  Input:\n",
        "    m - order of modulation\n",
        "    sequenceLen - lenght of sequence\n",
        "    trials - number trials\n",
        "    Noise - Boolean, if noise should be added\n",
        "    SNRdB - Ratio of signal to noise\n",
        "    h- channel parameters\n",
        "  \"\"\"\n",
        "  [x,y] = qammod2(m,sequenceLen,trials)\n",
        "  \n",
        "  xh = np.apply_along_axis(lambda q: np.convolve(q,h,mode=\"full\"),axis = 1,arr=x)\n",
        "  if(Noise):\n",
        "    SNR = 10**(SNRdB/10)\n",
        "    sym_noise_pow = np.var(xh)/SNR\n",
        "    sym_noise_scale_fact = np.sqrt(sym_noise_pow/2)\n",
        "    AWGN = sym_noise_scale_fact*np.random.normal(1, size=xh.shape) \n",
        "    xh = xh + AWGN\n",
        "  return [xh ,y ]\n",
        "  \n",
        "  \n",
        "def generateData(m,sequenceLen,trials,Noise,SNRdB,h,padding= True):\n",
        "  \"\"\"\n",
        "  Generates training, testing, and validation data for time invariant channels\n",
        "  Does one-hot encoding and padding\n",
        "  m - symbol alphabet\n",
        "  sequenceLen - length of data sequence\n",
        "  trials - number of samples\n",
        "  Noise- Boolean of whether to use AWGN\n",
        "  SNRdB - amount of noise\n",
        "  h - channel parameters\n",
        "  \"\"\"\n",
        "  data={}\n",
        "  [data['x_train'],data['y_train']] = sim_channel(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,h=h)\n",
        "  [data['x_val'],data['y_val']] = sim_channel(m=m,sequenceLen=sequenceLen,trials=int(trials*0.25),Noise= Noise,SNRdB=SNRdB,h=h)\n",
        "  [data['x_test'],data['y_test']] = sim_channel(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,h=h)\n",
        "  \n",
        "  print(\"x_train shape: \",data['x_train'].shape) # data, expected seqlen+chanelLen-1\n",
        "  print(\"y_train shape: \",data['y_train'].shape) # labels\n",
        "  \n",
        "  #One hot encoding\n",
        "  y_train = keras.utils.to_categorical(data['y_train'] , num_classes=m)\n",
        "  y_val = keras.utils.to_categorical(data['y_val'] , num_classes=m)\n",
        "  y_test = keras.utils.to_categorical(data['y_test'] , num_classes=m)\n",
        "  print(\"y_train shape, one-hot: \",y_train.shape)\n",
        "\n",
        "  #Padding \n",
        "  if(padding):\n",
        "    y_train = np.pad(y_train,((0,0),(0,chanelLen-1),(0,0)),\"constant\")\n",
        "    y_val = np.pad(y_val,((0,0),(0,chanelLen-1),(0,0)),\"constant\")\n",
        "    y_test = np.pad(y_test,((0,0),(0,chanelLen-1),(0,0)),\"constant\")\n",
        "\n",
        "  print(\"y_train shape, one-hot, padding: \",y_train.shape)\n",
        "\n",
        "  default_data = {\n",
        "    'x_train': data['x_train'],\n",
        "    'x_val': data['x_val'],\n",
        "    'x_test': data['x_test'],\n",
        "    'y_train': y_train,\n",
        "    'y_val': y_val,\n",
        "    'y_test': y_test,\n",
        "  }\n",
        "  return default_data\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-TfDKBM1YRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bb0fedb-17a7-4328-97ad-a2875c20b3e9"
      },
      "cell_type": "code",
      "source": [
        "# Instantiating Data\n",
        "\n",
        "m = 4         # order of modulation\n",
        "trials = 10000 # number of trials \n",
        "Noise = True\n",
        "SNRdB = 10\n",
        "seqLen = 300\n",
        "print(seqLen)\n",
        "#h = [1,0.4,0.3,0.2,0.25]\n",
        "chanelLen = 5\n",
        "h = np.random.rand(chanelLen)\n",
        "h[0] = 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Jz3iVxn48iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1866
        },
        "outputId": "87b8b31c-a157-4539-b57f-ec54f17a649e"
      },
      "cell_type": "code",
      "source": [
        "# QAM-4\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense,CuDNNLSTM, TimeDistributed,Softmax,Flatten,Bidirectional,Reshape,Embedding,Conv1D, Softmax,Flatten,BatchNormalization\n",
        "import keras\n",
        "\n",
        "#LSTM\n",
        "default_data_pad = generateData(m,seqLen,trials,Noise,SNRdB,h,padding=True)\n",
        "modLSTM = Sequential()\n",
        "#modLSTM.add(Bidirectional(CuDNNLSTM(10,return_sequences=True),input_shape=(seqLen+chanelLen-1,2)))\n",
        "modLSTM.add(CuDNNLSTM(30,return_sequences=True,input_shape=(seqLen+chanelLen-1,2)))\n",
        "modLSTM.add(TimeDistributed(Dense(m,activation=\"softmax\")))\n",
        "hist,score = try_model_lstm(modLSTM, default_data_pad, epochs=5)\n",
        "print(score)\n",
        "print(hist.history)\n",
        "\n",
        "#CNN\n",
        "default_data_no_pad = generateData(m,seqLen,trials,Noise,SNRdB,h,padding=False)\n",
        "modCNN = Sequential()\n",
        "modCNN.add(Conv1D(5,kernel_size=(chanelLen+1), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "# modCNN.add(BatchNormalization())\n",
        "# modCNN.add(Flatten())\n",
        "# modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "modCNN.add(TimeDistributed(Dense(m,activation=\"softmax\")))\n",
        "modCNN.add(Softmax(axis=2))\n",
        "hist,score = try_model_conv(modCNN, default_data_no_pad, epochs=10)\n",
        "print(score)\n",
        "print(hist.history)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (10000, 304, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 304, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_46 (CuDNNLSTM)    (None, 304, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_83 (TimeDis (None, 304, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            " 4864/10000 [=============>................] - ETA: 9s - loss: 1.0472 - accuracy_with_masking: 0.6179"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-dc68eaf0ea12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqLen\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchanelLen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_model_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_data_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-b293ef69480b>\u001b[0m in \u001b[0;36mtry_model_lstm\u001b[0;34m(model, data, epochs, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                      callbacks=[reduce_lr])  \n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XlmhcsZvy733",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Comparing Equalizer symbol error across different SNR"
      ]
    },
    {
      "metadata": {
        "id": "4uiqlqiQ9y_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13331
        },
        "outputId": "9eb042da-4a7a-466d-8a4c-de5e4e5a3f31"
      },
      "cell_type": "code",
      "source": [
        "m = 4         # order of modulation\n",
        "trials = 10000   # number of trials \n",
        "Noise = True\n",
        "x = 4\n",
        "seqLen = 300\n",
        "print(seqLen)\n",
        "# chanelLen = 5\n",
        "# h = np.random.rand(chanelLen)*0.5\n",
        "# h[0] = 1\n",
        "h = np.array([1,0.5,-0.3])\n",
        "chanelLen = len(h)\n",
        "print(\"Channel: \",h)\n",
        "\n",
        "snrs = np.linspace(10,-15,10)\n",
        "histories_lstm = []\n",
        "scores_lstm = []\n",
        "histories_conv = []\n",
        "scores_conv = []\n",
        "for SNRdB in snrs:\n",
        "  print(\"SNRdB: \",SNRdB)\n",
        "\n",
        "  #LSTM\n",
        "  default_data_pad = generateData(m,seqLen,trials,Noise,SNRdB,h,padding=True)\n",
        "  modLSTM = Sequential()\n",
        "  modLSTM.add(CuDNNLSTM(30,return_sequences=True,input_shape=(seqLen+chanelLen-1,2)))\n",
        "  modLSTM.add(TimeDistributed(Dense(m,activation=\"softmax\")))\n",
        "  hist,score = try_model_lstm(modLSTM, default_data_pad, epochs=5)\n",
        "  print(score)\n",
        "  histories_lstm.append(hist)\n",
        "  scores_lstm.append(score)\n",
        "  \n",
        "  #CNN\n",
        "  default_data_no_pad = generateData(m,seqLen,trials,Noise,SNRdB,h,padding=False)\n",
        "  modCNN = Sequential()\n",
        "  modCNN.add(Conv1D(10,kernel_size=(chanelLen), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "  modCNN.add(BatchNormalization())\n",
        "  modCNN.add(Flatten())\n",
        "  modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "  modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "  modCNN.add(Softmax(axis=2))\n",
        "  hist,score = try_model_conv(modCNN, default_data_no_pad, epochs=10)\n",
        "  print(score)\n",
        "  histories_conv.append(hist)\n",
        "  scores_conv.append(score)\n",
        "  print(\"Score: \",score)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "Channel:  [ 1.   0.5 -0.3]\n",
            "SNRdB:  10.0\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_11 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 9s 911us/step - loss: 0.8814 - accuracy_with_masking: 0.7747 - val_loss: 0.3773 - val_accuracy_with_masking: 0.9906\n",
            "Epoch 2/5\n",
            " 1408/10000 [===>..........................] - ETA: 5s - loss: 0.3415 - accuracy_with_masking: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 8s 753us/step - loss: 0.2087 - accuracy_with_masking: 0.9956 - val_loss: 0.1112 - val_accuracy_with_masking: 0.9974\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 747us/step - loss: 0.0764 - accuracy_with_masking: 0.9980 - val_loss: 0.0524 - val_accuracy_with_masking: 0.9985\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 7s 733us/step - loss: 0.0401 - accuracy_with_masking: 0.9987 - val_loss: 0.0307 - val_accuracy_with_masking: 0.9990\n",
            "Epoch 5/5\n",
            " 6848/10000 [===================>..........] - ETA: 2s - loss: 0.0265 - accuracy_with_masking: 0.9991"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 725us/step - loss: 0.0250 - accuracy_with_masking: 0.9991 - val_loss: 0.0204 - val_accuracy_with_masking: 0.9993\n",
            "10000/10000 [==============================] - 6s 631us/step\n",
            "Test accuracy: [0.02040519337952137, 0.9992136647224427]\n",
            "[0.02040519337952137, 0.9992136647224427]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_14 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_12 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_12 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 9664/10000 [===========================>..] - ETA: 0s - loss: 0.9497 - acc: 0.6280"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.9330 - acc: 0.6370 - val_loss: 0.4463 - val_acc: 0.8975\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.2657 - acc: 0.9567 - val_loss: 0.1822 - val_acc: 0.9766\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 253us/step - loss: 0.1191 - acc: 0.9885 - val_loss: 0.1032 - val_acc: 0.9869\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.0698 - acc: 0.9944 - val_loss: 0.0720 - val_acc: 0.9894\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.0468 - acc: 0.9968 - val_loss: 0.0567 - val_acc: 0.9902\n",
            "Epoch 6/10\n",
            " 8064/10000 [=======================>......] - ETA: 0s - loss: 0.0336 - acc: 0.9983"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.0339 - acc: 0.9980 - val_loss: 0.0480 - val_acc: 0.9905\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 2s 246us/step - loss: 0.0256 - acc: 0.9988 - val_loss: 0.0423 - val_acc: 0.9908\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.0201 - acc: 0.9992 - val_loss: 0.0385 - val_acc: 0.9907\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 252us/step - loss: 0.0159 - acc: 0.9995 - val_loss: 0.0361 - val_acc: 0.9906\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 255us/step - loss: 0.0128 - acc: 0.9997 - val_loss: 0.0339 - val_acc: 0.9906\n",
            "10000/10000 [==============================] - 1s 125us/step\n",
            "Test accuracy: [0.03367891373038292, 0.9907936644554138]\n",
            "[0.03367891373038292, 0.9907936644554138]\n",
            "Score:  [0.03367891373038292, 0.9907936644554138]\n",
            "SNRdB:  7.222222222222222\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_12 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            "   64/10000 [..............................] - ETA: 3:39 - loss: 1.3757 - accuracy_with_masking: 0.2949"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 9s 922us/step - loss: 0.9352 - accuracy_with_masking: 0.7355 - val_loss: 0.4762 - val_accuracy_with_masking: 0.9635\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 741us/step - loss: 0.2913 - accuracy_with_masking: 0.9741 - val_loss: 0.1743 - val_accuracy_with_masking: 0.9799\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 731us/step - loss: 0.1252 - accuracy_with_masking: 0.9837 - val_loss: 0.0901 - val_accuracy_with_masking: 0.9867\n",
            "Epoch 4/5\n",
            " 6400/10000 [==================>...........] - ETA: 2s - loss: 0.0779 - accuracy_with_masking: 0.9878"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 743us/step - loss: 0.0726 - accuracy_with_masking: 0.9883 - val_loss: 0.0593 - val_accuracy_with_masking: 0.9896\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 728us/step - loss: 0.0518 - accuracy_with_masking: 0.9900 - val_loss: 0.0454 - val_accuracy_with_masking: 0.9906\n",
            "10000/10000 [==============================] - 6s 619us/step\n",
            "Test accuracy: [0.045618675780296325, 0.9904913307189941]\n",
            "[0.045618675780296325, 0.9904913307189941]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_15 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_13 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_13 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3584/10000 [=========>....................] - ETA: 4s - loss: 1.3960 - acc: 0.3925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.9549 - acc: 0.6218 - val_loss: 0.4858 - val_acc: 0.8688\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 0.3143 - acc: 0.9274 - val_loss: 0.2401 - val_acc: 0.9436\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.1750 - acc: 0.9618 - val_loss: 0.1662 - val_acc: 0.9552\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 0.1240 - acc: 0.9707 - val_loss: 0.1378 - val_acc: 0.9573\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.0987 - acc: 0.9746 - val_loss: 0.1260 - val_acc: 0.9574\n",
            "Epoch 6/10\n",
            " 7040/10000 [====================>.........] - ETA: 0s - loss: 0.0803 - acc: 0.9794"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.0842 - acc: 0.9768 - val_loss: 0.1217 - val_acc: 0.9562\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 256us/step - loss: 0.0744 - acc: 0.9782 - val_loss: 0.1206 - val_acc: 0.9552\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.0675 - acc: 0.9794 - val_loss: 0.1221 - val_acc: 0.9542\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.0625 - acc: 0.9801 - val_loss: 0.1247 - val_acc: 0.9532\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.0578 - acc: 0.9811 - val_loss: 0.1286 - val_acc: 0.9525\n",
            "10000/10000 [==============================] - 1s 124us/step\n",
            "Test accuracy: [0.1281036313533783, 0.9525976661682128]\n",
            "[0.1281036313533783, 0.9525976661682128]\n",
            "Score:  [0.1281036313533783, 0.9525976661682128]\n",
            "SNRdB:  4.444444444444445\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_13 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 9s 943us/step - loss: 1.0403 - accuracy_with_masking: 0.6694 - val_loss: 0.6353 - val_accuracy_with_masking: 0.8918\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 743us/step - loss: 0.4473 - accuracy_with_masking: 0.9071 - val_loss: 0.3339 - val_accuracy_with_masking: 0.9153\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 727us/step - loss: 0.2836 - accuracy_with_masking: 0.9215 - val_loss: 0.2429 - val_accuracy_with_masking: 0.9279\n",
            "Epoch 4/5\n",
            " 6592/10000 [==================>...........] - ETA: 2s - loss: 0.2268 - accuracy_with_masking: 0.9307"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 726us/step - loss: 0.2205 - accuracy_with_masking: 0.9317 - val_loss: 0.2015 - val_accuracy_with_masking: 0.9350\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 724us/step - loss: 0.1916 - accuracy_with_masking: 0.9366 - val_loss: 0.1822 - val_accuracy_with_masking: 0.9383\n",
            "10000/10000 [==============================] - 6s 622us/step\n",
            "Test accuracy: [0.18353578412532806, 0.9377880000114441]\n",
            "[0.18353578412532806, 0.9377880000114441]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_16 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_14 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_14 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3456/10000 [=========>....................] - ETA: 4s - loss: 1.4258 - acc: 0.3786"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 446us/step - loss: 1.0047 - acc: 0.5875 - val_loss: 0.5779 - val_acc: 0.8041\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 0.4180 - acc: 0.8656 - val_loss: 0.3564 - val_acc: 0.8790\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 0.2868 - acc: 0.9041 - val_loss: 0.2933 - val_acc: 0.8915\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.2406 - acc: 0.9145 - val_loss: 0.2746 - val_acc: 0.8943\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.2184 - acc: 0.9196 - val_loss: 0.2708 - val_acc: 0.8949\n",
            "Epoch 6/10\n",
            " 7680/10000 [======================>.......] - ETA: 0s - loss: 0.1976 - acc: 0.9269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 256us/step - loss: 0.2054 - acc: 0.9231 - val_loss: 0.2728 - val_acc: 0.8953\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.1960 - acc: 0.9262 - val_loss: 0.2771 - val_acc: 0.8950\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 0.1881 - acc: 0.9290 - val_loss: 0.2813 - val_acc: 0.8952\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.1817 - acc: 0.9313 - val_loss: 0.2869 - val_acc: 0.8952\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.1761 - acc: 0.9335 - val_loss: 0.2912 - val_acc: 0.8947\n",
            "10000/10000 [==============================] - 1s 126us/step\n",
            "Test accuracy: [0.2903174907684326, 0.8954090016365052]\n",
            "[0.2903174907684326, 0.8954090016365052]\n",
            "Score:  [0.2903174907684326, 0.8954090016365052]\n",
            "SNRdB:  1.6666666666666679\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_14 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            "   64/10000 [..............................] - ETA: 4:13 - loss: 1.4112 - accuracy_with_masking: 0.1870"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 9s 932us/step - loss: 1.0064 - accuracy_with_masking: 0.6458 - val_loss: 0.6642 - val_accuracy_with_masking: 0.7967\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 731us/step - loss: 0.5553 - accuracy_with_masking: 0.8073 - val_loss: 0.4954 - val_accuracy_with_masking: 0.8139\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 744us/step - loss: 0.4753 - accuracy_with_masking: 0.8179 - val_loss: 0.4622 - val_accuracy_with_masking: 0.8219\n",
            "Epoch 4/5\n",
            " 6400/10000 [==================>...........] - ETA: 2s - loss: 0.4582 - accuracy_with_masking: 0.8229"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 738us/step - loss: 0.4562 - accuracy_with_masking: 0.8237 - val_loss: 0.4526 - val_accuracy_with_masking: 0.8254\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 733us/step - loss: 0.4504 - accuracy_with_masking: 0.8260 - val_loss: 0.4492 - val_accuracy_with_masking: 0.8267\n",
            "10000/10000 [==============================] - 6s 630us/step\n",
            "Test accuracy: [0.4474921380996704, 0.8268539992332459]\n",
            "[0.4474921380996704, 0.8268539992332459]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_17 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_15 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_15 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3072/10000 [========>.....................] - ETA: 5s - loss: 1.4930 - acc: 0.3502"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 460us/step - loss: 1.0657 - acc: 0.5508 - val_loss: 0.6818 - val_acc: 0.7374\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 265us/step - loss: 0.5564 - acc: 0.7891 - val_loss: 0.5290 - val_acc: 0.7894\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 263us/step - loss: 0.4670 - acc: 0.8174 - val_loss: 0.4979 - val_acc: 0.7996\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 262us/step - loss: 0.4373 - acc: 0.8276 - val_loss: 0.4918 - val_acc: 0.8038\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 0.4219 - acc: 0.8341 - val_loss: 0.4911 - val_acc: 0.8061\n",
            "Epoch 6/10\n",
            " 6656/10000 [==================>...........] - ETA: 0s - loss: 0.3920 - acc: 0.8471"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 264us/step - loss: 0.4092 - acc: 0.8397 - val_loss: 0.4903 - val_acc: 0.8081\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 0.3981 - acc: 0.8443 - val_loss: 0.4888 - val_acc: 0.8097\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 0.3889 - acc: 0.8479 - val_loss: 0.4873 - val_acc: 0.8111\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 0.3806 - acc: 0.8518 - val_loss: 0.4858 - val_acc: 0.8112\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 255us/step - loss: 0.3743 - acc: 0.8540 - val_loss: 0.4848 - val_acc: 0.8121\n",
            "10000/10000 [==============================] - 1s 126us/step\n",
            "Test accuracy: [0.48443298344612123, 0.8128626669883728]\n",
            "[0.48443298344612123, 0.8128626669883728]\n",
            "Score:  [0.48443298344612123, 0.8128626669883728]\n",
            "SNRdB:  -1.1111111111111107\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_15 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 1ms/step - loss: 1.0686 - accuracy_with_masking: 0.6092 - val_loss: 0.8204 - val_accuracy_with_masking: 0.6890\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 746us/step - loss: 0.7686 - accuracy_with_masking: 0.6923 - val_loss: 0.7464 - val_accuracy_with_masking: 0.6944\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 744us/step - loss: 0.7438 - accuracy_with_masking: 0.6955 - val_loss: 0.7401 - val_accuracy_with_masking: 0.6968\n",
            "Epoch 4/5\n",
            " 6272/10000 [=================>............] - ETA: 2s - loss: 0.7406 - accuracy_with_masking: 0.6967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 740us/step - loss: 0.7397 - accuracy_with_masking: 0.6972 - val_loss: 0.7372 - val_accuracy_with_masking: 0.6980\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 734us/step - loss: 0.7375 - accuracy_with_masking: 0.6980 - val_loss: 0.7354 - val_accuracy_with_masking: 0.6987\n",
            "10000/10000 [==============================] - 6s 629us/step\n",
            "Test accuracy: [0.7373781826019287, 0.6978483331680297]\n",
            "[0.7373781826019287, 0.6978483331680297]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_18 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_16 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_16 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3200/10000 [========>.....................] - ETA: 5s - loss: 1.5083 - acc: 0.3411"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.1691 - acc: 0.4915 - val_loss: 0.8717 - val_acc: 0.6322\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 0.7628 - acc: 0.6857 - val_loss: 0.7640 - val_acc: 0.6805\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.6986 - acc: 0.7140 - val_loss: 0.7459 - val_acc: 0.6920\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.6750 - acc: 0.7250 - val_loss: 0.7384 - val_acc: 0.6977\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.6562 - acc: 0.7337 - val_loss: 0.7318 - val_acc: 0.7010\n",
            "Epoch 6/10\n",
            " 7872/10000 [======================>.......] - ETA: 0s - loss: 0.6323 - acc: 0.7446"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 250us/step - loss: 0.6422 - acc: 0.7399 - val_loss: 0.7268 - val_acc: 0.7030\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 252us/step - loss: 0.6308 - acc: 0.7449 - val_loss: 0.7233 - val_acc: 0.7043\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 2s 250us/step - loss: 0.6228 - acc: 0.7483 - val_loss: 0.7208 - val_acc: 0.7055\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 2s 249us/step - loss: 0.6162 - acc: 0.7515 - val_loss: 0.7194 - val_acc: 0.7062\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 252us/step - loss: 0.6111 - acc: 0.7538 - val_loss: 0.7182 - val_acc: 0.7071\n",
            "10000/10000 [==============================] - 1s 128us/step\n",
            "Test accuracy: [0.7186088981628418, 0.7067906662940979]\n",
            "[0.7186088981628418, 0.7067906662940979]\n",
            "Score:  [0.7186088981628418, 0.7067906662940979]\n",
            "SNRdB:  -3.8888888888888893\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_16 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_16 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            "  128/10000 [..............................] - ETA: 2:38 - loss: 1.4105 - accuracy_with_masking: 0.2313"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 981us/step - loss: 1.1454 - accuracy_with_masking: 0.5191 - val_loss: 0.9786 - val_accuracy_with_masking: 0.5863\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 8s 754us/step - loss: 0.9698 - accuracy_with_masking: 0.5868 - val_loss: 0.9668 - val_accuracy_with_masking: 0.5878\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 748us/step - loss: 0.9661 - accuracy_with_masking: 0.5875 - val_loss: 0.9651 - val_accuracy_with_masking: 0.5882\n",
            "Epoch 4/5\n",
            " 6464/10000 [==================>...........] - ETA: 2s - loss: 0.9652 - accuracy_with_masking: 0.5875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 734us/step - loss: 0.9649 - accuracy_with_masking: 0.5877 - val_loss: 0.9643 - val_accuracy_with_masking: 0.5883\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 727us/step - loss: 0.9642 - accuracy_with_masking: 0.5879 - val_loss: 0.9637 - val_accuracy_with_masking: 0.5886\n",
            "10000/10000 [==============================] - 6s 633us/step\n",
            "Test accuracy: [0.964293137550354, 0.5880323347091675]\n",
            "[0.964293137550354, 0.5880323347091675]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_19 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_17 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_17 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3136/10000 [========>.....................] - ETA: 6s - loss: 1.5521 - acc: 0.3227"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 496us/step - loss: 1.2710 - acc: 0.4388 - val_loss: 1.0422 - val_acc: 0.5439\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 269us/step - loss: 0.9633 - acc: 0.5895 - val_loss: 0.9912 - val_acc: 0.5754\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 267us/step - loss: 0.9228 - acc: 0.6109 - val_loss: 0.9778 - val_acc: 0.5842\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 267us/step - loss: 0.8987 - acc: 0.6225 - val_loss: 0.9674 - val_acc: 0.5884\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 0.8807 - acc: 0.6302 - val_loss: 0.9614 - val_acc: 0.5907\n",
            "Epoch 6/10\n",
            " 7104/10000 [====================>.........] - ETA: 0s - loss: 0.8531 - acc: 0.6445"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.8676 - acc: 0.6367 - val_loss: 0.9568 - val_acc: 0.5924\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.8586 - acc: 0.6409 - val_loss: 0.9551 - val_acc: 0.5934\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 0.8517 - acc: 0.6444 - val_loss: 0.9538 - val_acc: 0.5938\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 0.8464 - acc: 0.6471 - val_loss: 0.9525 - val_acc: 0.5942\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 264us/step - loss: 0.8419 - acc: 0.6493 - val_loss: 0.9519 - val_acc: 0.5948\n",
            "10000/10000 [==============================] - 1s 129us/step\n",
            "Test accuracy: [0.9510939137458801, 0.5953286670684814]\n",
            "[0.9510939137458801, 0.5953286670684814]\n",
            "Score:  [0.9510939137458801, 0.5953286670684814]\n",
            "SNRdB:  -6.666666666666664\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_17 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_17 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 990us/step - loss: 1.1867 - accuracy_with_masking: 0.4752 - val_loss: 1.1302 - val_accuracy_with_masking: 0.4982\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 8s 765us/step - loss: 1.1310 - accuracy_with_masking: 0.4985 - val_loss: 1.1284 - val_accuracy_with_masking: 0.4992\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 8s 752us/step - loss: 1.1299 - accuracy_with_masking: 0.4989 - val_loss: 1.1276 - val_accuracy_with_masking: 0.4995\n",
            "Epoch 4/5\n",
            " 6400/10000 [==================>...........] - ETA: 2s - loss: 1.1296 - accuracy_with_masking: 0.4988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 749us/step - loss: 1.1293 - accuracy_with_masking: 0.4991 - val_loss: 1.1272 - val_accuracy_with_masking: 0.4996\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 745us/step - loss: 1.1290 - accuracy_with_masking: 0.4991 - val_loss: 1.1272 - val_accuracy_with_masking: 0.4995\n",
            "10000/10000 [==============================] - 6s 631us/step\n",
            "Test accuracy: [1.127930369758606, 0.49940366625785826]\n",
            "[1.127930369758606, 0.49940366625785826]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_20 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_18 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_18 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3072/10000 [========>.....................] - ETA: 6s - loss: 1.6031 - acc: 0.3023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 502us/step - loss: 1.3754 - acc: 0.3861 - val_loss: 1.2067 - val_acc: 0.4609\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 270us/step - loss: 1.1389 - acc: 0.5027 - val_loss: 1.1794 - val_acc: 0.4816\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 1.1046 - acc: 0.5204 - val_loss: 1.1648 - val_acc: 0.4879\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 262us/step - loss: 1.0795 - acc: 0.5318 - val_loss: 1.1535 - val_acc: 0.4909\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 1.0611 - acc: 0.5403 - val_loss: 1.1467 - val_acc: 0.4927\n",
            "Epoch 6/10\n",
            " 6656/10000 [==================>...........] - ETA: 0s - loss: 1.0310 - acc: 0.5568"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 260us/step - loss: 1.0479 - acc: 0.5468 - val_loss: 1.1428 - val_acc: 0.4941\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 263us/step - loss: 1.0387 - acc: 0.5520 - val_loss: 1.1408 - val_acc: 0.4953\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 264us/step - loss: 1.0323 - acc: 0.5551 - val_loss: 1.1396 - val_acc: 0.4952\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 1.0274 - acc: 0.5581 - val_loss: 1.1392 - val_acc: 0.4957\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 1.0234 - acc: 0.5600 - val_loss: 1.1388 - val_acc: 0.4958\n",
            "10000/10000 [==============================] - 1s 131us/step\n",
            "Test accuracy: [1.1395581382751465, 0.4949363323688507]\n",
            "[1.1395581382751465, 0.4949363323688507]\n",
            "Score:  [1.1395581382751465, 0.4949363323688507]\n",
            "SNRdB:  -9.444444444444443\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_18 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_18 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 999us/step - loss: 1.2865 - accuracy_with_masking: 0.3941 - val_loss: 1.2375 - val_accuracy_with_masking: 0.4314\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 738us/step - loss: 1.2385 - accuracy_with_masking: 0.4300 - val_loss: 1.2365 - val_accuracy_with_masking: 0.4317\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 731us/step - loss: 1.2379 - accuracy_with_masking: 0.4302 - val_loss: 1.2363 - val_accuracy_with_masking: 0.4315\n",
            "Epoch 4/5\n",
            " 6528/10000 [==================>...........] - ETA: 2s - loss: 1.2377 - accuracy_with_masking: 0.4302"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 733us/step - loss: 1.2375 - accuracy_with_masking: 0.4305 - val_loss: 1.2359 - val_accuracy_with_masking: 0.4316\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 732us/step - loss: 1.2373 - accuracy_with_masking: 0.4304 - val_loss: 1.2357 - val_accuracy_with_masking: 0.4317\n",
            "10000/10000 [==============================] - 6s 627us/step\n",
            "Test accuracy: [1.23712708568573, 0.4304360004901886]\n",
            "[1.23712708568573, 0.4304360004901886]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_21 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_19 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_19 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3392/10000 [=========>....................] - ETA: 6s - loss: 1.6253 - acc: 0.2887"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.4664 - acc: 0.3387 - val_loss: 1.3437 - val_acc: 0.3858\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 263us/step - loss: 1.2751 - acc: 0.4291 - val_loss: 1.3164 - val_acc: 0.4037\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 267us/step - loss: 1.2377 - acc: 0.4469 - val_loss: 1.3005 - val_acc: 0.4081\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 268us/step - loss: 1.2111 - acc: 0.4580 - val_loss: 1.2869 - val_acc: 0.4115\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 1.1903 - acc: 0.4675 - val_loss: 1.2790 - val_acc: 0.4133\n",
            "Epoch 6/10\n",
            " 6272/10000 [=================>............] - ETA: 0s - loss: 1.1573 - acc: 0.4872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 263us/step - loss: 1.1758 - acc: 0.4752 - val_loss: 1.2749 - val_acc: 0.4132\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 1.1660 - acc: 0.4812 - val_loss: 1.2725 - val_acc: 0.4143\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 261us/step - loss: 1.1593 - acc: 0.4853 - val_loss: 1.2717 - val_acc: 0.4140\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 265us/step - loss: 1.1542 - acc: 0.4885 - val_loss: 1.2712 - val_acc: 0.4144\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 1.1506 - acc: 0.4907 - val_loss: 1.2706 - val_acc: 0.4147\n",
            "10000/10000 [==============================] - 1s 126us/step\n",
            "Test accuracy: [1.270323971748352, 0.41470799922943113]\n",
            "[1.270323971748352, 0.41470799922943113]\n",
            "Score:  [1.270323971748352, 0.41470799922943113]\n",
            "SNRdB:  -12.222222222222221\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_19 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_19 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 1ms/step - loss: 1.3188 - accuracy_with_masking: 0.3646 - val_loss: 1.3035 - val_accuracy_with_masking: 0.3797\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 740us/step - loss: 1.3037 - accuracy_with_masking: 0.3791 - val_loss: 1.3030 - val_accuracy_with_masking: 0.3798\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 729us/step - loss: 1.3033 - accuracy_with_masking: 0.3792 - val_loss: 1.3027 - val_accuracy_with_masking: 0.3797\n",
            "Epoch 4/5\n",
            " 6656/10000 [==================>...........] - ETA: 2s - loss: 1.3029 - accuracy_with_masking: 0.3794"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 725us/step - loss: 1.3031 - accuracy_with_masking: 0.3792 - val_loss: 1.3029 - val_accuracy_with_masking: 0.3797\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 727us/step - loss: 1.3030 - accuracy_with_masking: 0.3793 - val_loss: 1.3024 - val_accuracy_with_masking: 0.3801\n",
            "10000/10000 [==============================] - 6s 622us/step\n",
            "Test accuracy: [1.3027780340194701, 0.3796153338432312]\n",
            "[1.3027780340194701, 0.3796153338432312]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_22 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_20 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_20 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3520/10000 [=========>....................] - ETA: 5s - loss: 1.6541 - acc: 0.2785"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 514us/step - loss: 1.5197 - acc: 0.3120 - val_loss: 1.4193 - val_acc: 0.3417\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 1.3572 - acc: 0.3801 - val_loss: 1.4032 - val_acc: 0.3483\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 255us/step - loss: 1.3249 - acc: 0.3927 - val_loss: 1.3854 - val_acc: 0.3515\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 1.2959 - acc: 0.4041 - val_loss: 1.3708 - val_acc: 0.3531\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 252us/step - loss: 1.2729 - acc: 0.4150 - val_loss: 1.3613 - val_acc: 0.3550\n",
            "Epoch 6/10\n",
            " 7616/10000 [=====================>........] - ETA: 0s - loss: 1.2463 - acc: 0.4313"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 255us/step - loss: 1.2563 - acc: 0.4240 - val_loss: 1.3554 - val_acc: 0.3550\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 256us/step - loss: 1.2452 - acc: 0.4312 - val_loss: 1.3526 - val_acc: 0.3556\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 252us/step - loss: 1.2378 - acc: 0.4361 - val_loss: 1.3515 - val_acc: 0.3563\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 255us/step - loss: 1.2328 - acc: 0.4395 - val_loss: 1.3510 - val_acc: 0.3562\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 1.2291 - acc: 0.4421 - val_loss: 1.3507 - val_acc: 0.3564\n",
            "10000/10000 [==============================] - 1s 125us/step\n",
            "Test accuracy: [1.3500991216659546, 0.3564630001544952]\n",
            "[1.3500991216659546, 0.3564630001544952]\n",
            "Score:  [1.3500991216659546, 0.3564630001544952]\n",
            "SNRdB:  -15.0\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_20 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_20 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,204\n",
            "Trainable params: 4,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            "   64/10000 [..............................] - ETA: 6:00 - loss: 1.4401 - accuracy_with_masking: 0.2428"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 1ms/step - loss: 1.3521 - accuracy_with_masking: 0.3297 - val_loss: 1.3419 - val_accuracy_with_masking: 0.3422\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 7s 725us/step - loss: 1.3415 - accuracy_with_masking: 0.3426 - val_loss: 1.3413 - val_accuracy_with_masking: 0.3422\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 7s 727us/step - loss: 1.3411 - accuracy_with_masking: 0.3427 - val_loss: 1.3410 - val_accuracy_with_masking: 0.3429\n",
            "Epoch 4/5\n",
            " 6784/10000 [===================>..........] - ETA: 2s - loss: 1.3409 - accuracy_with_masking: 0.3430"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 726us/step - loss: 1.3410 - accuracy_with_masking: 0.3429 - val_loss: 1.3409 - val_accuracy_with_masking: 0.3427\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 7s 729us/step - loss: 1.3408 - accuracy_with_masking: 0.3429 - val_loss: 1.3408 - val_accuracy_with_masking: 0.3423\n",
            "10000/10000 [==============================] - 6s 629us/step\n",
            "Test accuracy: [1.340877728843689, 0.34256100015640256]\n",
            "[1.340877728843689, 0.34256100015640256]\n",
            "x_train shape:  (10000, 302, 2)\n",
            "y_train shape:  (10000, 300)\n",
            "y_train shape, one-hot:  (10000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (10000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_23 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_21 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_21 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            " 3584/10000 [=========>....................] - ETA: 5s - loss: 1.6852 - acc: 0.2656"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 526us/step - loss: 1.5647 - acc: 0.2858 - val_loss: 1.4688 - val_acc: 0.3056\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 1.4093 - acc: 0.3445 - val_loss: 1.4544 - val_acc: 0.3092\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 1.3772 - acc: 0.3554 - val_loss: 1.4358 - val_acc: 0.3117\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 1.3475 - acc: 0.3666 - val_loss: 1.4201 - val_acc: 0.3135\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 3s 260us/step - loss: 1.3229 - acc: 0.3780 - val_loss: 1.4092 - val_acc: 0.3143\n",
            "Epoch 6/10\n",
            " 7040/10000 [====================>.........] - ETA: 0s - loss: 1.2913 - acc: 0.3988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 264us/step - loss: 1.3047 - acc: 0.3881 - val_loss: 1.4021 - val_acc: 0.3151\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 3s 255us/step - loss: 1.2924 - acc: 0.3961 - val_loss: 1.3982 - val_acc: 0.3151\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 1.2842 - acc: 0.4020 - val_loss: 1.3969 - val_acc: 0.3148\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 1.2788 - acc: 0.4061 - val_loss: 1.3961 - val_acc: 0.3151\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 1.2752 - acc: 0.4090 - val_loss: 1.3957 - val_acc: 0.3154\n",
            "10000/10000 [==============================] - 1s 128us/step\n",
            "Test accuracy: [1.395415417289734, 0.3151966672897339]\n",
            "[1.395415417289734, 0.3151966672897339]\n",
            "Score:  [1.395415417289734, 0.3151966672897339]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5D1bKi4zMVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "8c60e676-d2a9-4d2e-ea7d-9c59a56271dc"
      },
      "cell_type": "code",
      "source": [
        "s_lstm = np.array(scores_lstm)\n",
        "s_conv = np.array(scores_conv)\n",
        "s_lms = 1-np.array([0,0.06,3.49,20.42,42.74,57.27,66.08,71.97,74.61,74.54])*1.0/100\n",
        "plt.plot(snrs,s_conv[:,1],\"r\",label=\"Conv\")\n",
        "plt.plot(snrs,s_lstm[:,1],\"b\",label=\"LSTM\")\n",
        "plt.plot(snrs,s_lms,\"y\",label=\"LMS\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"SNR\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs SNR: Time Invariant\")\n",
        "\n",
        "from google.colab import files\n",
        "plt.savefig('SNR_time_invariant.png')\n",
        "files.download('SNR_time_invariant.png')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f47b8f57630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hDTFHQj9mOvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Time-Varying Channel"
      ]
    },
    {
      "metadata": {
        "id": "QTJRbvO9BkOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sim_channel_multi(m,sequenceLen,trials,Noise,SNRdB,h_list,channel_dur):\n",
        "  \"\"\"\n",
        "  Simulates a channel\n",
        "  Input:\n",
        "    m - order of modulation\n",
        "    sequenceLen - lenght of sequence\n",
        "    trials - number trials\n",
        "    Noise - Boolean, if noise should be added\n",
        "    SNRdB - Ratio of signal to noise\n",
        "    h_list- list of channel parameters for different channels\n",
        "    channel_dur - duration of channel before switch\n",
        "  \"\"\"\n",
        "  [x,y] = qammod2(m,sequenceLen,trials)\n",
        "  distortedChannels = []\n",
        "  for i in range(len(h_list)):\n",
        "    distortedChannels.append(np.apply_along_axis(lambda q: np.convolve(q,h_list[i,:],mode=\"full\"),axis = 1,arr = x))\n",
        "   \n",
        "  size = distortedChannels[0].shape[1]\n",
        "  i = 0\n",
        "  select = np.random.randint(len(h_list))\n",
        "  selected_stream = distortedChannels[select]\n",
        "  length = channel_dur\n",
        "  if(i + length >= size):\n",
        "    length = size - i\n",
        "  xh = selected_stream[:,i:i+length,:]\n",
        "  i = i + length\n",
        "  while(i < size):\n",
        "    select = np.random.randint(len(h_list))\n",
        "    selected_stream = distortedChannels[select]\n",
        "    length = channel_dur\n",
        "    if(i + length >= size):\n",
        "      length = size - i\n",
        "    chunk = selected_stream[:,i:i+length,:]\n",
        "    xh = np.concatenate((xh, chunk),axis = 1)\n",
        "    i = i + length\n",
        "    \n",
        "  if(Noise):\n",
        "    SNR = 10**(SNRdB/10)\n",
        "    sym_noise_pow = np.var(xh)/SNR\n",
        "    sym_noise_scale_fact = np.sqrt(sym_noise_pow/2)\n",
        "    AWGN = sym_noise_scale_fact*np.random.normal(1, size=xh.shape) \n",
        "    xh = xh + AWGN\n",
        "  return [xh ,y ]\n",
        "\n",
        "\n",
        "def generateData_multi(m,sequenceLen,trials,Noise,SNRdB,h_list,channel_dur,padding=True,window=False,window_size = 10):\n",
        "  \"\"\"\n",
        "  h_list = List of channel parameters \n",
        "  \"\"\"\n",
        "  data={}\n",
        "  x_train,y_train = sim_channel_multi(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,h_list=h_list,channel_dur=channel_dur)\n",
        "  x_val,y_val= sim_channel_multi(m=m,sequenceLen=sequenceLen,trials=int(trials*0.5),Noise= Noise,SNRdB=SNRdB,h_list=h_list,channel_dur=channel_dur)\n",
        "  x_test,y_test= sim_channel_multi(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,h_list=h_list,channel_dur=channel_dur)\n",
        "  \n",
        "  print(\"x_train shape: \",x_train.shape) # data, expected seqlen+chanelLen-1\n",
        "  print(\"y_train shape: \",y_train.shape) # labels\n",
        "  \n",
        "  #One hot encoding\n",
        "  y_train = keras.utils.to_categorical(y_train , num_classes=m)\n",
        "  y_val = keras.utils.to_categorical(y_val , num_classes=m)\n",
        "  y_test = keras.utils.to_categorical(y_test , num_classes=m)\n",
        "  print(\"y_train shape, one-hot: \",y_train.shape)\n",
        "\n",
        "  #Padding \n",
        "  if(padding):\n",
        "    y_train = np.pad(y_train,((0,0),(0,chanelLen-1),(0,0)),\"constant\")\n",
        "    y_val = np.pad(y_val,((0,0),(0,chanelLen-1),(0,0)),\"constant\")\n",
        "    y_test = np.pad(y_test,((0,0),(0,chanelLen-1),(0,0)),\"constant\")\n",
        "    print(\"y_train shape, one-hot, padding: \",y_train.shape)\n",
        "  \n",
        "  #Windowing\n",
        "  if(window):\n",
        "    x_train = windowing(x_train,window_size)\n",
        "    x_val = windowing(x_val,window_size)\n",
        "    x_test = windowing(x_test,window_size)\n",
        "    print(\"x_train shape, window: \",x_train.shape)\n",
        "    \n",
        "  default_data = {\n",
        "    'x_train': x_train,\n",
        "    'x_val': x_val,\n",
        "    'x_test': x_test,\n",
        "    'y_train': y_train,\n",
        "    'y_val': y_val,\n",
        "    'y_test': y_test,\n",
        "  }\n",
        "  return default_data\n",
        " \n",
        "def windowing(x,window_size):\n",
        "  \"\"\"\n",
        "  x - input data of dimension (trials,timestep,features)\n",
        "  Will pad windows with zero \n",
        "  \"\"\"\n",
        "  trials, timestep, features = x.shape\n",
        "  out = np.empty((trials,timestep,window_size*features))\n",
        "  xpad = np.pad(x,((0,0),(0,window_size+1),(0,0)),\"constant\")\n",
        "  for i in range(timestep):\n",
        "    out[:,i] = np.reshape(xpad[:,i:i+window_size],(trials,window_size*features))\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NR55JyWohgD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "526bd622-09ff-421f-92be-71569b872dfa"
      },
      "cell_type": "code",
      "source": [
        "# Instantiating Data\n",
        "\n",
        "m = 4         # order of modulation\n",
        "trials = 10000 # number of trials \n",
        "Noise = True\n",
        "SNRdB = 5\n",
        "seqLen = 300\n",
        "print(seqLen)\n",
        "h_list = []\n",
        "h_list.append(np.array([1,0.5,-0.3]))\n",
        "h_list.append(np.array([1,-.5,-0.5]))\n",
        "h_list.append(np.array([1,-0.25,-0.25]))\n",
        "h_list = np.array(h_list)\n",
        "chanelLen = len(h_list[0])\n",
        "#chanelLen = 5\n",
        "# h_list = np.random.rand(3,chanelLen)\n",
        "# h_list[:,0] = 1\n",
        "channel_dur = 75\n",
        "print(h_list)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "[[ 1.    0.5  -0.3 ]\n",
            " [ 1.   -0.5  -0.5 ]\n",
            " [ 1.   -0.25 -0.25]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGVMP0Kwhi8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# QAM-4\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense,CuDNNLSTM, TimeDistributed,Bidirectional,BatchNormalization,Dropout,Conv1D, Flatten, Reshape,Softmax\n",
        "from keras import optimizers\n",
        "import keras\n",
        "\n",
        "#LSTM no windwod\n",
        "def LSTM_variant_no_window():\n",
        "  data = generateData_multi(m,seqLen,trials,Noise,SNRdB,h_list,channel_dur,padding=True)\n",
        "  modLSTM = Sequential()\n",
        "  #modLSTM.add(Bidirectional(CuDNNLSTM(10,return_sequences=True),input_shape=(seqLen+chanelLen-1,2)))\n",
        "  modLSTM.add(CuDNNLSTM(30,return_sequences=True,input_shape=(seqLen+chanelLen-1,2)))\n",
        "  #modLSTM.add(TimeDistributed(Dense(30,activation=\"tanh\")))\n",
        "  modLSTM.add(TimeDistributed(BatchNormalization()))\n",
        "  modLSTM.add(TimeDistributed(Dense(m,activation=\"softmax\")))\n",
        "  #return try_model_lstm(modLSTM, default_data_pad, epochs=10)\n",
        "  \n",
        "  #Training\n",
        "  epochs = 20\n",
        "  verbose = True\n",
        "  reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy_with_masking', factor=0.2,\n",
        "                              patience=3,verbose=verbose)\n",
        "\n",
        "  opt = optimizers.Nadam()\n",
        "  modLSTM.compile(optimizer= opt,\n",
        "            loss=categorical_crossentropy_with_masking,\n",
        "            metrics=[accuracy_with_masking])\n",
        "\n",
        "  modLSTM.summary()  \n",
        "  history = modLSTM.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=int(0.1*trials), verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']),\n",
        "                     callbacks=[reduce_lr])  \n",
        "  score = modLSTM.evaluate(data['x_test'], data['y_test'],batch_size = 1000)\n",
        "  return history,score\n",
        "\n",
        "#hist1, score1 = LSTM_variant_no_window() \n",
        "\n",
        "\n",
        "def LSTM_variant_with_window():\n",
        "  window_size = chanelLen+2\n",
        "  data = generateData_multi(m,seqLen,trials,Noise,SNRdB,h_list,channel_dur,padding=True,window=True,window_size=window_size)\n",
        "  modLSTM = Sequential()\n",
        "  modLSTM.add(CuDNNLSTM(40,return_sequences=True,input_shape=(seqLen+chanelLen-1,window_size*2),\n",
        "                        recurrent_regularizer =regularizers.l1(0.0001),kernel_regularizer = regularizers.l2(0.001)))\n",
        "#   modLSTM.add(CuDNNLSTM(50,return_sequences=True,input_shape=(seqLen+chanelLen-1,window_size*2),\n",
        "#                         recurrent_regularizer =regularizers.l1(0.0001),kernel_regularizer = regularizers.l2(0.0001)))\n",
        "  #modLSTM.add(TimeDistributed(BatchNormalization()))\n",
        "  #modLSTM.add(TimeDistributed(Dense(30,activation=\"tanh\")))\n",
        "  #modLSTM.add(TimeDistributed(BatchNormalization()))\n",
        "  #modLSTM.add(TimeDistributed(Dropout(0.2)))\n",
        "  modLSTM.add(TimeDistributed(Dense(m,activation=\"softmax\")))\n",
        "  #return try_model_lstm(modLSTM, default_data_pad, epochs=10)\n",
        "\n",
        "  #Training\n",
        "  epochs = 20\n",
        "  verbose = True\n",
        "  reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy_with_masking', factor=0.2,\n",
        "                              patience=3,verbose=verbose)\n",
        "  \n",
        "  opt = optimizers.Nadam()\n",
        "  modLSTM.compile(optimizer= opt,\n",
        "            loss=categorical_crossentropy_with_masking,\n",
        "            metrics=[accuracy_with_masking])\n",
        "\n",
        "  modLSTM.summary()  \n",
        "  history = modLSTM.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=int(0.1*trials), verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']),\n",
        "                     callbacks=[reduce_lr])  \n",
        "  score = modLSTM.evaluate(data['x_test'], data['y_test'],batch_size = 1000)\n",
        "  return history,score\n",
        "\n",
        "#hist2, score2 = LSTM_variant_with_window()  \n",
        "\n",
        "def ConvNet_variant():\n",
        "  data = generateData_multi(m,seqLen,trials,Noise,SNRdB,h_list,channel_dur,padding=False)\n",
        "  modCNN = Sequential()\n",
        "  modCNN.add(Conv1D(10,kernel_size=(chanelLen), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "  modCNN.add(BatchNormalization())\n",
        "  modCNN.add(Flatten())\n",
        "  modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "  modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "  modCNN.add(Softmax(axis=2))\n",
        "  return try_model_conv(modCNN, data, epochs=20)\n",
        "\n",
        "#hist3, score3 = ConvNet_variant()  \n",
        "# print(\"Conv: \", score3)\n",
        "# print(\"No Window: \", score1)\n",
        "# print(\"With Window: \", score2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-EYreLafsjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32541
        },
        "outputId": "a85d0ed4-30ab-44cd-c1ca-91cdeebf7337"
      },
      "cell_type": "code",
      "source": [
        "m = 4         # order of modulation\n",
        "trials = 15000   # number of trials \n",
        "Noise = True\n",
        "seqLen = 300\n",
        "print(seqLen)\n",
        "h_list = []\n",
        "h_list.append(np.array([1,0.5,-0.3]))\n",
        "h_list.append(np.array([1,-.5,-0.5]))\n",
        "h_list.append(np.array([1,-0.25,-0.25]))\n",
        "# h_list.append(np.array([1,0.5,-0.3,.2,.1]))\n",
        "# h_list.append(np.array([1,-.5,-0.5,.4,.1]))\n",
        "# h_list.append(np.array([1,-0.25,-0.25,-.1, 0.7]))\n",
        "h_list = np.array(h_list)\n",
        "chanelLen = len(h_list[0])\n",
        "channel_dur = 75\n",
        "print(\"Channel: \",h_list)\n",
        "\n",
        "snrs = np.linspace(10,-15,10)\n",
        "histories_lstm2 = []\n",
        "scores_lstm2 = []\n",
        "histories_lstm2_W = []\n",
        "scores_lstm2_W = []\n",
        "histories_conv2 = []\n",
        "scores_conv2 = []\n",
        "for SNRdB in snrs:\n",
        "  print(\"SNRdB: \",SNRdB)\n",
        "\n",
        "  #LSTM no window\n",
        "  hist,score = LSTM_variant_no_window()\n",
        "  histories_lstm2.append(hist)\n",
        "  scores_lstm2.append(score)\n",
        "  print(\"Score: \",score)\n",
        "  #LSTM with window\n",
        "  hist,score = LSTM_variant_with_window()\n",
        "  histories_lstm2_W.append(hist)\n",
        "  scores_lstm2_W.append(score)\n",
        "  print(\"Score: \",score)\n",
        "  #CNN\n",
        "  hist,score = ConvNet_variant()\n",
        "  histories_conv2.append(hist)\n",
        "  scores_conv2.append(score)\n",
        "  print(\"Score: \",score)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "Channel:  [[ 1.    0.5  -0.3 ]\n",
            " [ 1.   -0.5  -0.5 ]\n",
            " [ 1.   -0.25 -0.25]]\n",
            "SNRdB:  10.0\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 246us/step - loss: 1.0302 - accuracy_with_masking: 0.5886 - val_loss: 0.7766 - val_accuracy_with_masking: 0.6967\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.5223 - accuracy_with_masking: 0.8798 - val_loss: 0.4399 - val_accuracy_with_masking: 0.8360\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.3163 - accuracy_with_masking: 0.9298 - val_loss: 0.3189 - val_accuracy_with_masking: 0.9021\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.2470 - accuracy_with_masking: 0.9399 - val_loss: 0.2876 - val_accuracy_with_masking: 0.9006\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.2126 - accuracy_with_masking: 0.9437 - val_loss: 0.2645 - val_accuracy_with_masking: 0.9047\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1912 - accuracy_with_masking: 0.9466 - val_loss: 0.2459 - val_accuracy_with_masking: 0.9099\n",
            "Epoch 7/20\n",
            " 1500/15000 [==>...........................] - ETA: 1s - loss: 0.1824 - accuracy_with_masking: 0.9476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.1759 - accuracy_with_masking: 0.9492 - val_loss: 0.2287 - val_accuracy_with_masking: 0.9162\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1641 - accuracy_with_masking: 0.9516 - val_loss: 0.2158 - val_accuracy_with_masking: 0.9205\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1543 - accuracy_with_masking: 0.9540 - val_loss: 0.2017 - val_accuracy_with_masking: 0.9264\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1462 - accuracy_with_masking: 0.9561 - val_loss: 0.1916 - val_accuracy_with_masking: 0.9302\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1393 - accuracy_with_masking: 0.9579 - val_loss: 0.1819 - val_accuracy_with_masking: 0.9341\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1334 - accuracy_with_masking: 0.9594 - val_loss: 0.1744 - val_accuracy_with_masking: 0.9370\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.1285 - accuracy_with_masking: 0.9605 - val_loss: 0.1692 - val_accuracy_with_masking: 0.9386\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1243 - accuracy_with_masking: 0.9614 - val_loss: 0.1634 - val_accuracy_with_masking: 0.9407\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.1208 - accuracy_with_masking: 0.9620 - val_loss: 0.1583 - val_accuracy_with_masking: 0.9427\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1178 - accuracy_with_masking: 0.9624 - val_loss: 0.1548 - val_accuracy_with_masking: 0.9438\n",
            "Epoch 17/20\n",
            " 7500/15000 [==============>...............] - ETA: 0s - loss: 0.1161 - accuracy_with_masking: 0.9625"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.1152 - accuracy_with_masking: 0.9627 - val_loss: 0.1523 - val_accuracy_with_masking: 0.9443\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.1129 - accuracy_with_masking: 0.9630 - val_loss: 0.1506 - val_accuracy_with_masking: 0.9446\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1109 - accuracy_with_masking: 0.9633 - val_loss: 0.1484 - val_accuracy_with_masking: 0.9451\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1090 - accuracy_with_masking: 0.9635 - val_loss: 0.1470 - val_accuracy_with_masking: 0.9453\n",
            "15000/15000 [==============================] - 1s 38us/step\n",
            "Score:  [0.1916435847679774, 0.9250955581665039]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 176us/step - loss: 1.3771 - accuracy_with_masking: 0.3982 - val_loss: 1.2771 - val_accuracy_with_masking: 0.5269\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 134us/step - loss: 1.2016 - accuracy_with_masking: 0.6567 - val_loss: 1.0975 - val_accuracy_with_masking: 0.6418\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.0039 - accuracy_with_masking: 0.7800 - val_loss: 0.9283 - val_accuracy_with_masking: 0.7083\n",
            "Epoch 4/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.8627 - accuracy_with_masking: 0.8214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.8299 - accuracy_with_masking: 0.8312 - val_loss: 0.7802 - val_accuracy_with_masking: 0.7687\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6855 - accuracy_with_masking: 0.8681 - val_loss: 0.6646 - val_accuracy_with_masking: 0.8210\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.5704 - accuracy_with_masking: 0.9003 - val_loss: 0.5707 - val_accuracy_with_masking: 0.8639\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4809 - accuracy_with_masking: 0.9233 - val_loss: 0.4966 - val_accuracy_with_masking: 0.8932\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4104 - accuracy_with_masking: 0.9400 - val_loss: 0.4375 - val_accuracy_with_masking: 0.9137\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.3589 - accuracy_with_masking: 0.9509 - val_loss: 0.3902 - val_accuracy_with_masking: 0.9290\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.3211 - accuracy_with_masking: 0.9583 - val_loss: 0.3535 - val_accuracy_with_masking: 0.9393\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.2931 - accuracy_with_masking: 0.9627 - val_loss: 0.3254 - val_accuracy_with_masking: 0.9458\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2713 - accuracy_with_masking: 0.9656 - val_loss: 0.3033 - val_accuracy_with_masking: 0.9503\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.2538 - accuracy_with_masking: 0.9677 - val_loss: 0.2848 - val_accuracy_with_masking: 0.9541\n",
            "Epoch 14/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.2418 - accuracy_with_masking: 0.9692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2393 - accuracy_with_masking: 0.9694 - val_loss: 0.2697 - val_accuracy_with_masking: 0.9568\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 138us/step - loss: 0.2271 - accuracy_with_masking: 0.9709 - val_loss: 0.2568 - val_accuracy_with_masking: 0.9591\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2166 - accuracy_with_masking: 0.9722 - val_loss: 0.2456 - val_accuracy_with_masking: 0.9611\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.2073 - accuracy_with_masking: 0.9734 - val_loss: 0.2352 - val_accuracy_with_masking: 0.9631\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.1990 - accuracy_with_masking: 0.9745 - val_loss: 0.2269 - val_accuracy_with_masking: 0.9645\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.1927 - accuracy_with_masking: 0.9750 - val_loss: 0.2195 - val_accuracy_with_masking: 0.9655\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.1854 - accuracy_with_masking: 0.9762 - val_loss: 0.2118 - val_accuracy_with_masking: 0.9670\n",
            "15000/15000 [==============================] - 1s 52us/step\n",
            "Score:  [0.18324929475784302, 0.9774977803230286]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_1 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            " 5500/15000 [==========>...................] - ETA: 1s - loss: 1.4009 - acc: 0.3786"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 143us/step - loss: 1.0137 - acc: 0.5925 - val_loss: 0.7439 - val_acc: 0.7194\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.3419 - acc: 0.9389 - val_loss: 0.4880 - val_acc: 0.8162\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.1563 - acc: 0.9844 - val_loss: 0.4204 - val_acc: 0.8348\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.0921 - acc: 0.9922 - val_loss: 0.4034 - val_acc: 0.8402\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0629 - acc: 0.9948 - val_loss: 0.4030 - val_acc: 0.8422\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0468 - acc: 0.9961 - val_loss: 0.4095 - val_acc: 0.8428\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0367 - acc: 0.9970 - val_loss: 0.4199 - val_acc: 0.8428\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.0299 - acc: 0.9975 - val_loss: 0.4320 - val_acc: 0.8424\n",
            "Epoch 9/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 0.0223 - acc: 0.9990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0249 - acc: 0.9979 - val_loss: 0.4446 - val_acc: 0.8421\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0212 - acc: 0.9982 - val_loss: 0.4578 - val_acc: 0.8416\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0184 - acc: 0.9985 - val_loss: 0.4697 - val_acc: 0.8413\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0160 - acc: 0.9987 - val_loss: 0.4827 - val_acc: 0.8408\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.0140 - acc: 0.9989 - val_loss: 0.4947 - val_acc: 0.8406\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0124 - acc: 0.9990 - val_loss: 0.5061 - val_acc: 0.8406\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0110 - acc: 0.9992 - val_loss: 0.5173 - val_acc: 0.8402\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0098 - acc: 0.9993 - val_loss: 0.5273 - val_acc: 0.8400\n",
            "Epoch 17/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 0.0073 - acc: 0.9997"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0088 - acc: 0.9994 - val_loss: 0.5382 - val_acc: 0.8396\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0079 - acc: 0.9994 - val_loss: 0.5477 - val_acc: 0.8396\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0071 - acc: 0.9995 - val_loss: 0.5571 - val_acc: 0.8395\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0064 - acc: 0.9995 - val_loss: 0.5669 - val_acc: 0.8393\n",
            "15000/15000 [==============================] - 2s 114us/step\n",
            "Test accuracy: [0.8874354990005493, 0.7673366653442383]\n",
            "Score:  [0.8874354990005493, 0.7673366653442383]\n",
            "SNRdB:  7.222222222222222\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 164us/step - loss: 1.5177 - accuracy_with_masking: 0.2858 - val_loss: 0.9493 - val_accuracy_with_masking: 0.6011\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.6107 - accuracy_with_masking: 0.8849 - val_loss: 0.5680 - val_accuracy_with_masking: 0.8049\n",
            "Epoch 3/20\n",
            " 7500/15000 [==============>...............] - ETA: 0s - loss: 0.4333 - accuracy_with_masking: 0.9505"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4030 - accuracy_with_masking: 0.9542 - val_loss: 0.4984 - val_accuracy_with_masking: 0.8210\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.3120 - accuracy_with_masking: 0.9614 - val_loss: 0.4741 - val_accuracy_with_masking: 0.8216\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.2581 - accuracy_with_masking: 0.9637 - val_loss: 0.4572 - val_accuracy_with_masking: 0.8236\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.2222 - accuracy_with_masking: 0.9651 - val_loss: 0.4417 - val_accuracy_with_masking: 0.8279\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1964 - accuracy_with_masking: 0.9664 - val_loss: 0.4317 - val_accuracy_with_masking: 0.8314\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1769 - accuracy_with_masking: 0.9675 - val_loss: 0.4209 - val_accuracy_with_masking: 0.8359\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1617 - accuracy_with_masking: 0.9685 - val_loss: 0.4112 - val_accuracy_with_masking: 0.8401\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1494 - accuracy_with_masking: 0.9695 - val_loss: 0.4057 - val_accuracy_with_masking: 0.8428\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.1393 - accuracy_with_masking: 0.9703 - val_loss: 0.4009 - val_accuracy_with_masking: 0.8452\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.1309 - accuracy_with_masking: 0.9710 - val_loss: 0.3974 - val_accuracy_with_masking: 0.8472\n",
            "Epoch 13/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.1250 - accuracy_with_masking: 0.9716"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.1237 - accuracy_with_masking: 0.9717 - val_loss: 0.3947 - val_accuracy_with_masking: 0.8489\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1177 - accuracy_with_masking: 0.9722 - val_loss: 0.3968 - val_accuracy_with_masking: 0.8494\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1125 - accuracy_with_masking: 0.9727 - val_loss: 0.3967 - val_accuracy_with_masking: 0.8504\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1080 - accuracy_with_masking: 0.9731 - val_loss: 0.3990 - val_accuracy_with_masking: 0.8509\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.1041 - accuracy_with_masking: 0.9734 - val_loss: 0.3989 - val_accuracy_with_masking: 0.8517\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.1007 - accuracy_with_masking: 0.9737 - val_loss: 0.4016 - val_accuracy_with_masking: 0.8519\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.0977 - accuracy_with_masking: 0.9739 - val_loss: 0.4036 - val_accuracy_with_masking: 0.8524\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.0951 - accuracy_with_masking: 0.9741 - val_loss: 0.4071 - val_accuracy_with_masking: 0.8524\n",
            "15000/15000 [==============================] - 1s 39us/step\n",
            "Score:  [0.37522029081980385, 0.8564502278963725]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_4 (CuDNNLSTM)     (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "12000/15000 [=======================>......] - ETA: 0s - loss: 1.3340 - accuracy_with_masking: 0.4381"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 3s 185us/step - loss: 1.3218 - accuracy_with_masking: 0.4596 - val_loss: 1.2732 - val_accuracy_with_masking: 0.5563\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.1923 - accuracy_with_masking: 0.6131 - val_loss: 1.1227 - val_accuracy_with_masking: 0.6736\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.0183 - accuracy_with_masking: 0.6932 - val_loss: 0.9443 - val_accuracy_with_masking: 0.7351\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.8466 - accuracy_with_masking: 0.7625 - val_loss: 0.8063 - val_accuracy_with_masking: 0.7702\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.7199 - accuracy_with_masking: 0.8080 - val_loss: 0.7025 - val_accuracy_with_masking: 0.8022\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.6213 - accuracy_with_masking: 0.8457 - val_loss: 0.6202 - val_accuracy_with_masking: 0.8290\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.5469 - accuracy_with_masking: 0.8698 - val_loss: 0.5496 - val_accuracy_with_masking: 0.8535\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.4841 - accuracy_with_masking: 0.8904 - val_loss: 0.4923 - val_accuracy_with_masking: 0.8725\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4347 - accuracy_with_masking: 0.9047 - val_loss: 0.4478 - val_accuracy_with_masking: 0.8860\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.3953 - accuracy_with_masking: 0.9152 - val_loss: 0.4112 - val_accuracy_with_masking: 0.8973\n",
            "Epoch 11/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.3700 - accuracy_with_masking: 0.9213"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.3645 - accuracy_with_masking: 0.9225 - val_loss: 0.3851 - val_accuracy_with_masking: 0.9037\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.3418 - accuracy_with_masking: 0.9264 - val_loss: 0.3658 - val_accuracy_with_masking: 0.9074\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.3245 - accuracy_with_masking: 0.9286 - val_loss: 0.3517 - val_accuracy_with_masking: 0.9094\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.3111 - accuracy_with_masking: 0.9301 - val_loss: 0.3386 - val_accuracy_with_masking: 0.9119\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.2983 - accuracy_with_masking: 0.9323 - val_loss: 0.3269 - val_accuracy_with_masking: 0.9145\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.2877 - accuracy_with_masking: 0.9341 - val_loss: 0.3169 - val_accuracy_with_masking: 0.9167\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.2789 - accuracy_with_masking: 0.9355 - val_loss: 0.3084 - val_accuracy_with_masking: 0.9188\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2715 - accuracy_with_masking: 0.9366 - val_loss: 0.3028 - val_accuracy_with_masking: 0.9196\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2649 - accuracy_with_masking: 0.9378 - val_loss: 0.2949 - val_accuracy_with_masking: 0.9218\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2582 - accuracy_with_masking: 0.9393 - val_loss: 0.2860 - val_accuracy_with_masking: 0.9248\n",
            " 6000/15000 [===========>..................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 54us/step\n",
            "Score:  [0.28935904105504356, 0.9230226635932922]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_2 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 157us/step - loss: 1.0083 - acc: 0.5941 - val_loss: 1.0602 - val_acc: 0.5349\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.3848 - acc: 0.9066 - val_loss: 1.0832 - val_acc: 0.5697\n",
            "Epoch 3/20\n",
            "12000/15000 [=======================>......] - ETA: 0s - loss: 0.2244 - acc: 0.9509"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.2181 - acc: 0.9514 - val_loss: 1.2067 - val_acc: 0.5769\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.1556 - acc: 0.9622 - val_loss: 1.3490 - val_acc: 0.5784\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.1253 - acc: 0.9667 - val_loss: 1.4956 - val_acc: 0.5788\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.1082 - acc: 0.9689 - val_loss: 1.6363 - val_acc: 0.5785\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0975 - acc: 0.9703 - val_loss: 1.7693 - val_acc: 0.5782\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0901 - acc: 0.9713 - val_loss: 1.9033 - val_acc: 0.5777\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0846 - acc: 0.9721 - val_loss: 2.0257 - val_acc: 0.5774\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0803 - acc: 0.9727 - val_loss: 2.1440 - val_acc: 0.5770\n",
            "Epoch 11/20\n",
            " 2500/15000 [====>.........................] - ETA: 1s - loss: 0.0613 - acc: 0.9812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0772 - acc: 0.9732 - val_loss: 2.2529 - val_acc: 0.5769\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0740 - acc: 0.9740 - val_loss: 2.3636 - val_acc: 0.5763\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0713 - acc: 0.9746 - val_loss: 2.4587 - val_acc: 0.5763\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0692 - acc: 0.9751 - val_loss: 2.5527 - val_acc: 0.5763\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0671 - acc: 0.9758 - val_loss: 2.6446 - val_acc: 0.5757\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0648 - acc: 0.9764 - val_loss: 2.7310 - val_acc: 0.5753\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0630 - acc: 0.9770 - val_loss: 2.8118 - val_acc: 0.5752\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.0608 - acc: 0.9778 - val_loss: 2.8892 - val_acc: 0.5751\n",
            "Epoch 19/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 0.0420 - acc: 0.9860"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0590 - acc: 0.9784 - val_loss: 2.9632 - val_acc: 0.5748\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0570 - acc: 0.9791 - val_loss: 3.0323 - val_acc: 0.5746\n",
            "15000/15000 [==============================] - 2s 113us/step\n",
            "Test accuracy: [1.8114092968622844, 0.6997159985542297]\n",
            "Score:  [1.8114092968622844, 0.6997159985542297]\n",
            "SNRdB:  4.444444444444445\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_5 (CuDNNLSTM)     (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 184us/step - loss: 1.2616 - accuracy_with_masking: 0.4526 - val_loss: 0.8673 - val_accuracy_with_masking: 0.6494\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.7121 - accuracy_with_masking: 0.7297 - val_loss: 0.5409 - val_accuracy_with_masking: 0.8008\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.5523 - accuracy_with_masking: 0.7819 - val_loss: 0.4629 - val_accuracy_with_masking: 0.8235\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.5128 - accuracy_with_masking: 0.7923 - val_loss: 0.4362 - val_accuracy_with_masking: 0.8315\n",
            "Epoch 5/20\n",
            " 3000/15000 [=====>........................] - ETA: 1s - loss: 0.5008 - accuracy_with_masking: 0.7958"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.4934 - accuracy_with_masking: 0.7989 - val_loss: 0.4233 - val_accuracy_with_masking: 0.8357\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4810 - accuracy_with_masking: 0.8037 - val_loss: 0.4158 - val_accuracy_with_masking: 0.8379\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.4720 - accuracy_with_masking: 0.8072 - val_loss: 0.4112 - val_accuracy_with_masking: 0.8392\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.4651 - accuracy_with_masking: 0.8100 - val_loss: 0.4088 - val_accuracy_with_masking: 0.8395\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4598 - accuracy_with_masking: 0.8122 - val_loss: 0.4076 - val_accuracy_with_masking: 0.8395\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.4556 - accuracy_with_masking: 0.8139 - val_loss: 0.4074 - val_accuracy_with_masking: 0.8394\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4523 - accuracy_with_masking: 0.8154 - val_loss: 0.4052 - val_accuracy_with_masking: 0.8401\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.4496 - accuracy_with_masking: 0.8165 - val_loss: 0.4060 - val_accuracy_with_masking: 0.8396\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4472 - accuracy_with_masking: 0.8176 - val_loss: 0.4063 - val_accuracy_with_masking: 0.8395\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.4449 - accuracy_with_masking: 0.8186 - val_loss: 0.4068 - val_accuracy_with_masking: 0.8394\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 15/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 0.4440 - accuracy_with_masking: 0.8189"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4433 - accuracy_with_masking: 0.8194 - val_loss: 0.4033 - val_accuracy_with_masking: 0.8409\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4428 - accuracy_with_masking: 0.8196 - val_loss: 0.4002 - val_accuracy_with_masking: 0.8424\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4422 - accuracy_with_masking: 0.8199 - val_loss: 0.3974 - val_accuracy_with_masking: 0.8437\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4416 - accuracy_with_masking: 0.8201 - val_loss: 0.3957 - val_accuracy_with_masking: 0.8446\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4410 - accuracy_with_masking: 0.8205 - val_loss: 0.3941 - val_accuracy_with_masking: 0.8453\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.4404 - accuracy_with_masking: 0.8208 - val_loss: 0.3927 - val_accuracy_with_masking: 0.8460\n",
            "15000/15000 [==============================] - 1s 38us/step\n",
            "Score:  [0.4259129007657369, 0.8280351082483928]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_6 (CuDNNLSTM)     (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 204us/step - loss: 1.3658 - accuracy_with_masking: 0.4669 - val_loss: 1.2896 - val_accuracy_with_masking: 0.5919\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2050 - accuracy_with_masking: 0.6786 - val_loss: 1.1251 - val_accuracy_with_masking: 0.6677\n",
            "Epoch 3/20\n",
            " 1500/15000 [==>...........................] - ETA: 1s - loss: 1.1070 - accuracy_with_masking: 0.7182"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.0296 - accuracy_with_masking: 0.7360 - val_loss: 0.9712 - val_accuracy_with_masking: 0.7008\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.8810 - accuracy_with_masking: 0.7557 - val_loss: 0.8500 - val_accuracy_with_masking: 0.7263\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.7656 - accuracy_with_masking: 0.7791 - val_loss: 0.7604 - val_accuracy_with_masking: 0.7513\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6776 - accuracy_with_masking: 0.8036 - val_loss: 0.6905 - val_accuracy_with_masking: 0.7756\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.6095 - accuracy_with_masking: 0.8251 - val_loss: 0.6425 - val_accuracy_with_masking: 0.7908\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.5615 - accuracy_with_masking: 0.8384 - val_loss: 0.6044 - val_accuracy_with_masking: 0.8038\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.5256 - accuracy_with_masking: 0.8477 - val_loss: 0.5798 - val_accuracy_with_masking: 0.8101\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.5024 - accuracy_with_masking: 0.8516 - val_loss: 0.5621 - val_accuracy_with_masking: 0.8141\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4848 - accuracy_with_masking: 0.8546 - val_loss: 0.5466 - val_accuracy_with_masking: 0.8182\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4712 - accuracy_with_masking: 0.8570 - val_loss: 0.5352 - val_accuracy_with_masking: 0.8211\n",
            "Epoch 13/20\n",
            " 7500/15000 [==============>...............] - ETA: 0s - loss: 0.4649 - accuracy_with_masking: 0.8573"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.4617 - accuracy_with_masking: 0.8582 - val_loss: 0.5261 - val_accuracy_with_masking: 0.8236\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.4520 - accuracy_with_masking: 0.8608 - val_loss: 0.5217 - val_accuracy_with_masking: 0.8243\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.4447 - accuracy_with_masking: 0.8622 - val_loss: 0.5135 - val_accuracy_with_masking: 0.8271\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.4354 - accuracy_with_masking: 0.8654 - val_loss: 0.5083 - val_accuracy_with_masking: 0.8287\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4298 - accuracy_with_masking: 0.8667 - val_loss: 0.5105 - val_accuracy_with_masking: 0.8272\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4243 - accuracy_with_masking: 0.8682 - val_loss: 0.4962 - val_accuracy_with_masking: 0.8331\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4163 - accuracy_with_masking: 0.8714 - val_loss: 0.4835 - val_accuracy_with_masking: 0.8378\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4097 - accuracy_with_masking: 0.8736 - val_loss: 0.4794 - val_accuracy_with_masking: 0.8400\n",
            "15000/15000 [==============================] - 1s 53us/step\n",
            "Score:  [0.397349488735199, 0.8815731088320414]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_3 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            " 1750/15000 [==>...........................] - ETA: 7s - loss: 1.6734 - acc: 0.2814 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 165us/step - loss: 1.0554 - acc: 0.5611 - val_loss: 0.7586 - val_acc: 0.7071\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.4477 - acc: 0.8700 - val_loss: 0.5641 - val_acc: 0.7935\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.2751 - acc: 0.9227 - val_loss: 0.5370 - val_acc: 0.8083\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.2119 - acc: 0.9350 - val_loss: 0.5507 - val_acc: 0.8126\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.1831 - acc: 0.9393 - val_loss: 0.5780 - val_acc: 0.8139\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 92us/step - loss: 0.1678 - acc: 0.9414 - val_loss: 0.6094 - val_acc: 0.8143\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.1580 - acc: 0.9433 - val_loss: 0.6435 - val_acc: 0.8140\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.1517 - acc: 0.9445 - val_loss: 0.6746 - val_acc: 0.8141\n",
            "Epoch 9/20\n",
            " 1500/15000 [==>...........................] - ETA: 1s - loss: 0.1145 - acc: 0.9620"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.1468 - acc: 0.9458 - val_loss: 0.7052 - val_acc: 0.8137\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.1426 - acc: 0.9469 - val_loss: 0.7321 - val_acc: 0.8136\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.1392 - acc: 0.9482 - val_loss: 0.7578 - val_acc: 0.8136\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.1359 - acc: 0.9494 - val_loss: 0.7790 - val_acc: 0.8135\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.1329 - acc: 0.9505 - val_loss: 0.8024 - val_acc: 0.8132\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.1299 - acc: 0.9516 - val_loss: 0.8202 - val_acc: 0.8136\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.1272 - acc: 0.9526 - val_loss: 0.8406 - val_acc: 0.8130\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.1243 - acc: 0.9538 - val_loss: 0.8536 - val_acc: 0.8133\n",
            "Epoch 17/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 0.0866 - acc: 0.9696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.1216 - acc: 0.9548 - val_loss: 0.8671 - val_acc: 0.8134\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.1190 - acc: 0.9559 - val_loss: 0.8849 - val_acc: 0.8131\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.1169 - acc: 0.9566 - val_loss: 0.8958 - val_acc: 0.8130\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.1144 - acc: 0.9576 - val_loss: 0.9052 - val_acc: 0.8132\n",
            "15000/15000 [==============================] - 2s 117us/step\n",
            "Test accuracy: [0.9152881753603618, 0.7879482233683268]\n",
            "Score:  [0.9152881753603618, 0.7879482233683268]\n",
            "SNRdB:  1.6666666666666679\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_7 (CuDNNLSTM)     (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 194us/step - loss: 1.0442 - accuracy_with_masking: 0.5653 - val_loss: 0.7961 - val_accuracy_with_masking: 0.6786\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.6974 - accuracy_with_masking: 0.7257 - val_loss: 0.6361 - val_accuracy_with_masking: 0.7461\n",
            "Epoch 3/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 0.6206 - accuracy_with_masking: 0.7520"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.6064 - accuracy_with_masking: 0.7568 - val_loss: 0.6115 - val_accuracy_with_masking: 0.7483\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.5777 - accuracy_with_masking: 0.7666 - val_loss: 0.6111 - val_accuracy_with_masking: 0.7476\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.5661 - accuracy_with_masking: 0.7704 - val_loss: 0.6097 - val_accuracy_with_masking: 0.7489\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.5601 - accuracy_with_masking: 0.7725 - val_loss: 0.6043 - val_accuracy_with_masking: 0.7516\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5563 - accuracy_with_masking: 0.7740 - val_loss: 0.5961 - val_accuracy_with_masking: 0.7555\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5537 - accuracy_with_masking: 0.7751 - val_loss: 0.5873 - val_accuracy_with_masking: 0.7595\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5517 - accuracy_with_masking: 0.7759 - val_loss: 0.5786 - val_accuracy_with_masking: 0.7636\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.5501 - accuracy_with_masking: 0.7766 - val_loss: 0.5734 - val_accuracy_with_masking: 0.7660\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.5489 - accuracy_with_masking: 0.7772 - val_loss: 0.5670 - val_accuracy_with_masking: 0.7689\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.5478 - accuracy_with_masking: 0.7776 - val_loss: 0.5639 - val_accuracy_with_masking: 0.7703\n",
            "Epoch 13/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.5474 - accuracy_with_masking: 0.7777"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5470 - accuracy_with_masking: 0.7779 - val_loss: 0.5594 - val_accuracy_with_masking: 0.7724\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.5463 - accuracy_with_masking: 0.7782 - val_loss: 0.5577 - val_accuracy_with_masking: 0.7732\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.5458 - accuracy_with_masking: 0.7785 - val_loss: 0.5558 - val_accuracy_with_masking: 0.7740\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.5453 - accuracy_with_masking: 0.7787 - val_loss: 0.5545 - val_accuracy_with_masking: 0.7746\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5449 - accuracy_with_masking: 0.7789 - val_loss: 0.5532 - val_accuracy_with_masking: 0.7752\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5446 - accuracy_with_masking: 0.7791 - val_loss: 0.5528 - val_accuracy_with_masking: 0.7754\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.5442 - accuracy_with_masking: 0.7792 - val_loss: 0.5522 - val_accuracy_with_masking: 0.7756\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.5439 - accuracy_with_masking: 0.7794 - val_loss: 0.5525 - val_accuracy_with_masking: 0.7755\n",
            "15000/15000 [==============================] - 1s 37us/step\n",
            "Score:  [0.49466328422228495, 0.8032535552978516]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_8 (CuDNNLSTM)     (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "12000/15000 [=======================>......] - ETA: 0s - loss: 1.4501 - accuracy_with_masking: 0.2622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 3s 212us/step - loss: 1.4347 - accuracy_with_masking: 0.3024 - val_loss: 1.3476 - val_accuracy_with_masking: 0.5135\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.2788 - accuracy_with_masking: 0.5527 - val_loss: 1.1883 - val_accuracy_with_masking: 0.6296\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1214 - accuracy_with_masking: 0.6414 - val_loss: 1.0295 - val_accuracy_with_masking: 0.7025\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9784 - accuracy_with_masking: 0.6930 - val_loss: 0.8908 - val_accuracy_with_masking: 0.7522\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.8650 - accuracy_with_masking: 0.7246 - val_loss: 0.7823 - val_accuracy_with_masking: 0.7847\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.7780 - accuracy_with_masking: 0.7514 - val_loss: 0.7020 - val_accuracy_with_masking: 0.8058\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.7172 - accuracy_with_masking: 0.7686 - val_loss: 0.6442 - val_accuracy_with_masking: 0.8196\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 134us/step - loss: 0.6734 - accuracy_with_masking: 0.7807 - val_loss: 0.6068 - val_accuracy_with_masking: 0.8249\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6451 - accuracy_with_masking: 0.7865 - val_loss: 0.5813 - val_accuracy_with_masking: 0.8269\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.6270 - accuracy_with_masking: 0.7893 - val_loss: 0.5623 - val_accuracy_with_masking: 0.8285\n",
            "Epoch 11/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.6165 - accuracy_with_masking: 0.7906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6147 - accuracy_with_masking: 0.7907 - val_loss: 0.5494 - val_accuracy_with_masking: 0.8289\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6064 - accuracy_with_masking: 0.7915 - val_loss: 0.5423 - val_accuracy_with_masking: 0.8280\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.5985 - accuracy_with_masking: 0.7930 - val_loss: 0.5339 - val_accuracy_with_masking: 0.8293\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.5915 - accuracy_with_masking: 0.7946 - val_loss: 0.5271 - val_accuracy_with_masking: 0.8300\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.5864 - accuracy_with_masking: 0.7955 - val_loss: 0.5217 - val_accuracy_with_masking: 0.8304\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.5841 - accuracy_with_masking: 0.7952 - val_loss: 0.5174 - val_accuracy_with_masking: 0.8307\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.5787 - accuracy_with_masking: 0.7968 - val_loss: 0.5106 - val_accuracy_with_masking: 0.8324\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.5761 - accuracy_with_masking: 0.7970 - val_loss: 0.5068 - val_accuracy_with_masking: 0.8330\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.5716 - accuracy_with_masking: 0.7983 - val_loss: 0.5051 - val_accuracy_with_masking: 0.8328\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.5703 - accuracy_with_masking: 0.7981 - val_loss: 0.5078 - val_accuracy_with_masking: 0.8304\n",
            " 7000/15000 [=============>................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 52us/step\n",
            "Score:  [0.6155043244361877, 0.7765193303426107]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_4 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 185us/step - loss: 1.0947 - acc: 0.5333 - val_loss: 0.7480 - val_acc: 0.7137\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.5917 - acc: 0.7788 - val_loss: 0.5488 - val_acc: 0.7872\n",
            "Epoch 3/20\n",
            "10750/15000 [====================>.........] - ETA: 0s - loss: 0.4792 - acc: 0.8162"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.4785 - acc: 0.8146 - val_loss: 0.4981 - val_acc: 0.8015\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.4441 - acc: 0.8248 - val_loss: 0.4848 - val_acc: 0.8065\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.4305 - acc: 0.8301 - val_loss: 0.4809 - val_acc: 0.8095\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.4212 - acc: 0.8342 - val_loss: 0.4789 - val_acc: 0.8114\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.4136 - acc: 0.8380 - val_loss: 0.4767 - val_acc: 0.8129\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.4061 - acc: 0.8414 - val_loss: 0.4732 - val_acc: 0.8152\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.3992 - acc: 0.8439 - val_loss: 0.4697 - val_acc: 0.8167\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.3927 - acc: 0.8466 - val_loss: 0.4676 - val_acc: 0.8174\n",
            "Epoch 11/20\n",
            " 2500/15000 [====>.........................] - ETA: 1s - loss: 0.3381 - acc: 0.8709"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.3871 - acc: 0.8488 - val_loss: 0.4651 - val_acc: 0.8184\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.3821 - acc: 0.8509 - val_loss: 0.4632 - val_acc: 0.8193\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.3779 - acc: 0.8526 - val_loss: 0.4608 - val_acc: 0.8201\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.3741 - acc: 0.8542 - val_loss: 0.4598 - val_acc: 0.8204\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.3709 - acc: 0.8552 - val_loss: 0.4581 - val_acc: 0.8211\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.3680 - acc: 0.8565 - val_loss: 0.4574 - val_acc: 0.8215\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.3655 - acc: 0.8576 - val_loss: 0.4569 - val_acc: 0.8216\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.3632 - acc: 0.8587 - val_loss: 0.4560 - val_acc: 0.8219\n",
            "Epoch 19/20\n",
            "  250/15000 [..............................] - ETA: 1s - loss: 0.3092 - acc: 0.8859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.3612 - acc: 0.8593 - val_loss: 0.4558 - val_acc: 0.8220\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.3594 - acc: 0.8600 - val_loss: 0.4554 - val_acc: 0.8222\n",
            "15000/15000 [==============================] - 2s 117us/step\n",
            "Test accuracy: [1.0796482714335123, 0.6607388889948527]\n",
            "Score:  [1.0796482714335123, 0.6607388889948527]\n",
            "SNRdB:  -1.1111111111111107\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_9 (CuDNNLSTM)     (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 216us/step - loss: 1.4801 - accuracy_with_masking: 0.3404 - val_loss: 1.1110 - val_accuracy_with_masking: 0.5302\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9624 - accuracy_with_masking: 0.5918 - val_loss: 0.8379 - val_accuracy_with_masking: 0.6621\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.8357 - accuracy_with_masking: 0.6507 - val_loss: 0.8038 - val_accuracy_with_masking: 0.6703\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.7925 - accuracy_with_masking: 0.6711 - val_loss: 0.7989 - val_accuracy_with_masking: 0.6702\n",
            "Epoch 5/20\n",
            " 3000/15000 [=====>........................] - ETA: 1s - loss: 0.7786 - accuracy_with_masking: 0.6775"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.7741 - accuracy_with_masking: 0.6796 - val_loss: 0.8007 - val_accuracy_with_masking: 0.6685\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.7653 - accuracy_with_masking: 0.6838 - val_loss: 0.7915 - val_accuracy_with_masking: 0.6719\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.7603 - accuracy_with_masking: 0.6862 - val_loss: 0.7848 - val_accuracy_with_masking: 0.6741\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.7571 - accuracy_with_masking: 0.6877 - val_loss: 0.7790 - val_accuracy_with_masking: 0.6762\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 116us/step - loss: 0.7548 - accuracy_with_masking: 0.6888 - val_loss: 0.7786 - val_accuracy_with_masking: 0.6760\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.7532 - accuracy_with_masking: 0.6895 - val_loss: 0.7802 - val_accuracy_with_masking: 0.6751\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.7519 - accuracy_with_masking: 0.6900 - val_loss: 0.7813 - val_accuracy_with_masking: 0.6745\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.7512 - accuracy_with_masking: 0.6902 - val_loss: 0.7795 - val_accuracy_with_masking: 0.6753\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.7510 - accuracy_with_masking: 0.6903 - val_loss: 0.7781 - val_accuracy_with_masking: 0.6759\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.7508 - accuracy_with_masking: 0.6904 - val_loss: 0.7773 - val_accuracy_with_masking: 0.6763\n",
            "Epoch 15/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 0.7505 - accuracy_with_masking: 0.6906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.7506 - accuracy_with_masking: 0.6905 - val_loss: 0.7767 - val_accuracy_with_masking: 0.6766\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.7505 - accuracy_with_masking: 0.6905 - val_loss: 0.7762 - val_accuracy_with_masking: 0.6768\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.7503 - accuracy_with_masking: 0.6906 - val_loss: 0.7760 - val_accuracy_with_masking: 0.6770\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.7501 - accuracy_with_masking: 0.6907 - val_loss: 0.7759 - val_accuracy_with_masking: 0.6771\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.7499 - accuracy_with_masking: 0.6907 - val_loss: 0.7759 - val_accuracy_with_masking: 0.6770\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.7498 - accuracy_with_masking: 0.6908 - val_loss: 0.7758 - val_accuracy_with_masking: 0.6771\n",
            "15000/15000 [==============================] - 1s 39us/step\n",
            "Score:  [0.9538516243298848, 0.608181111017863]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_10 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 232us/step - loss: 1.3846 - accuracy_with_masking: 0.4290 - val_loss: 1.3150 - val_accuracy_with_masking: 0.5261\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 134us/step - loss: 1.2472 - accuracy_with_masking: 0.6038 - val_loss: 1.1809 - val_accuracy_with_masking: 0.5847\n",
            "Epoch 3/20\n",
            " 1500/15000 [==>...........................] - ETA: 1s - loss: 1.1667 - accuracy_with_masking: 0.6438"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1024 - accuracy_with_masking: 0.6662 - val_loss: 1.0556 - val_accuracy_with_masking: 0.6308\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9657 - accuracy_with_masking: 0.7121 - val_loss: 0.9530 - val_accuracy_with_masking: 0.6605\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.8527 - accuracy_with_masking: 0.7393 - val_loss: 0.8818 - val_accuracy_with_masking: 0.6795\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.7706 - accuracy_with_masking: 0.7563 - val_loss: 0.8464 - val_accuracy_with_masking: 0.6852\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.7178 - accuracy_with_masking: 0.7643 - val_loss: 0.8356 - val_accuracy_with_masking: 0.6846\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6890 - accuracy_with_masking: 0.7659 - val_loss: 0.8336 - val_accuracy_with_masking: 0.6841\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6689 - accuracy_with_masking: 0.7683 - val_loss: 0.8355 - val_accuracy_with_masking: 0.6836\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6605 - accuracy_with_masking: 0.7689 - val_loss: 0.8339 - val_accuracy_with_masking: 0.6844\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6583 - accuracy_with_masking: 0.7690 - val_loss: 0.8341 - val_accuracy_with_masking: 0.6844\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6563 - accuracy_with_masking: 0.7692 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6845\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 13/20\n",
            " 6000/15000 [===========>..................] - ETA: 1s - loss: 0.6549 - accuracy_with_masking: 0.7696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6551 - accuracy_with_masking: 0.7693 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6845\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6547 - accuracy_with_masking: 0.7693 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6845\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6543 - accuracy_with_masking: 0.7693 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6846\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6541 - accuracy_with_masking: 0.7694 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6846\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.6540 - accuracy_with_masking: 0.7694 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6846\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.6539 - accuracy_with_masking: 0.7694 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6846\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6539 - accuracy_with_masking: 0.7694 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6846\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.6539 - accuracy_with_masking: 0.7694 - val_loss: 0.8342 - val_accuracy_with_masking: 0.6846\n",
            "15000/15000 [==============================] - 1s 53us/step\n",
            "Score:  [0.7816269596417745, 0.707502007484436]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_5 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_5 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "  250/15000 [..............................] - ETA: 1:18 - loss: 1.8474 - acc: 0.2458"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 3s 198us/step - loss: 1.1668 - acc: 0.4901 - val_loss: 1.0234 - val_acc: 0.5606\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.7696 - acc: 0.6832 - val_loss: 0.9748 - val_acc: 0.6046\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.7068 - acc: 0.7090 - val_loss: 0.9870 - val_acc: 0.6161\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.6875 - acc: 0.7191 - val_loss: 0.9917 - val_acc: 0.6214\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.6735 - acc: 0.7257 - val_loss: 0.9866 - val_acc: 0.6250\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.6612 - acc: 0.7311 - val_loss: 0.9786 - val_acc: 0.6272\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.6506 - acc: 0.7354 - val_loss: 0.9711 - val_acc: 0.6292\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.6424 - acc: 0.7389 - val_loss: 0.9657 - val_acc: 0.6304\n",
            "Epoch 9/20\n",
            " 2500/15000 [====>.........................] - ETA: 1s - loss: 0.5844 - acc: 0.7672"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.6352 - acc: 0.7420 - val_loss: 0.9624 - val_acc: 0.6314\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.6297 - acc: 0.7447 - val_loss: 0.9612 - val_acc: 0.6320\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.6252 - acc: 0.7465 - val_loss: 0.9600 - val_acc: 0.6325\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.6213 - acc: 0.7485 - val_loss: 0.9588 - val_acc: 0.6330\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.6179 - acc: 0.7500 - val_loss: 0.9594 - val_acc: 0.6332\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.6150 - acc: 0.7513 - val_loss: 0.9591 - val_acc: 0.6335\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.6125 - acc: 0.7523 - val_loss: 0.9591 - val_acc: 0.6336\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.6100 - acc: 0.7536 - val_loss: 0.9594 - val_acc: 0.6339\n",
            "Epoch 17/20\n",
            " 1750/15000 [==>...........................] - ETA: 1s - loss: 0.5601 - acc: 0.7797"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.6081 - acc: 0.7545 - val_loss: 0.9593 - val_acc: 0.6341\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.6062 - acc: 0.7554 - val_loss: 0.9597 - val_acc: 0.6341\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.6045 - acc: 0.7561 - val_loss: 0.9592 - val_acc: 0.6341\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.6029 - acc: 0.7569 - val_loss: 0.9595 - val_acc: 0.6344\n",
            "15000/15000 [==============================] - 2s 118us/step\n",
            "Test accuracy: [0.8607127987861634, 0.6670842220624288]\n",
            "Score:  [0.8607127987861634, 0.6670842220624288]\n",
            "SNRdB:  -3.8888888888888893\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_11 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_16 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_17 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 225us/step - loss: 1.3038 - accuracy_with_masking: 0.3877 - val_loss: 1.1409 - val_accuracy_with_masking: 0.4727\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 1.0484 - accuracy_with_masking: 0.5470 - val_loss: 1.0091 - val_accuracy_with_masking: 0.5554\n",
            "Epoch 3/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 1.0038 - accuracy_with_masking: 0.5673"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.9960 - accuracy_with_masking: 0.5717 - val_loss: 0.9862 - val_accuracy_with_masking: 0.5700\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.9811 - accuracy_with_masking: 0.5798 - val_loss: 0.9832 - val_accuracy_with_masking: 0.5737\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.9757 - accuracy_with_masking: 0.5825 - val_loss: 0.9729 - val_accuracy_with_masking: 0.5800\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.9729 - accuracy_with_masking: 0.5838 - val_loss: 0.9621 - val_accuracy_with_masking: 0.5858\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9711 - accuracy_with_masking: 0.5846 - val_loss: 0.9500 - val_accuracy_with_masking: 0.5929\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.9699 - accuracy_with_masking: 0.5852 - val_loss: 0.9396 - val_accuracy_with_masking: 0.5998\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9693 - accuracy_with_masking: 0.5855 - val_loss: 0.9354 - val_accuracy_with_masking: 0.6029\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9685 - accuracy_with_masking: 0.5858 - val_loss: 0.9305 - val_accuracy_with_masking: 0.6064\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.9679 - accuracy_with_masking: 0.5861 - val_loss: 0.9290 - val_accuracy_with_masking: 0.6073\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.9674 - accuracy_with_masking: 0.5863 - val_loss: 0.9292 - val_accuracy_with_masking: 0.6073\n",
            "Epoch 13/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.9671 - accuracy_with_masking: 0.5864"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9672 - accuracy_with_masking: 0.5863 - val_loss: 0.9288 - val_accuracy_with_masking: 0.6078\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 0.9670 - accuracy_with_masking: 0.5865 - val_loss: 0.9277 - val_accuracy_with_masking: 0.6085\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.9665 - accuracy_with_masking: 0.5868 - val_loss: 0.9285 - val_accuracy_with_masking: 0.6080\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9662 - accuracy_with_masking: 0.5869 - val_loss: 0.9274 - val_accuracy_with_masking: 0.6085\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9660 - accuracy_with_masking: 0.5870 - val_loss: 0.9282 - val_accuracy_with_masking: 0.6080\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9657 - accuracy_with_masking: 0.5871 - val_loss: 0.9266 - val_accuracy_with_masking: 0.6087\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 0.9657 - accuracy_with_masking: 0.5871 - val_loss: 0.9265 - val_accuracy_with_masking: 0.6088\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 0.9656 - accuracy_with_masking: 0.5872 - val_loss: 0.9265 - val_accuracy_with_masking: 0.6088\n",
            "15000/15000 [==============================] - 1s 39us/step\n",
            "Score:  [0.9760073184967041, 0.5812853336334228]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_12 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_18 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            " 9000/15000 [=================>............] - ETA: 1s - loss: 1.4178 - accuracy_with_masking: 0.3276"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 4s 242us/step - loss: 1.3907 - accuracy_with_masking: 0.3684 - val_loss: 1.3234 - val_accuracy_with_masking: 0.4649\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.2676 - accuracy_with_masking: 0.4946 - val_loss: 1.2133 - val_accuracy_with_masking: 0.5291\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1634 - accuracy_with_masking: 0.5465 - val_loss: 1.1209 - val_accuracy_with_masking: 0.5650\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.0859 - accuracy_with_masking: 0.5739 - val_loss: 1.0592 - val_accuracy_with_masking: 0.5826\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.0393 - accuracy_with_masking: 0.5881 - val_loss: 1.0243 - val_accuracy_with_masking: 0.5930\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.0173 - accuracy_with_masking: 0.5932 - val_loss: 1.0043 - val_accuracy_with_masking: 0.5987\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.0046 - accuracy_with_masking: 0.5965 - val_loss: 0.9933 - val_accuracy_with_masking: 0.6013\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.9986 - accuracy_with_masking: 0.5972 - val_loss: 0.9913 - val_accuracy_with_masking: 0.6001\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.9950 - accuracy_with_masking: 0.5973 - val_loss: 0.9835 - val_accuracy_with_masking: 0.6026\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9921 - accuracy_with_masking: 0.5975 - val_loss: 0.9795 - val_accuracy_with_masking: 0.6032\n",
            "Epoch 11/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.9875 - accuracy_with_masking: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9865 - accuracy_with_masking: 0.5990 - val_loss: 0.9762 - val_accuracy_with_masking: 0.6037\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.9836 - accuracy_with_masking: 0.5993 - val_loss: 0.9741 - val_accuracy_with_masking: 0.6037\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9819 - accuracy_with_masking: 0.5992 - val_loss: 0.9725 - val_accuracy_with_masking: 0.6033\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9802 - accuracy_with_masking: 0.5990 - val_loss: 0.9703 - val_accuracy_with_masking: 0.6035\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.9775 - accuracy_with_masking: 0.5999 - val_loss: 0.9688 - val_accuracy_with_masking: 0.6041\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9768 - accuracy_with_masking: 0.5999 - val_loss: 0.9684 - val_accuracy_with_masking: 0.6042\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9764 - accuracy_with_masking: 0.6000 - val_loss: 0.9680 - val_accuracy_with_masking: 0.6042\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9760 - accuracy_with_masking: 0.6000 - val_loss: 0.9676 - val_accuracy_with_masking: 0.6042\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.9756 - accuracy_with_masking: 0.6000 - val_loss: 0.9672 - val_accuracy_with_masking: 0.6042\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.9752 - accuracy_with_masking: 0.6001 - val_loss: 0.9668 - val_accuracy_with_masking: 0.6042\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            " 4000/15000 [=======>......................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 52us/step\n",
            "Score:  [0.9931166370709738, 0.5900662144025167]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_6 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_6 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 3s 217us/step - loss: 1.2620 - acc: 0.4365 - val_loss: 1.0860 - val_acc: 0.5236\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.9764 - acc: 0.5810 - val_loss: 1.0480 - val_acc: 0.5541\n",
            "Epoch 3/20\n",
            "10000/15000 [===================>..........] - ETA: 0s - loss: 0.9320 - acc: 0.6054"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.9405 - acc: 0.6013 - val_loss: 1.0365 - val_acc: 0.5637\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.9214 - acc: 0.6107 - val_loss: 1.0242 - val_acc: 0.5689\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.9052 - acc: 0.6176 - val_loss: 1.0128 - val_acc: 0.5727\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.8923 - acc: 0.6236 - val_loss: 1.0061 - val_acc: 0.5747\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.8824 - acc: 0.6284 - val_loss: 1.0006 - val_acc: 0.5765\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.8746 - acc: 0.6320 - val_loss: 0.9981 - val_acc: 0.5774\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.8688 - acc: 0.6350 - val_loss: 0.9963 - val_acc: 0.5779\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.8640 - acc: 0.6374 - val_loss: 0.9946 - val_acc: 0.5788\n",
            "Epoch 11/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 0.8101 - acc: 0.6670"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.8601 - acc: 0.6392 - val_loss: 0.9941 - val_acc: 0.5791\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.8568 - acc: 0.6408 - val_loss: 0.9933 - val_acc: 0.5794\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.8540 - acc: 0.6425 - val_loss: 0.9928 - val_acc: 0.5797\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.8514 - acc: 0.6438 - val_loss: 0.9930 - val_acc: 0.5796\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.8493 - acc: 0.6447 - val_loss: 0.9922 - val_acc: 0.5800\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.8474 - acc: 0.6458 - val_loss: 0.9921 - val_acc: 0.5801\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.8457 - acc: 0.6465 - val_loss: 0.9923 - val_acc: 0.5802\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.8442 - acc: 0.6473 - val_loss: 0.9919 - val_acc: 0.5804\n",
            "Epoch 19/20\n",
            "  250/15000 [..............................] - ETA: 1s - loss: 0.8035 - acc: 0.6716"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.8427 - acc: 0.6481 - val_loss: 0.9923 - val_acc: 0.5803\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.8416 - acc: 0.6489 - val_loss: 0.9923 - val_acc: 0.5802\n",
            "15000/15000 [==============================] - 2s 118us/step\n",
            "Test accuracy: [1.0378574694315592, 0.5580935565948486]\n",
            "Score:  [1.0378574694315592, 0.5580935565948486]\n",
            "SNRdB:  -6.666666666666664\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_13 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_19 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_20 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 240us/step - loss: 1.3264 - accuracy_with_masking: 0.3931 - val_loss: 1.2750 - val_accuracy_with_masking: 0.4075\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 1.1543 - accuracy_with_masking: 0.4896 - val_loss: 1.2778 - val_accuracy_with_masking: 0.4533\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.1296 - accuracy_with_masking: 0.5006 - val_loss: 1.2591 - val_accuracy_with_masking: 0.4548\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1228 - accuracy_with_masking: 0.5034 - val_loss: 1.2378 - val_accuracy_with_masking: 0.4534\n",
            "Epoch 5/20\n",
            " 3000/15000 [=====>........................] - ETA: 1s - loss: 1.1207 - accuracy_with_masking: 0.5037"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 117us/step - loss: 1.1201 - accuracy_with_masking: 0.5045 - val_loss: 1.2172 - val_accuracy_with_masking: 0.4571\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 1.1187 - accuracy_with_masking: 0.5051 - val_loss: 1.2006 - val_accuracy_with_masking: 0.4628\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.1179 - accuracy_with_masking: 0.5056 - val_loss: 1.1863 - val_accuracy_with_masking: 0.4686\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1174 - accuracy_with_masking: 0.5058 - val_loss: 1.1738 - val_accuracy_with_masking: 0.4742\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.1170 - accuracy_with_masking: 0.5060 - val_loss: 1.1704 - val_accuracy_with_masking: 0.4756\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1167 - accuracy_with_masking: 0.5062 - val_loss: 1.1607 - val_accuracy_with_masking: 0.4808\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1165 - accuracy_with_masking: 0.5062 - val_loss: 1.1626 - val_accuracy_with_masking: 0.4798\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1163 - accuracy_with_masking: 0.5063 - val_loss: 1.1568 - val_accuracy_with_masking: 0.4826\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1161 - accuracy_with_masking: 0.5064 - val_loss: 1.1517 - val_accuracy_with_masking: 0.4854\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1160 - accuracy_with_masking: 0.5065 - val_loss: 1.1534 - val_accuracy_with_masking: 0.4842\n",
            "Epoch 15/20\n",
            " 7500/15000 [==============>...............] - ETA: 0s - loss: 1.1157 - accuracy_with_masking: 0.5066"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.1159 - accuracy_with_masking: 0.5066 - val_loss: 1.1488 - val_accuracy_with_masking: 0.4871\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.1157 - accuracy_with_masking: 0.5066 - val_loss: 1.1477 - val_accuracy_with_masking: 0.4878\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1156 - accuracy_with_masking: 0.5067 - val_loss: 1.1477 - val_accuracy_with_masking: 0.4879\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1156 - accuracy_with_masking: 0.5067 - val_loss: 1.1504 - val_accuracy_with_masking: 0.4863\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1156 - accuracy_with_masking: 0.5066 - val_loss: 1.1497 - val_accuracy_with_masking: 0.4868\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.1154 - accuracy_with_masking: 0.5067 - val_loss: 1.1437 - val_accuracy_with_masking: 0.4905\n",
            "15000/15000 [==============================] - 1s 38us/step\n",
            "Score:  [1.1021302620569864, 0.5135531067848206]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_14 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_21 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 267us/step - loss: 1.3938 - accuracy_with_masking: 0.3594 - val_loss: 1.3371 - val_accuracy_with_masking: 0.4316\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3067 - accuracy_with_masking: 0.4489 - val_loss: 1.2710 - val_accuracy_with_masking: 0.4665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2385 - accuracy_with_masking: 0.4831 - val_loss: 1.2260 - val_accuracy_with_masking: 0.4798\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1903 - accuracy_with_masking: 0.5008 - val_loss: 1.2012 - val_accuracy_with_masking: 0.4864\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.1626 - accuracy_with_masking: 0.5091 - val_loss: 1.1928 - val_accuracy_with_masking: 0.4889\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1487 - accuracy_with_masking: 0.5136 - val_loss: 1.1929 - val_accuracy_with_masking: 0.4874\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.1430 - accuracy_with_masking: 0.5144 - val_loss: 1.1911 - val_accuracy_with_masking: 0.4868\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.1395 - accuracy_with_masking: 0.5144 - val_loss: 1.1878 - val_accuracy_with_masking: 0.4864\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1359 - accuracy_with_masking: 0.5153 - val_loss: 1.1855 - val_accuracy_with_masking: 0.4875\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1349 - accuracy_with_masking: 0.5155 - val_loss: 1.1848 - val_accuracy_with_masking: 0.4875\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1342 - accuracy_with_masking: 0.5155 - val_loss: 1.1840 - val_accuracy_with_masking: 0.4875\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 138us/step - loss: 1.1337 - accuracy_with_masking: 0.5155 - val_loss: 1.1839 - val_accuracy_with_masking: 0.4875\n",
            "Epoch 13/20\n",
            " 3000/15000 [=====>........................] - ETA: 1s - loss: 1.1345 - accuracy_with_masking: 0.5149"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1336 - accuracy_with_masking: 0.5155 - val_loss: 1.1837 - val_accuracy_with_masking: 0.4875\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.1334 - accuracy_with_masking: 0.5155 - val_loss: 1.1835 - val_accuracy_with_masking: 0.4875\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1333 - accuracy_with_masking: 0.5156 - val_loss: 1.1835 - val_accuracy_with_masking: 0.4875\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1333 - accuracy_with_masking: 0.5156 - val_loss: 1.1835 - val_accuracy_with_masking: 0.4875\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.1333 - accuracy_with_masking: 0.5156 - val_loss: 1.1834 - val_accuracy_with_masking: 0.4876\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1332 - accuracy_with_masking: 0.5156 - val_loss: 1.1834 - val_accuracy_with_masking: 0.4876\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1332 - accuracy_with_masking: 0.5156 - val_loss: 1.1834 - val_accuracy_with_masking: 0.4876\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.1332 - accuracy_with_masking: 0.5156 - val_loss: 1.1834 - val_accuracy_with_masking: 0.4876\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
            "15000/15000 [==============================] - 1s 52us/step\n",
            "Score:  [1.1578718423843384, 0.50182044506073]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_7 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 4s 237us/step - loss: 1.3633 - acc: 0.3824 - val_loss: 1.3256 - val_acc: 0.4080\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.1545 - acc: 0.4916 - val_loss: 1.3218 - val_acc: 0.4281\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.1274 - acc: 0.5079 - val_loss: 1.3103 - val_acc: 0.4341\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.1073 - acc: 0.5168 - val_loss: 1.2945 - val_acc: 0.4375\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 1.0899 - acc: 0.5239 - val_loss: 1.2809 - val_acc: 0.4397\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.0759 - acc: 0.5302 - val_loss: 1.2723 - val_acc: 0.4411\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.0654 - acc: 0.5356 - val_loss: 1.2668 - val_acc: 0.4421\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.0575 - acc: 0.5399 - val_loss: 1.2641 - val_acc: 0.4427\n",
            "Epoch 9/20\n",
            "  250/15000 [..............................] - ETA: 1s - loss: 0.9944 - acc: 0.5787"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.0514 - acc: 0.5433 - val_loss: 1.2630 - val_acc: 0.4429\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.0467 - acc: 0.5461 - val_loss: 1.2621 - val_acc: 0.4432\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.0430 - acc: 0.5479 - val_loss: 1.2620 - val_acc: 0.4434\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.0400 - acc: 0.5496 - val_loss: 1.2613 - val_acc: 0.4433\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.0374 - acc: 0.5513 - val_loss: 1.2616 - val_acc: 0.4435\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.0353 - acc: 0.5525 - val_loss: 1.2613 - val_acc: 0.4437\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.0333 - acc: 0.5535 - val_loss: 1.2613 - val_acc: 0.4439\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.0317 - acc: 0.5545 - val_loss: 1.2610 - val_acc: 0.4439\n",
            "Epoch 17/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 0.9937 - acc: 0.5782"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.0303 - acc: 0.5554 - val_loss: 1.2616 - val_acc: 0.4440\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 1.0290 - acc: 0.5561 - val_loss: 1.2614 - val_acc: 0.4439\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.0278 - acc: 0.5567 - val_loss: 1.2621 - val_acc: 0.4439\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.0268 - acc: 0.5573 - val_loss: 1.2623 - val_acc: 0.4441\n",
            "15000/15000 [==============================] - 2s 121us/step\n",
            "Test accuracy: [1.2206472225824991, 0.4562433325767517]\n",
            "Score:  [1.2206472225824991, 0.4562433325767517]\n",
            "SNRdB:  -9.444444444444443\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_15 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_22 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_23 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 257us/step - loss: 1.4290 - accuracy_with_masking: 0.3457 - val_loss: 1.3445 - val_accuracy_with_masking: 0.3717\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2604 - accuracy_with_masking: 0.4207 - val_loss: 1.3090 - val_accuracy_with_masking: 0.4009\n",
            "Epoch 3/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 1.2456 - accuracy_with_masking: 0.4286"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2424 - accuracy_with_masking: 0.4296 - val_loss: 1.2910 - val_accuracy_with_masking: 0.4102\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2364 - accuracy_with_masking: 0.4319 - val_loss: 1.2791 - val_accuracy_with_masking: 0.4131\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2338 - accuracy_with_masking: 0.4332 - val_loss: 1.2670 - val_accuracy_with_masking: 0.4173\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2324 - accuracy_with_masking: 0.4340 - val_loss: 1.2585 - val_accuracy_with_masking: 0.4206\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2316 - accuracy_with_masking: 0.4346 - val_loss: 1.2536 - val_accuracy_with_masking: 0.4223\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2311 - accuracy_with_masking: 0.4349 - val_loss: 1.2504 - val_accuracy_with_masking: 0.4232\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2307 - accuracy_with_masking: 0.4351 - val_loss: 1.2476 - val_accuracy_with_masking: 0.4248\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2304 - accuracy_with_masking: 0.4353 - val_loss: 1.2469 - val_accuracy_with_masking: 0.4248\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2302 - accuracy_with_masking: 0.4354 - val_loss: 1.2454 - val_accuracy_with_masking: 0.4255\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2300 - accuracy_with_masking: 0.4355 - val_loss: 1.2447 - val_accuracy_with_masking: 0.4258\n",
            "Epoch 13/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 1.2300 - accuracy_with_masking: 0.4354"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2298 - accuracy_with_masking: 0.4356 - val_loss: 1.2443 - val_accuracy_with_masking: 0.4259\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2297 - accuracy_with_masking: 0.4356 - val_loss: 1.2440 - val_accuracy_with_masking: 0.4260\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2295 - accuracy_with_masking: 0.4357 - val_loss: 1.2435 - val_accuracy_with_masking: 0.4262\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2294 - accuracy_with_masking: 0.4358 - val_loss: 1.2432 - val_accuracy_with_masking: 0.4262\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2293 - accuracy_with_masking: 0.4358 - val_loss: 1.2430 - val_accuracy_with_masking: 0.4263\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2293 - accuracy_with_masking: 0.4358 - val_loss: 1.2429 - val_accuracy_with_masking: 0.4263\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2292 - accuracy_with_masking: 0.4359 - val_loss: 1.2429 - val_accuracy_with_masking: 0.4262\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2292 - accuracy_with_masking: 0.4358 - val_loss: 1.2445 - val_accuracy_with_masking: 0.4245\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "15000/15000 [==============================] - 1s 38us/step\n",
            "Score:  [1.2345566352208455, 0.4316391090552012]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_16 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_24 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "10500/15000 [====================>.........] - ETA: 1s - loss: 1.4347 - accuracy_with_masking: 0.3003"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 4s 281us/step - loss: 1.4204 - accuracy_with_masking: 0.3196 - val_loss: 1.3722 - val_accuracy_with_masking: 0.3823\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3496 - accuracy_with_masking: 0.3999 - val_loss: 1.3178 - val_accuracy_with_masking: 0.4211\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3045 - accuracy_with_masking: 0.4259 - val_loss: 1.2811 - val_accuracy_with_masking: 0.4377\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2778 - accuracy_with_masking: 0.4371 - val_loss: 1.2608 - val_accuracy_with_masking: 0.4461\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2634 - accuracy_with_masking: 0.4425 - val_loss: 1.2503 - val_accuracy_with_masking: 0.4491\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2569 - accuracy_with_masking: 0.4437 - val_loss: 1.2449 - val_accuracy_with_masking: 0.4496\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2512 - accuracy_with_masking: 0.4448 - val_loss: 1.2400 - val_accuracy_with_masking: 0.4505\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2475 - accuracy_with_masking: 0.4449 - val_loss: 1.2364 - val_accuracy_with_masking: 0.4507\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2438 - accuracy_with_masking: 0.4456 - val_loss: 1.2335 - val_accuracy_with_masking: 0.4508\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2418 - accuracy_with_masking: 0.4452 - val_loss: 1.2322 - val_accuracy_with_masking: 0.4500\n",
            "Epoch 11/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 1.2396 - accuracy_with_masking: 0.4454"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2390 - accuracy_with_masking: 0.4457 - val_loss: 1.2287 - val_accuracy_with_masking: 0.4511\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2366 - accuracy_with_masking: 0.4460 - val_loss: 1.2267 - val_accuracy_with_masking: 0.4512\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2347 - accuracy_with_masking: 0.4459 - val_loss: 1.2253 - val_accuracy_with_masking: 0.4510\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2334 - accuracy_with_masking: 0.4458 - val_loss: 1.2241 - val_accuracy_with_masking: 0.4509\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2317 - accuracy_with_masking: 0.4463 - val_loss: 1.2226 - val_accuracy_with_masking: 0.4516\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2311 - accuracy_with_masking: 0.4465 - val_loss: 1.2222 - val_accuracy_with_masking: 0.4517\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2308 - accuracy_with_masking: 0.4465 - val_loss: 1.2219 - val_accuracy_with_masking: 0.4517\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2305 - accuracy_with_masking: 0.4466 - val_loss: 1.2217 - val_accuracy_with_masking: 0.4517\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.2303 - accuracy_with_masking: 0.4466 - val_loss: 1.2216 - val_accuracy_with_masking: 0.4517\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2303 - accuracy_with_masking: 0.4466 - val_loss: 1.2215 - val_accuracy_with_masking: 0.4517\n",
            " 2000/15000 [===>..........................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 53us/step\n",
            "Score:  [1.2163368066151936, 0.4556233366330465]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_8 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_8 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 251us/step - loss: 1.4451 - acc: 0.3386 - val_loss: 1.4025 - val_acc: 0.3558\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2881 - acc: 0.4186 - val_loss: 1.3935 - val_acc: 0.3702\n",
            "Epoch 3/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 1.2524 - acc: 0.4393"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.2645 - acc: 0.4311 - val_loss: 1.3762 - val_acc: 0.3746\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2440 - acc: 0.4386 - val_loss: 1.3580 - val_acc: 0.3783\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2251 - acc: 0.4462 - val_loss: 1.3452 - val_acc: 0.3800\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2096 - acc: 0.4534 - val_loss: 1.3365 - val_acc: 0.3814\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.1972 - acc: 0.4597 - val_loss: 1.3310 - val_acc: 0.3825\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.1879 - acc: 0.4653 - val_loss: 1.3277 - val_acc: 0.3832\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.1811 - acc: 0.4694 - val_loss: 1.3269 - val_acc: 0.3829\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.1760 - acc: 0.4729 - val_loss: 1.3259 - val_acc: 0.3833\n",
            "Epoch 11/20\n",
            " 1750/15000 [==>...........................] - ETA: 1s - loss: 1.1371 - acc: 0.5000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.1723 - acc: 0.4754 - val_loss: 1.3260 - val_acc: 0.3832\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 1.1692 - acc: 0.4772 - val_loss: 1.3252 - val_acc: 0.3837\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.1668 - acc: 0.4788 - val_loss: 1.3257 - val_acc: 0.3837\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.1648 - acc: 0.4800 - val_loss: 1.3255 - val_acc: 0.3836\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 1.1631 - acc: 0.4814 - val_loss: 1.3254 - val_acc: 0.3838\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.1617 - acc: 0.4822 - val_loss: 1.3250 - val_acc: 0.3840\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.1604 - acc: 0.4832 - val_loss: 1.3263 - val_acc: 0.3835\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.1593 - acc: 0.4838 - val_loss: 1.3250 - val_acc: 0.3842\n",
            "Epoch 19/20\n",
            " 1000/15000 [=>............................] - ETA: 1s - loss: 1.1314 - acc: 0.5034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.1583 - acc: 0.4845 - val_loss: 1.3257 - val_acc: 0.3838\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.1574 - acc: 0.4850 - val_loss: 1.3259 - val_acc: 0.3839\n",
            "15000/15000 [==============================] - 2s 121us/step\n",
            "Test accuracy: [1.3031127568562826, 0.39740977732340493]\n",
            "Score:  [1.3031127568562826, 0.39740977732340493]\n",
            "SNRdB:  -12.222222222222221\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_17 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_25 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_26 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 275us/step - loss: 1.8912 - accuracy_with_masking: 0.2459 - val_loss: 1.4861 - val_accuracy_with_masking: 0.2966\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3862 - accuracy_with_masking: 0.3325 - val_loss: 1.3665 - val_accuracy_with_masking: 0.3514\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3273 - accuracy_with_masking: 0.3684 - val_loss: 1.3457 - val_accuracy_with_masking: 0.3625\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3167 - accuracy_with_masking: 0.3758 - val_loss: 1.3343 - val_accuracy_with_masking: 0.3661\n",
            "Epoch 5/20\n",
            " 3000/15000 [=====>........................] - ETA: 1s - loss: 1.3127 - accuracy_with_masking: 0.3785"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3107 - accuracy_with_masking: 0.3788 - val_loss: 1.3235 - val_accuracy_with_masking: 0.3705\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3071 - accuracy_with_masking: 0.3806 - val_loss: 1.3172 - val_accuracy_with_masking: 0.3731\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3048 - accuracy_with_masking: 0.3818 - val_loss: 1.3138 - val_accuracy_with_masking: 0.3746\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3032 - accuracy_with_masking: 0.3826 - val_loss: 1.3116 - val_accuracy_with_masking: 0.3754\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 1.3019 - accuracy_with_masking: 0.3832 - val_loss: 1.3103 - val_accuracy_with_masking: 0.3757\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3009 - accuracy_with_masking: 0.3835 - val_loss: 1.3099 - val_accuracy_with_masking: 0.3752\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3000 - accuracy_with_masking: 0.3839 - val_loss: 1.3103 - val_accuracy_with_masking: 0.3741\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2994 - accuracy_with_masking: 0.3842 - val_loss: 1.3113 - val_accuracy_with_masking: 0.3724\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2990 - accuracy_with_masking: 0.3844 - val_loss: 1.3101 - val_accuracy_with_masking: 0.3736\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2988 - accuracy_with_masking: 0.3845 - val_loss: 1.3092 - val_accuracy_with_masking: 0.3744\n",
            "Epoch 15/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 1.2989 - accuracy_with_masking: 0.3842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.2987 - accuracy_with_masking: 0.3845 - val_loss: 1.3085 - val_accuracy_with_masking: 0.3752\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2986 - accuracy_with_masking: 0.3845 - val_loss: 1.3075 - val_accuracy_with_masking: 0.3763\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2986 - accuracy_with_masking: 0.3846 - val_loss: 1.3068 - val_accuracy_with_masking: 0.3771\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2986 - accuracy_with_masking: 0.3846 - val_loss: 1.3061 - val_accuracy_with_masking: 0.3776\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2986 - accuracy_with_masking: 0.3846 - val_loss: 1.3056 - val_accuracy_with_masking: 0.3781\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.2986 - accuracy_with_masking: 0.3845 - val_loss: 1.3052 - val_accuracy_with_masking: 0.3785\n",
            "15000/15000 [==============================] - 1s 39us/step\n",
            "Score:  [1.3243041435877483, 0.36539066831270856]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_18 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_27 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 291us/step - loss: 1.4472 - accuracy_with_masking: 0.2831 - val_loss: 1.4137 - val_accuracy_with_masking: 0.3248\n",
            "Epoch 2/20\n",
            "12000/15000 [=======================>......] - ETA: 0s - loss: 1.3978 - accuracy_with_masking: 0.3433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3938 - accuracy_with_masking: 0.3470 - val_loss: 1.3737 - val_accuracy_with_masking: 0.3648\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3624 - accuracy_with_masking: 0.3724 - val_loss: 1.3508 - val_accuracy_with_masking: 0.3786\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3465 - accuracy_with_masking: 0.3793 - val_loss: 1.3404 - val_accuracy_with_masking: 0.3822\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3373 - accuracy_with_masking: 0.3827 - val_loss: 1.3313 - val_accuracy_with_masking: 0.3859\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3306 - accuracy_with_masking: 0.3848 - val_loss: 1.3260 - val_accuracy_with_masking: 0.3868\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3260 - accuracy_with_masking: 0.3854 - val_loss: 1.3226 - val_accuracy_with_masking: 0.3863\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3235 - accuracy_with_masking: 0.3842 - val_loss: 1.3201 - val_accuracy_with_masking: 0.3859\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3197 - accuracy_with_masking: 0.3854 - val_loss: 1.3159 - val_accuracy_with_masking: 0.3877\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3164 - accuracy_with_masking: 0.3865 - val_loss: 1.3140 - val_accuracy_with_masking: 0.3876\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3148 - accuracy_with_masking: 0.3861 - val_loss: 1.3123 - val_accuracy_with_masking: 0.3874\n",
            "Epoch 12/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 1.3129 - accuracy_with_masking: 0.3866"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 138us/step - loss: 1.3126 - accuracy_with_masking: 0.3864 - val_loss: 1.3113 - val_accuracy_with_masking: 0.3862\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.3111 - accuracy_with_masking: 0.3869 - val_loss: 1.3092 - val_accuracy_with_masking: 0.3881\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3104 - accuracy_with_masking: 0.3872 - val_loss: 1.3089 - val_accuracy_with_masking: 0.3880\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3101 - accuracy_with_masking: 0.3872 - val_loss: 1.3086 - val_accuracy_with_masking: 0.3881\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3098 - accuracy_with_masking: 0.3873 - val_loss: 1.3082 - val_accuracy_with_masking: 0.3881\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3095 - accuracy_with_masking: 0.3873 - val_loss: 1.3081 - val_accuracy_with_masking: 0.3881\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 1.3095 - accuracy_with_masking: 0.3873 - val_loss: 1.3081 - val_accuracy_with_masking: 0.3881\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3094 - accuracy_with_masking: 0.3873 - val_loss: 1.3080 - val_accuracy_with_masking: 0.3882\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3093 - accuracy_with_masking: 0.3873 - val_loss: 1.3079 - val_accuracy_with_masking: 0.3882\n",
            "10000/15000 [===================>..........] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 54us/step\n",
            "Score:  [1.307089614868164, 0.38935978213946026]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_9 (Conv1D)            (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_9 (Reshape)          (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_9 (Softmax)          (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 263us/step - loss: 1.4952 - acc: 0.3115 - val_loss: 1.4601 - val_acc: 0.3219\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.3733 - acc: 0.3671 - val_loss: 1.4491 - val_acc: 0.3288\n",
            "Epoch 3/20\n",
            " 9750/15000 [==================>...........] - ETA: 0s - loss: 1.3418 - acc: 0.3829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.3518 - acc: 0.3751 - val_loss: 1.4292 - val_acc: 0.3316\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.3300 - acc: 0.3826 - val_loss: 1.4124 - val_acc: 0.3335\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.3108 - acc: 0.3901 - val_loss: 1.3988 - val_acc: 0.3355\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2938 - acc: 0.3977 - val_loss: 1.3884 - val_acc: 0.3375\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2798 - acc: 0.4053 - val_loss: 1.3819 - val_acc: 0.3381\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.2692 - acc: 0.4117 - val_loss: 1.3778 - val_acc: 0.3385\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.2614 - acc: 0.4170 - val_loss: 1.3758 - val_acc: 0.3389\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2559 - acc: 0.4208 - val_loss: 1.3747 - val_acc: 0.3391\n",
            "Epoch 11/20\n",
            " 2500/15000 [====>.........................] - ETA: 1s - loss: 1.2218 - acc: 0.4478"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.2518 - acc: 0.4238 - val_loss: 1.3742 - val_acc: 0.3392\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.2488 - acc: 0.4263 - val_loss: 1.3742 - val_acc: 0.3393\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2465 - acc: 0.4280 - val_loss: 1.3743 - val_acc: 0.3394\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2445 - acc: 0.4294 - val_loss: 1.3744 - val_acc: 0.3393\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2430 - acc: 0.4307 - val_loss: 1.3743 - val_acc: 0.3394\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 100us/step - loss: 1.2417 - acc: 0.4317 - val_loss: 1.3745 - val_acc: 0.3392\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2406 - acc: 0.4325 - val_loss: 1.3745 - val_acc: 0.3395\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2396 - acc: 0.4331 - val_loss: 1.3742 - val_acc: 0.3393\n",
            "Epoch 19/20\n",
            " 1750/15000 [==>...........................] - ETA: 1s - loss: 1.2180 - acc: 0.4514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2388 - acc: 0.4339 - val_loss: 1.3745 - val_acc: 0.3394\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.2379 - acc: 0.4345 - val_loss: 1.3748 - val_acc: 0.3395\n",
            "15000/15000 [==============================] - 2s 121us/step\n",
            "Test accuracy: [1.362413663927714, 0.3457806669076284]\n",
            "Score:  [1.362413663927714, 0.3457806669076284]\n",
            "SNRdB:  -15.0\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_19 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_28 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_29 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 5s 316us/step - loss: 1.5326 - accuracy_with_masking: 0.2845 - val_loss: 1.4887 - val_accuracy_with_masking: 0.2984\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3959 - accuracy_with_masking: 0.3151 - val_loss: 1.4654 - val_accuracy_with_masking: 0.2956\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3696 - accuracy_with_masking: 0.3239 - val_loss: 1.4231 - val_accuracy_with_masking: 0.3002\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3598 - accuracy_with_masking: 0.3277 - val_loss: 1.3975 - val_accuracy_with_masking: 0.3046\n",
            "Epoch 5/20\n",
            " 4500/15000 [========>.....................] - ETA: 1s - loss: 1.3563 - accuracy_with_masking: 0.3294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3548 - accuracy_with_masking: 0.3307 - val_loss: 1.3841 - val_accuracy_with_masking: 0.3090\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3520 - accuracy_with_masking: 0.3327 - val_loss: 1.3763 - val_accuracy_with_masking: 0.3115\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3504 - accuracy_with_masking: 0.3336 - val_loss: 1.3705 - val_accuracy_with_masking: 0.3151\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3488 - accuracy_with_masking: 0.3351 - val_loss: 1.3658 - val_accuracy_with_masking: 0.3186\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3479 - accuracy_with_masking: 0.3359 - val_loss: 1.3631 - val_accuracy_with_masking: 0.3193\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3475 - accuracy_with_masking: 0.3362 - val_loss: 1.3606 - val_accuracy_with_masking: 0.3211\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3468 - accuracy_with_masking: 0.3369 - val_loss: 1.3579 - val_accuracy_with_masking: 0.3240\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3462 - accuracy_with_masking: 0.3374 - val_loss: 1.3558 - val_accuracy_with_masking: 0.3262\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3460 - accuracy_with_masking: 0.3375 - val_loss: 1.3535 - val_accuracy_with_masking: 0.3290\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3458 - accuracy_with_masking: 0.3376 - val_loss: 1.3532 - val_accuracy_with_masking: 0.3313\n",
            "Epoch 15/20\n",
            " 7500/15000 [==============>...............] - ETA: 0s - loss: 1.3464 - accuracy_with_masking: 0.3368"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3458 - accuracy_with_masking: 0.3376 - val_loss: 1.3517 - val_accuracy_with_masking: 0.3309\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3452 - accuracy_with_masking: 0.3383 - val_loss: 1.3502 - val_accuracy_with_masking: 0.3327\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 117us/step - loss: 1.3450 - accuracy_with_masking: 0.3384 - val_loss: 1.3500 - val_accuracy_with_masking: 0.3321\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3449 - accuracy_with_masking: 0.3384 - val_loss: 1.3489 - val_accuracy_with_masking: 0.3343\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 118us/step - loss: 1.3451 - accuracy_with_masking: 0.3381 - val_loss: 1.3485 - val_accuracy_with_masking: 0.3338\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 119us/step - loss: 1.3445 - accuracy_with_masking: 0.3387 - val_loss: 1.3475 - val_accuracy_with_masking: 0.3348\n",
            "15000/15000 [==============================] - 1s 38us/step\n",
            "Score:  [1.348013695081075, 0.33444888989130656]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_20 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_30 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 5s 311us/step - loss: 1.4469 - accuracy_with_masking: 0.2848 - val_loss: 1.4210 - val_accuracy_with_masking: 0.3098\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.4074 - accuracy_with_masking: 0.3227 - val_loss: 1.3946 - val_accuracy_with_masking: 0.3336\n",
            "Epoch 3/20\n",
            " 3000/15000 [=====>........................] - ETA: 1s - loss: 1.3940 - accuracy_with_masking: 0.3335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3882 - accuracy_with_masking: 0.3368 - val_loss: 1.3813 - val_accuracy_with_masking: 0.3406\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3765 - accuracy_with_masking: 0.3423 - val_loss: 1.3728 - val_accuracy_with_masking: 0.3431\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3690 - accuracy_with_masking: 0.3440 - val_loss: 1.3661 - val_accuracy_with_masking: 0.3445\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3630 - accuracy_with_masking: 0.3454 - val_loss: 1.3611 - val_accuracy_with_masking: 0.3453\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3592 - accuracy_with_masking: 0.3455 - val_loss: 1.3579 - val_accuracy_with_masking: 0.3453\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3555 - accuracy_with_masking: 0.3464 - val_loss: 1.3548 - val_accuracy_with_masking: 0.3460\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3532 - accuracy_with_masking: 0.3463 - val_loss: 1.3524 - val_accuracy_with_masking: 0.3463\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3508 - accuracy_with_masking: 0.3469 - val_loss: 1.3503 - val_accuracy_with_masking: 0.3468\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 138us/step - loss: 1.3491 - accuracy_with_masking: 0.3472 - val_loss: 1.3493 - val_accuracy_with_masking: 0.3467\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3484 - accuracy_with_masking: 0.3467 - val_loss: 1.3475 - val_accuracy_with_masking: 0.3472\n",
            "Epoch 13/20\n",
            " 7500/15000 [==============>...............] - ETA: 0s - loss: 1.3467 - accuracy_with_masking: 0.3476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3464 - accuracy_with_masking: 0.3478 - val_loss: 1.3468 - val_accuracy_with_masking: 0.3471\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3461 - accuracy_with_masking: 0.3472 - val_loss: 1.3473 - val_accuracy_with_masking: 0.3455\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3456 - accuracy_with_masking: 0.3470 - val_loss: 1.3455 - val_accuracy_with_masking: 0.3468\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3440 - accuracy_with_masking: 0.3481 - val_loss: 1.3443 - val_accuracy_with_masking: 0.3477\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3436 - accuracy_with_masking: 0.3482 - val_loss: 1.3442 - val_accuracy_with_masking: 0.3477\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3435 - accuracy_with_masking: 0.3482 - val_loss: 1.3440 - val_accuracy_with_masking: 0.3477\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.3433 - accuracy_with_masking: 0.3482 - val_loss: 1.3439 - val_accuracy_with_masking: 0.3477\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.3432 - accuracy_with_masking: 0.3482 - val_loss: 1.3438 - val_accuracy_with_masking: 0.3477\n",
            "15000/15000 [==============================] - 1s 52us/step\n",
            "Score:  [1.341054916381836, 0.3508975565433502]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_10 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_10 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_10 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "  750/15000 [>.............................] - ETA: 46s - loss: 1.8130 - acc: 0.2524 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 4s 276us/step - loss: 1.5334 - acc: 0.2864 - val_loss: 1.4512 - val_acc: 0.2999\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.4247 - acc: 0.3295 - val_loss: 1.4367 - val_acc: 0.3068\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.4029 - acc: 0.3368 - val_loss: 1.4205 - val_acc: 0.3090\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.3815 - acc: 0.3435 - val_loss: 1.4062 - val_acc: 0.3121\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.3616 - acc: 0.3507 - val_loss: 1.3950 - val_acc: 0.3144\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.3436 - acc: 0.3589 - val_loss: 1.3869 - val_acc: 0.3160\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.3283 - acc: 0.3673 - val_loss: 1.3821 - val_acc: 0.3170\n",
            "Epoch 8/20\n",
            "13750/15000 [==========================>...] - ETA: 0s - loss: 1.3141 - acc: 0.3771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 101us/step - loss: 1.3164 - acc: 0.3750 - val_loss: 1.3790 - val_acc: 0.3173\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 1.3076 - acc: 0.3812 - val_loss: 1.3774 - val_acc: 0.3174\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.3016 - acc: 0.3859 - val_loss: 1.3764 - val_acc: 0.3176\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 1.2974 - acc: 0.3895 - val_loss: 1.3761 - val_acc: 0.3178\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2943 - acc: 0.3921 - val_loss: 1.3761 - val_acc: 0.3177\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.2920 - acc: 0.3939 - val_loss: 1.3763 - val_acc: 0.3179\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2902 - acc: 0.3956 - val_loss: 1.3761 - val_acc: 0.3178\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 1.2888 - acc: 0.3968 - val_loss: 1.3761 - val_acc: 0.3179\n",
            "Epoch 16/20\n",
            " 1750/15000 [==>...........................] - ETA: 1s - loss: 1.2688 - acc: 0.4160"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 1s 100us/step - loss: 1.2876 - acc: 0.3978 - val_loss: 1.3760 - val_acc: 0.3179\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2865 - acc: 0.3987 - val_loss: 1.3760 - val_acc: 0.3180\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.2857 - acc: 0.3995 - val_loss: 1.3761 - val_acc: 0.3180\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 1.2849 - acc: 0.4000 - val_loss: 1.3760 - val_acc: 0.3180\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 1.2842 - acc: 0.4007 - val_loss: 1.3762 - val_acc: 0.3180\n",
            "15000/15000 [==============================] - 2s 122us/step\n",
            "Test accuracy: [1.3724843554178874, 0.3215893332958221]\n",
            "Score:  [1.3724843554178874, 0.3215893332958221]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cWjZDxSkeMXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "c0ae022e-9fbe-4c6e-8afa-b592f0e0971a"
      },
      "cell_type": "code",
      "source": [
        "s_lstm2 = np.array(scores_lstm2)\n",
        "s_lstm2_W = np.array(scores_lstm2_W)\n",
        "s_conv2 = np.array(scores_conv2)\n",
        "#s_lms2 = 1-np.array([2,2.47,5.82,21.18,41.54,56.99,66.24,71.6,73.42,74.5])*1.0/100\n",
        "s_lms2 = 1-np.array([5.24,5.34,8.01,21.62,40.6,56.13,65.12,70.04,72.57,72.51])*1.0/100\n",
        "plt.plot(snrs,s_conv2[:,1],\"r\",label=\"Conv\")\n",
        "plt.plot(snrs,s_lstm2[:,1],\"b\",label=\"LSTM\")\n",
        "plt.plot(snrs,s_lstm2_W[:,1],\"g\",label=\"LSTM, Window\")\n",
        "plt.plot(snrs,s_lms2,\"y\",label=\"LMS\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"SNR\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs SNR: Time Variant\")\n",
        "\n",
        "from google.colab import files\n",
        "plt.savefig(\"SNR_time_variant.png\")\n",
        "files.download(\"SNR_time_variant.png\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noihRSiUARVGUKPX/q/f3GOse9mgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fee99c14c88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JWAeTnf7ROTe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Base Case, No Noise Case"
      ]
    },
    {
      "metadata": {
        "id": "DwQTM8nuRXqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3284
        },
        "outputId": "252238d9-feeb-480e-e37b-240369e6e999"
      },
      "cell_type": "code",
      "source": [
        "m = 4         # order of modulation\n",
        "trials = 15000   # number of trials \n",
        "Noise = False\n",
        "seqLen = 300\n",
        "print(seqLen)\n",
        "h_list = []\n",
        "h_list.append(np.array([1,0.5,-0.3]))\n",
        "h_list.append(np.array([1,-.5,-0.5]))\n",
        "h_list.append(np.array([1,-0.25,-0.25]))\n",
        "h_list = np.array(h_list)\n",
        "chanelLen = len(h_list[0])\n",
        "channel_dur = 75\n",
        "print(\"Channel: \",h_list)\n",
        "\n",
        "\n",
        "#LSTM no window\n",
        "hist1_n ,score1_n = LSTM_variant_no_window()\n",
        "#LSTM with window\n",
        "hist2_n,score2_n = LSTM_variant_with_window()\n",
        "#CNN\n",
        "hist3_n,score3_n = ConvNet_variant()\n",
        "\n",
        "print(\"LSTM No Window Score: \",score1_n)\n",
        "print(\"LSTM with Window Score: \",score2_n)\n",
        "print(\"Conv Score: \",score3_n)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "Channel:  [[ 1.    0.5  -0.3 ]\n",
            " [ 1.   -0.5  -0.5 ]\n",
            " [ 1.   -0.25 -0.25]]\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_25 (CuDNNLSTM)    (None, 302, 30)           4080      \n",
            "_________________________________________________________________\n",
            "time_distributed_37 (TimeDis (None, 302, 30)           120       \n",
            "_________________________________________________________________\n",
            "time_distributed_38 (TimeDis (None, 302, 4)            124       \n",
            "=================================================================\n",
            "Total params: 4,324\n",
            "Trainable params: 4,264\n",
            "Non-trainable params: 60\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 5s 357us/step - loss: 1.0215 - accuracy_with_masking: 0.5571 - val_loss: 0.8066 - val_accuracy_with_masking: 0.6132\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 122us/step - loss: 0.6203 - accuracy_with_masking: 0.7812 - val_loss: 0.5261 - val_accuracy_with_masking: 0.7610\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 122us/step - loss: 0.4039 - accuracy_with_masking: 0.9242 - val_loss: 0.3609 - val_accuracy_with_masking: 0.8657\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.3037 - accuracy_with_masking: 0.9547 - val_loss: 0.3146 - val_accuracy_with_masking: 0.8802\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.2406 - accuracy_with_masking: 0.9620 - val_loss: 0.2796 - val_accuracy_with_masking: 0.8986\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.1944 - accuracy_with_masking: 0.9691 - val_loss: 0.2513 - val_accuracy_with_masking: 0.9177\n",
            "Epoch 7/20\n",
            " 1500/15000 [==>...........................] - ETA: 1s - loss: 0.1732 - accuracy_with_masking: 0.9740"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.1587 - accuracy_with_masking: 0.9782 - val_loss: 0.2249 - val_accuracy_with_masking: 0.9409\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.1308 - accuracy_with_masking: 0.9868 - val_loss: 0.2001 - val_accuracy_with_masking: 0.9622\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.1100 - accuracy_with_masking: 0.9921 - val_loss: 0.1771 - val_accuracy_with_masking: 0.9765\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0949 - accuracy_with_masking: 0.9943 - val_loss: 0.1575 - val_accuracy_with_masking: 0.9824\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0839 - accuracy_with_masking: 0.9956 - val_loss: 0.1427 - val_accuracy_with_masking: 0.9832\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0755 - accuracy_with_masking: 0.9962 - val_loss: 0.1313 - val_accuracy_with_masking: 0.9831\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.0689 - accuracy_with_masking: 0.9967 - val_loss: 0.1220 - val_accuracy_with_masking: 0.9832\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0634 - accuracy_with_masking: 0.9972 - val_loss: 0.1145 - val_accuracy_with_masking: 0.9830\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0603 - accuracy_with_masking: 0.9973 - val_loss: 0.1134 - val_accuracy_with_masking: 0.9843\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 122us/step - loss: 0.0594 - accuracy_with_masking: 0.9974 - val_loss: 0.1124 - val_accuracy_with_masking: 0.9854\n",
            "Epoch 17/20\n",
            " 6000/15000 [===========>..................] - ETA: 0s - loss: 0.0588 - accuracy_with_masking: 0.9975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0586 - accuracy_with_masking: 0.9974 - val_loss: 0.1113 - val_accuracy_with_masking: 0.9862\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.0577 - accuracy_with_masking: 0.9975 - val_loss: 0.1101 - val_accuracy_with_masking: 0.9871\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0569 - accuracy_with_masking: 0.9975 - val_loss: 0.1088 - val_accuracy_with_masking: 0.9879\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 121us/step - loss: 0.0560 - accuracy_with_masking: 0.9976 - val_loss: 0.1075 - val_accuracy_with_masking: 0.9887\n",
            "15000/15000 [==============================] - 1s 41us/step\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "y_train shape, one-hot, padding:  (15000, 302, 4)\n",
            "x_train shape, window:  (15000, 302, 10)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_26 (CuDNNLSTM)    (None, 302, 40)           8320      \n",
            "_________________________________________________________________\n",
            "time_distributed_39 (TimeDis (None, 302, 4)            164       \n",
            "=================================================================\n",
            "Total params: 8,484\n",
            "Trainable params: 8,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 5s 364us/step - loss: 1.4195 - accuracy_with_masking: 0.3163 - val_loss: 1.3228 - val_accuracy_with_masking: 0.4138\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 1.2410 - accuracy_with_masking: 0.5889 - val_loss: 1.1238 - val_accuracy_with_masking: 0.5490\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 1.0134 - accuracy_with_masking: 0.7533 - val_loss: 0.9539 - val_accuracy_with_masking: 0.6159\n",
            "Epoch 4/20\n",
            "10500/15000 [====================>.........] - ETA: 0s - loss: 0.8394 - accuracy_with_masking: 0.8516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.8128 - accuracy_with_masking: 0.8586 - val_loss: 0.8163 - val_accuracy_with_masking: 0.6661\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.6504 - accuracy_with_masking: 0.9073 - val_loss: 0.6974 - val_accuracy_with_masking: 0.7462\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.5142 - accuracy_with_masking: 0.9427 - val_loss: 0.6023 - val_accuracy_with_masking: 0.8289\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4150 - accuracy_with_masking: 0.9654 - val_loss: 0.5155 - val_accuracy_with_masking: 0.9127\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.3390 - accuracy_with_masking: 0.9813 - val_loss: 0.4425 - val_accuracy_with_masking: 0.9585\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2835 - accuracy_with_masking: 0.9908 - val_loss: 0.3811 - val_accuracy_with_masking: 0.9825\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.2434 - accuracy_with_masking: 0.9955 - val_loss: 0.3306 - val_accuracy_with_masking: 0.9930\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.2141 - accuracy_with_masking: 0.9977 - val_loss: 0.2896 - val_accuracy_with_masking: 0.9973\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.1922 - accuracy_with_masking: 0.9987 - val_loss: 0.2570 - val_accuracy_with_masking: 0.9987\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.1752 - accuracy_with_masking: 0.9991 - val_loss: 0.2309 - val_accuracy_with_masking: 0.9992\n",
            "Epoch 14/20\n",
            " 9000/15000 [=================>............] - ETA: 0s - loss: 0.1642 - accuracy_with_masking: 0.9993"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.1618 - accuracy_with_masking: 0.9993 - val_loss: 0.2100 - val_accuracy_with_masking: 0.9994\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.1510 - accuracy_with_masking: 0.9995 - val_loss: 0.1929 - val_accuracy_with_masking: 0.9995\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 138us/step - loss: 0.1420 - accuracy_with_masking: 0.9995 - val_loss: 0.1790 - val_accuracy_with_masking: 0.9996\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.1345 - accuracy_with_masking: 0.9996 - val_loss: 0.1673 - val_accuracy_with_masking: 0.9997\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 137us/step - loss: 0.1280 - accuracy_with_masking: 0.9997 - val_loss: 0.1574 - val_accuracy_with_masking: 0.9997\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.1224 - accuracy_with_masking: 0.9997 - val_loss: 0.1489 - val_accuracy_with_masking: 0.9998\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 135us/step - loss: 0.1175 - accuracy_with_masking: 0.9998 - val_loss: 0.1415 - val_accuracy_with_masking: 0.9998\n",
            "15000/15000 [==============================] - 1s 53us/step\n",
            "x_train shape:  (15000, 302, 2)\n",
            "y_train shape:  (15000, 300)\n",
            "y_train shape, one-hot:  (15000, 300, 4)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_13 (Conv1D)           (None, 300, 10)           70        \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 300, 10)           40        \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1200)              3601200   \n",
            "_________________________________________________________________\n",
            "reshape_13 (Reshape)         (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "softmax_13 (Softmax)         (None, 300, 4)            0         \n",
            "=================================================================\n",
            "Total params: 3,601,310\n",
            "Trainable params: 3,601,290\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "Train on 15000 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            " 6250/15000 [===========>..................] - ETA: 5s - loss: 1.3243 - acc: 0.4187"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 5s 339us/step - loss: 0.9442 - acc: 0.6392 - val_loss: 0.7074 - val_acc: 0.7417\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.2399 - acc: 0.9847 - val_loss: 0.5791 - val_acc: 0.8057\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 104us/step - loss: 0.0825 - acc: 0.9997 - val_loss: 0.6140 - val_acc: 0.8146\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 104us/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.6678 - val_acc: 0.8164\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.8166\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 102us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.7643 - val_acc: 0.8165\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.8163\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8396 - val_acc: 0.8160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.8709 - val_acc: 0.8158\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 104us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.8989 - val_acc: 0.8157\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.9244 - val_acc: 0.8155\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.9476 - val_acc: 0.8153\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 100us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.9690 - val_acc: 0.8151\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 103us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.9888 - val_acc: 0.8150\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 102us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.0074 - val_acc: 0.8148\n",
            "Epoch 16/20\n",
            "12250/15000 [=======================>......] - ETA: 0s - loss: 0.0023 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.0241 - val_acc: 0.8148\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 103us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.0406 - val_acc: 0.8146\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 102us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0560 - val_acc: 0.8144\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 102us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0702 - val_acc: 0.8143\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 103us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0838 - val_acc: 0.8142\n",
            "15000/15000 [==============================] - 2s 130us/step\n",
            "Test accuracy: [0.06742531068722407, 0.9776008907953898]\n",
            "LSTM No Window Score:  [0.051715163389841716, 0.996222448348999]\n",
            "LSTM with Window Score:  [0.2623449683189392, 0.9389404416084289]\n",
            "Conv Score:  [0.06742531068722407, 0.9776008907953898]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}