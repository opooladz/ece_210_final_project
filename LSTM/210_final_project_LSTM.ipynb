{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210_final_project_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/opooladz/ece_210_final_project/blob/master/LSTM/210_final_project_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DeLbOeSmqguA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Libs \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special\n",
        "import scipy.io as sio\n",
        "import math\n",
        "#from  scipy.ndimage import convolve1d\n",
        "\n",
        "# Reloading any code written in external .py files.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ogt-kQ8x61dI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keras try model \n",
        "def try_model(model, data, name, epochs=200, verbose=1):  \n",
        "  model.compile(optimizer='nadam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=[ 'accuracy'])\n",
        "\n",
        "  model.summary()  \n",
        "  history = model.fit(data['x_train'], data['y_train'], \n",
        "            epochs=epochs, batch_size=64, verbose=verbose, \n",
        "            validation_data=(data['x_val'], data['y_val']))  \n",
        "  score = model.evaluate(data['x_test'], data['y_test'])\n",
        "  print('Test accuracy: {}'.format(score))\n",
        "  \n",
        "#   out_path = 'serialized_models/{}.h5'.format(name)  \n",
        "#   model.save(out_path)\n",
        "  \n",
        "#   with open('serialized_models/{}_history.pickle'.format(name), 'wb') as handle:\n",
        "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "  return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a24-OWBXsGkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Comms Stuff Will add more later\n",
        "def qammod(m,y):\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  x = a + 1.*1j*b\n",
        "  # lets hold x in a np array([real,imag])\n",
        "  # x = np.array([a,1.*b]).T\n",
        "  return [x , y] \n",
        "\n",
        "def qammod2(m,size,trials):\n",
        "  \"\"\"\n",
        "  m - highest integer for the randint\n",
        "  \"\"\"\n",
        "  y = np.random.randint(m,size=(trials,size))\n",
        "  if(np.all(y>=m)):\n",
        "    print('qammod: all elements of X must be in range [0,M-1]')\n",
        "  \n",
        "  if (~np.all(y == np.fix(y) ) ):\n",
        "    print(\"qammod: all elements of X must be integers\");\n",
        "  \n",
        "  c = np.sqrt(m);\n",
        "  if( ~(np.all(c == np.fix(c)) and np.all(np.math.log(c, 2) == np.fix(np.math.log(c, 2))) ) ):\n",
        "    print(\"qammod: M must be a square of a power of 2\");\n",
        "  \n",
        "  b = -2*np.fmod(y,c) + c - 1.;\n",
        "  a = 2*np.floor(y *1./c) - c + 1.;\n",
        "  #x = a + 1.*1j*b\n",
        "  # lets hold x in a dp array([real,imag])\n",
        "  #x = np.array([a,1.*b])\n",
        "  x = np.dstack((a,b))\n",
        "  return [x , y]                        \n",
        "\n",
        "def channel2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  \n",
        "  [x,y] = qammod2(m,sequenceLen,trials)\n",
        "  \n",
        "  h = [1., 0.5, 0.3, -0.13, 0.2, 0, 0.4]\n",
        "  #h = np.random.randn(1,chanelLen)\n",
        "  #h = [1]\n",
        "  #print(x.shape)\n",
        "#   xh = np.empty((sequenceLen+len(h)-1,2))\n",
        "#   xh[:,0] = np.convolve(x[:,0],h)   \n",
        "#   xh[:,1] = np.convolve(x[:,1],h)   \n",
        "  #xh = convolve1d(x,h,axis = 1)\n",
        "  xh = np.apply_along_axis(lambda m: np.convolve(m,h[0:chanelLen],mode=\"full\"),axis = 1,arr=x)\n",
        "  #print(xh.shape)\n",
        "  SNR = 10**(SNRdB/10)\n",
        "  sym_noise_pow = np.var(xh)/SNR\n",
        "  sym_noise_scale_fact = np.sqrt(sym_noise_pow/2)\n",
        "  if(Noise):\n",
        "    AWGN = sym_noise_scale_fact*np.random.normal(1, size=xh.shape) \n",
        "    xh = xh + AWGN\n",
        "  #return [xhN.T , np.repeat(y,2) ]\n",
        "  return [xh ,y ]\n",
        "  \n",
        "                        \n",
        "data={}\n",
        "def generateData2(m,sequenceLen,trials,Noise,SNRdB,chanelLen):\n",
        "  [data['x_train'],data['y_train']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_val'],data['y_val']] = channel2(m=m,sequenceLen=sequenceLen,trials=int(trials*0.5),Noise= Noise,SNRdB=SNRdB,chanelLen=chanelLen)\n",
        "  [data['x_test'],data['y_test']] = channel2(m=m,sequenceLen=sequenceLen,trials=trials,Noise=Noise,SNRdB=SNRdB,chanelLen=chanelLen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sztUIJEosHZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "06752264-477f-4d2b-a735-13d11d98bc24"
      },
      "cell_type": "code",
      "source": [
        "# Visulizing the data\n",
        "\n",
        "m = 4         # order of modulation\n",
        "#seqLen = 64    # length of one trial must be square powers of 2 to make sense see below \n",
        "trials = 10000   # number of trials \n",
        "Noise = 1\n",
        "SNRdB = 20\n",
        "chanelLen = 4\n",
        "\n",
        "\n",
        "x = 4\n",
        "square_power_of_two = 2**(2*x)\n",
        "seqLen = square_power_of_two  \n",
        "print(seqLen)\n",
        "\n",
        "generateData2(m,seqLen,trials,Noise,SNRdB,chanelLen)\n",
        "print(data['x_train'].shape) # data  # axis 1 should be 2x seqLen because of conv with a 2tap filter\n",
        "print(data['y_train'].shape) # labels\n",
        "#print(data['x_train']) # so u can see the data \n",
        "\n",
        "# tmp = (data['x_train'][:,:-1].reshape(trials,seqLen))\n",
        "\n",
        "# #plot 1\n",
        "# plt.scatter(np.real(tmp[0][:]),np.imag(tmp[0][:]))   \n",
        "#                                          # I only plot the first 10 points from \n",
        "#                                          # the sequence because as time goes on \n",
        "#                                          # the data becomes less dependent on the\n",
        "#                                          # previous symbols. Even 10 is a lot. \n",
        "# plt.title('4-QAM Mod With Multi-Channel AWGN plot 1')\n",
        "# plt.show()\n",
        "\n",
        "#plot 2\n",
        "# Just a pure 16 qam with 1 point on each constalation point \n",
        "# clearly we have 16 classes\n",
        "# [xtmp,ytmp]=  qammod(16,data['y_train'])\n",
        "# plt.scatter(xtmp[:,0],xtmp[:,1])\n",
        "# plt.title('16-QAM Mod plot 2')\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "(10000, 259, 2)\n",
            "(10000, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6RLVcKzsKTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3a9c0845-836a-4687-c4d2-54e9c5bcd41c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Some keras stuffs\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, Flatten, AveragePooling2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.layers import Reshape, Permute\n",
        "from keras import regularizers\n",
        "import keras\n",
        "ykeys = {'y_train','y_val','y_test'}\n",
        "xkeys = {'x_train','x_val','x_test'}\n",
        "\n",
        "  \n",
        "y_train = keras.utils.to_categorical(data['y_train'] , num_classes=m)\n",
        "y_val = keras.utils.to_categorical(data['y_val'] , num_classes=m)\n",
        "y_test = keras.utils.to_categorical(data['y_test'] , num_classes=m)\n",
        "\n",
        "print(data['x_train'].shape)\n",
        "print(data['x_test'].shape)\n",
        "print(y_train.shape)\n",
        "print(data['x_val'].shape)\n",
        "\n",
        "\n",
        "default_data = {\n",
        "  'x_train': data['x_train'],\n",
        "  'x_val': data['x_val'],\n",
        "  'x_test': data['x_test'],\n",
        "  'y_train': y_train,\n",
        "  'y_val': y_val,\n",
        "  'y_test': y_test,\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 259, 2)\n",
            "(10000, 259, 2)\n",
            "(10000, 256, 4)\n",
            "(5000, 259, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Jz3iVxn48iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "0dd30cbb-1c23-4fc4-e626-31c1b19b8d54"
      },
      "cell_type": "code",
      "source": [
        "# QAM-4\n",
        "from keras.layers import Reshape,Dense,Embedding,Conv1D, LSTM,CuDNNLSTM, TimeDistributed, GaussianNoise, Softmax,Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "modCNN = Sequential()\n",
        "modCNN.add(Conv1D(2,kernel_size=(3), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(2,kernel_size=(3)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Flatten())\n",
        "modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "modCNN.add(BatchNormalization())\n",
        "#modCNN.add(Dropout(0.4))\n",
        "modCNN.add(Softmax(axis=2))\n",
        "try_model(modCNN, default_data, 'conv_lstmx', epochs=3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_51 (Conv1D)           (None, 257, 2)            14        \n",
            "_________________________________________________________________\n",
            "batch_normalization_76 (Batc (None, 257, 2)            8         \n",
            "_________________________________________________________________\n",
            "conv1d_52 (Conv1D)           (None, 255, 2)            14        \n",
            "_________________________________________________________________\n",
            "batch_normalization_77 (Batc (None, 255, 2)            8         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 510)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1024)              523264    \n",
            "_________________________________________________________________\n",
            "reshape_26 (Reshape)         (None, 256, 4)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_78 (Batc (None, 256, 4)            16        \n",
            "_________________________________________________________________\n",
            "softmax_26 (Softmax)         (None, 256, 4)            0         \n",
            "=================================================================\n",
            "Total params: 523,324\n",
            "Trainable params: 523,308\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "Train on 10000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 7s 698us/step - loss: 1.1606 - acc: 0.4976 - val_loss: 0.8564 - val_acc: 0.7162\n",
            "Epoch 2/3\n",
            " 1152/10000 [==>...........................] - ETA: 2s - loss: 0.7258 - acc: 0.7811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 308us/step - loss: 0.5313 - acc: 0.8944 - val_loss: 0.4259 - val_acc: 0.9846\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 306us/step - loss: 0.2556 - acc: 0.9934 - val_loss: 0.2174 - val_acc: 0.9938\n",
            "10000/10000 [==============================] - 1s 142us/step\n",
            "Test accuracy: [0.21727805149555207, 0.993878125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f907cc92a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "4uiqlqiQ9y_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "ee4da771-efaf-4480-f5ec-915959c0e0a7"
      },
      "cell_type": "code",
      "source": [
        "# QAM-16\n",
        "from keras.layers import Reshape,Dense,Embedding,Conv1D, LSTM,CuDNNLSTM, TimeDistributed, GaussianNoise, Softmax,Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "modCNN = Sequential()\n",
        "modCNN.add(Conv1D(5,kernel_size=(3), input_shape=(seqLen+chanelLen-1,2) ))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Conv1D(5,kernel_size=(3)))\n",
        "modCNN.add(BatchNormalization())\n",
        "modCNN.add(Flatten())\n",
        "modCNN.add(Dense(seqLen*m,bias_regularizer=regularizers.l2(0.005)))\n",
        "modCNN.add(Reshape(target_shape = (seqLen,m)))\n",
        "modCNN.add(BatchNormalization())\n",
        "#modCNN.add(Dropout(0.4))\n",
        "modCNN.add(Softmax(axis=2))\n",
        "try_model(modCNN, default_data, 'conv_lstmx', epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_49 (Conv1D)           (None, 255, 5)            35        \n",
            "_________________________________________________________________\n",
            "batch_normalization_73 (Batc (None, 255, 5)            20        \n",
            "_________________________________________________________________\n",
            "conv1d_50 (Conv1D)           (None, 253, 5)            80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_74 (Batc (None, 253, 5)            20        \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 1265)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4096)              5185536   \n",
            "_________________________________________________________________\n",
            "reshape_25 (Reshape)         (None, 256, 16)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_75 (Batc (None, 256, 16)           64        \n",
            "_________________________________________________________________\n",
            "softmax_25 (Softmax)         (None, 256, 16)           0         \n",
            "=================================================================\n",
            "Total params: 5,185,755\n",
            "Trainable params: 5,185,703\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            " 7296/50000 [===>..........................] - ETA: 38s - loss: 2.7033 - acc: 0.1396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 25s 507us/step - loss: 1.9520 - acc: 0.3473 - val_loss: 1.5289 - val_acc: 0.4553\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 1.3766 - acc: 0.5473 - val_loss: 1.2272 - val_acc: 0.5897\n",
            "Epoch 3/10\n",
            " 3712/50000 [=>............................] - ETA: 17s - loss: 1.1733 - acc: 0.6474"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 415us/step - loss: 1.1216 - acc: 0.6566 - val_loss: 1.0188 - val_acc: 0.6890\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 21s 415us/step - loss: 0.9363 - acc: 0.7375 - val_loss: 0.8583 - val_acc: 0.7649\n",
            "Epoch 5/10\n",
            " 4672/50000 [=>............................] - ETA: 17s - loss: 0.8156 - acc: 0.7925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 416us/step - loss: 0.7880 - acc: 0.7997 - val_loss: 0.7222 - val_acc: 0.8215\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 21s 411us/step - loss: 0.6635 - acc: 0.8481 - val_loss: 0.6088 - val_acc: 0.8651\n",
            "Epoch 7/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 411us/step - loss: 0.5584 - acc: 0.8847 - val_loss: 0.5116 - val_acc: 0.8981\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 20s 408us/step - loss: 0.4698 - acc: 0.9120 - val_loss: 0.4291 - val_acc: 0.9214\n",
            "Epoch 9/10\n",
            " 6912/50000 [===>..........................] - ETA: 16s - loss: 0.4136 - acc: 0.9261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 411us/step - loss: 0.3962 - acc: 0.9320 - val_loss: 0.3629 - val_acc: 0.9393\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 20s 409us/step - loss: 0.3352 - acc: 0.9469 - val_loss: 0.3086 - val_acc: 0.9518\n",
            "15136/50000 [========>.....................] - ETA: 5s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 8s 158us/step\n",
            "Test accuracy: [0.308697285490036, 0.951788125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f907daf32b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "QTJRbvO9BkOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}